---
layout: post
title: Joint Collaborative Autoencoders
author: Jaeheon Kwon
categories: Papers
tags: [recommendation,Autoencoder]
---

#  Improving Top-K Recommendation via Joint Collaborative Autoencoders 

## Abstract

이 논문에서는 user-user & item-item간의 상관관계를 동시에 학습하여, 더 robust하고 Top-K Recommendation의 성능을 향상시키는 Joint Collaborative Autoencoder를 소개합니다.

구체적으로, 우리는 user-item 상관관계를 모델링하고, feedback 이질성의 영향을 감소시키는 정규화의 중요성을 보여줍니다.

또한, pairwise hinge-based object function을 사용하여 Top-K 정확도를 높이고, 추천을 리턴합니다.

마지막으로 미니 배치 최적화 알고리즘을 사용하여 제안된 모델을 학습시키고, 추가적인 실험을 통해 세 가지 공개 데이터셋에 대하여 최근 SOTA 모델들과 우리 모델을 비교합니다.

## Introduction

클릭 수, 구매 수, 조회 수 등의 feedback은 explicit rating보다 더 넓은 범위에 해당하므로 implicit Top-K recommenders는 광범위한 영향을 미칠 수 있는 좋은 기회를 제공합니다.

가장 영향력 있는 접근 방법 중 하나는 Collaborative filtering(CF)인데, 유저의 선호도 일관성(user-user CF) 혹은 item간의 rating 상관관계(item-item CF)를 학습합니다.

최근에 우리는 신경망 프레임워크로 CF의 확장을 목표로 하는 일련의 작업들을 봐왔습니다. 이는 유연성, 비선형성, 구조의 복잡성 등을 사용하여 표현력과 추천 성능을 SOTA로 이끌었습니다.

이러한 새로운 신경망 기반의 neighborhood based model은 한가지 한계는 user와 item 상호작용의 중요성을 고려하지 않은 채 only user or only item과 같은 저차원 임베딩을 학습하려고 하는 것입니다.

결과적으로 추천 성능이 제한될 수 있습니다.

대조적으로 user-item의 상호작용을 고려한 효과적인 모델링은 추천 퀄리티를 향상시키는 것을 선행 연구들에서 볼 수 있었습니다.

이러한 직관에 대해선 아래의 섹션에서 실험적으로 확인합니다.

우리는 user-based & item-based 오토 인코더는 대부분의 추천이 같지만, 둘 사이의   상당한 불일치가 있음을 발견했습니다.

JCA모델은 user-user & item-item의 상관관계를 동시에 배우고, 이를 통해recommender는 숨겨진 정보에 대해 상당한 이점을 취할 수 있게 되고, 추천 품질의 향상으로 이어집니다.

JCA에서 이러한 user-item 상호작용을 모델링하는 방법을 보여주고, feedback 이질성의 영향을 완화하기 위한 정규화의 중요성을 보여줍니다.

> feedback heterogeneity?
>
> naive methods에서는 user가 싫어하는 item을 추천해주는 것을 뜻하는 것 같음

## Preliminary

### Implicit Top-K Recommendation

set of Users as $U = \{ 1,2,...,N \}$

set of Items as $I = \{ 1,2,...,M \}$

set of historical feedback from the users to the items as $O =\{ u, i,r_{u,i} \}$

$u$ = indexes one user

$i$ = indexes one item

$r_{u,i}$ = represents the rating from the user $u$ to the item $i$

Implicit top-K recommendations에서는 보통 positive feedback signals만 사용하는데, 이것은 우리가 user가 좋아하는 item에 대해서만 알고 있고 유저가 싫어하는 item에 대해선 알지 못한다는 것을 의미합니다.

이 historical feedback을 바탕으로 우리는 상호작용 하지 않은 item에 대한 각 user의 선호도를 예측하고, 예측 점수가 가장 높은 item을 user에게 추천하는 것입니다.

또한 우리는 user $u$가 positive feedback을 준 item set에 대하여 $O^{+}_{u}$로 표기하고,

user $u$에게 feedback을 받지 않은 item set을 $O^{-}_{u}$로 표기합니다.

실제로 우리는 모델을 훈련시키기 위해 unrated items의 부분 집합을 random sampling하므로, 본 논문에서는 random selected negative samples를 나타내기 위해 $O^{-}_{u}$를 사용합니다.



### Autoencoders for Recommendation

implicit top-K recommendation 문제를 해결하기 위해 오토인코더 기반 모델은 비 신경 및 다른 신경망 모델과 비교하여 유망한 성능을 보여왔습니다.

우리는 오토인코더의 입력으로 binary로 표기된 rating vector of users(or items)을 넣으면 출력으로 일치하는 완전하게 rating vector를 받습니다.

 [AutoRec: Autoencoders Meet Collaborative Filtering]( https://dl.acm.org/doi/pdf/10.1145/2740908.2742726 )에서 제안한  오토인코더 베이스 추천 모델 AutoRec는 implicit binary feedback Matrix $R$을 입력으로 받아서 preference matrix $\hat R$을 출력합니다.

$\hat R = f(g(RV + b1)W + b2) \tag{1}$

만약 $f(),g()$가 identity function이고, bias node가 무시된다면 AutoRec는 다음과 같이 표기할 수 있습니다.

$\hat R = RVW \tag{2}$ 

이는 유사도 측정으로 두개의 factorized matrices를 가진 user based neighborhood model과 동일합니다.

결과적으로 user rating vector $R^U \in R^{N*M}$을 입력으로 넣으면(user vetor는 row임) AutoRec는 item간의 유사성을 알게 됩니다.

우리는 이 모델을 user-based AutoRec(or U-AutoRec)라고 부릅니다.

비슷한 방식으로 item rating vector $R^I \in R^{M*N}$을 입력으로 하고 user간의 유사도를 학습할 수 있습니다.

이 모델은 item-based AutoRec(or I-AutoRec)라고 부릅니다.



### User-based AutoRec and Item-based AutoRec Are Complementary

이전 연구에서 전통적인(non-neural) user & item based CF model은 근본적으로 다르다는 것을 확인했습니다.

우리는 neural neighborhood-based CF 방법(U-AutoRec & I-AutoRec)의 차이점을 조사합니다.

보다 구체적으로, 다른 모델에서 캡처한 같은 데이터셋으로 부터 다른 정보가 보완적인 추천을 생성할 수 있는지 알아봅니다.

이 질문에 답하기 위해서 우리는 같은 MovieLens 1M dataset을 통해 U-AutoRec와 I-AutoRec를 실행합니다.

이 데이터 셋의 각 user에 대해 두 모델은 순위가 지정된 영화 리스트를 추천합니다.

우리는 모델의 적중률을 10개의 추천된 영화 집합으로 고려합니다.

U-AutoRec의 히트를 $H^U$로, I-AutoRec의 히트를 $H^I$로 나타냅니다.

그런 다음 특정 user에 대한 이 두 모델의 히트 차이 비율을 다음과 같이 나타냅니다.

$HitsDifferenceRate  = \frac{size(H_U \cup H_I)-size(H_U \cap H_I)}{size(H_U \cup H_I)} \tag{3}$



$size()$는 집합의 원소 수를 계산합니다.

HDR은 두 모델 사이의 올바른 추천의 차이를 보여줍니다.

만약 Rate가 높다면 두 모델이 보완적인 추천을 제공함을 나타냅니다.

> HDR이 높다는 건 $H^U$와 $H^I$의 원소의 수가 교집합 없이 합집합에 가깝다는 뜻이고, 이는 서로 다른 모델이 다른 추천(user, item vector에 따라)을 제공한다는 뜻이고 이를 통해 보완적인 추천이 가능하다는 건가..?

MovieLens user에 대한 HDR의 CDF는 Fig.1에 나와 있습니다.

<img src = "https://py-tonic.github.io/images/jca/1.PNG">

우리는 60%이상의 user의 HDR이 20%보다 크며 일부 사용자(약 30%)가 HDR이 50%보다 큰 것을 볼 수 있습니다.

그러므로 우리는 Fig.1의 관측에 의거하여 U-AutoRec와 I-AutoRec는 서로 보완적인 다른 추천을 생성한다고 결론지을 수 있습니다.

또한, U-AutoRec와 I-AutoRec의 추천 퀄리티와 간단한 평균화 모델을 비교하여 두 모델이 보완적이라고 결론지을 수 있습니다.

> 평균화 모델은 UI-AutoRec라는 이름으로,
>
> 별도로 훈련된 U-AutoRec와 I-AutoRec의 출력을 최종결과로 평균화함.

세 가지 데이터 셋의 실험을 통해 우리는 Table.1에서 U-AutoRec & I-AutoRec의 평균은 각각의 단일 모델과 비교하여 top-10 Recommendation의 퀄리티가 더 향상된 것을 관측했습니다.

따라서 두 모델을 함께 결합하여 정보의 양쪽을 동시에 탐색하는 것은 top-K recommendation의 추천 퀄리티를 향상시키는데 유망합니다.

<img src = "https://py-tonic.github.io/images/jca/2.PNG">

## Proposed Model

### Joint Collaborative Autoencoder

JCA의 직관은 user & items을 개별적으로 처리하지 않고 동시에 직접 모델링 하는 것입니다.

heterogeneity of feedback을 고려하지 않은 naive한 user & item 조합은 user가 싫어하는 item에 대해서도 출력 레이어에서 예측 점수가 과대 평가 될 수 있습니다.

JCA 구조에 대해서는 Fig.2에서 볼 수 있습니다.

**Joint User-Item Correlations Modeling.** N개의 user, M개의 item이 주어질 때, JCA는 전체 rating matrix $R \in R^{N*M}$을 이중 입력으로 사용합니다.

Fig.2에서 처럼 rating matrix는 왼쪽과 오른쪽 모두에서 모델에 입력됩니다.

주요 차이점은 matrix가 슬라이스 되는 방식에 있습니다.

왼쪽은 하나의 item rating vector$(R^T)_i \in R^{1,N}$을 하나의 샘플(i.e. one column of R)로 입력하고, 

오른쪽은 하나의 user rating vector$R_u \in R^{1,M}$을 하나의 샘플(i.e. one row of R)로 입력합니다.

본질적으로 모델에는 두 개의 구성 요소가 있는데, 첫 번째는 User Component인 $R_u$를 하나의 입력 샘플로 사용하고, 다른 하나는 Item Component라고 불리는 $(R^T)_i$입니다.

두 구성 요소는 두 개의 오토 인코더 구조로 rating matrix를 독립적으로 복구합니다.

user & item 구성 요소의 첫 번째 레이어의 가중치는 각각 $V^U \in R^{M,H^U} and \ V^I \in R^{N,H^I}$로 표기합니다.

$H^U and \ H^I$는 두 구성 요소의 hidden layer의 차원을 나타냅니다.

마찬가지로, 두 번째 레이어의 가중치를 각각

$W^U \in R^{H^U,M} and \ W^I \in R^{H^I,N}$으로 표기합니다.

hidden layer 및 output layer의 bias는  user component인 경우 $b^U_1 and \ b^U_2$로, item component인 경우 $b^I_1 and \ b^I_2$로 표기합니다.

우리는 hidden layer 및 output layer에 대해 두 component 모두 활성화 함수로 sigmoid를 사용합니다.

user or item의 하나 혹은 여러개의 불완전한 rating vector를 입력하고 완성된 rating vector를 출력하는 기존의 user-based & item-based AutoRec와 달리, JCA는 전체 rating matrix를 입력으로 취하여 전체 완료된 rating matrix를 출력합니다. 

user component와 item component는 두 개의 완성된 rating matrix를 독립적으로 출력하며, 두 개의 출력을 결합하여 최종 출력이 됩니다.

$\hat R  = \frac{1}{2}[h_{item}(R)+h_{user}(R)] \tag{1}$

$\hat R$은 predicted rating matrix이고, $h_{item}$은 item 구성 요소의 출력, $h_{user}$은 user 구성 요소 출력입니다.

**Learnable Item Normalization Factor.** 기존 오토인코더 기반 추천 시스템의 한가지 과제는 hidden layer에 정규화가 없다는 것입니다.

결과적으로 heterogeneity of feedback은 문제를 야기합니다.

user-based AutoRec를 예로 들면 more positive feedback을 user rating vector로 입력하면 모델은 결과적으로 더 큰 norm의 hidden layer가 생성되어 user가 싫어하는 item에 대해서도 output layer에서 더 높은 예측 점수를 얻을 수 있습니다.

item-based AutoRec에서도 비슷한 상황이 발생하는데, 이 경우 more positive feedback인 item은 싫어하는 user에 대해서도 전체적으로 더 높은 예측 점수를 얻습니다.

user 별 정규화 상수를 채택한 FISM에서 영감을 얻은 이 item feedback hete  rogeneity의 영향을 완화하기 위해 학습 가능한 item 정규화 요소를 추가합니다.

구체적으로, 우리는 학습 가능한 item Normalization Factor $f \in R^{M,1}$를 item component의 hidden layer에 곱합니다.

 이 파라미터는 피드백이 많은 item의 predicted ratings이 더 높아질 수 있는 문제를 해결하기 위해 각 item의 norm of the latent factor를 정규화합니다.

recommender가 예상 선호도 점수를 매기고, 각 user에 대해 top-K items를 독립적으로 추천하기 때문에 user component에는 normalization factor가 필요하지 않습니다.



### Pairwise Hinge-based Object Function for Implicit Top-K Recommenders

기존의 object function을 최적화하여 파라미터를 학습할 수 있지만,

이러한 기존의 함수 중 다수는 MSE or AUC를 최적화 하려고 시도합니다.

이는 Top-K Recommendation metrics과 일치하지 않습니다.

때문에 우리는 pairwise hinge-based objcet function을 통해 직접 최적화 합니다.



$L = \sum\sum max(0,\hat r_{u,j} - \hat r_{u,i} + d) + \frac{\lambda}{2} \vert\vert \theta \vert\vert^2_F \tag{2}$

ADG 및 NDCG와 같은 평가 방식에 적합합니다.

$\hat r_{u,j} $ 와 $\hat r_{u,i}$는 user $u$에 대해  positive feedback(item $i$)과 negative sampling($j$)으로 예측된 점수입니다.

실제로 우리는 관찰되지 않은 모든 항목을 negative sample로 사용할 수 없기 때문에 random negative sample에 대해 일정한 마진을 설정하고 random negative sampling 전략의 영향을 막기 위해 positive feedback을 설정합니다.



## Reference

<hr>

 [JCA](https://dl.acm.org/doi/epdf/10.1145/3308558.3313678) 

[github]( https://github.com/Zziwei/Joint-Collaborative-Autoencoder )