---
layout: post
title: 확률과 통계 기본(2)
author: Jaeheon Kwon
categories: 
tags: 
---

# 확률과 통계 기본 (2)

수정중..



## 이항분포

이항분포(binomial distribution)는 '확률 p로 앞이 나오는 동전을 n번 던졌을 때 앞이 몇번 나올지'의 분포입니다.<br>

즉, 확률 p로 1, q = (1 - p)로 0이 나오는 **독립적인 확률변수** $Z_1,...,Z_n$을 두면,<br>

$X ≡ Z_1,...,Z_n$의 분포가 이항분포가 됩니다.

<img src = "https://py-tonic.github.io/images/Probability/2.PNG">

위 그림처럼 이항 분포는 n과 p에따라 바뀝니다.
그래서 Bn(n, p)로 나타냅니다.

일반화 해보면 Random 한 n, p에 대하여 P(X = k)로 볼 수 있습니다.
우선 X = k인 확률변수 $Z_1,...,Z_n$의 패턴이 $_nC_k$가지 있습니다.
또한 각각이 확률 $p^kq^{n-k}$이므로
 $P(X=K) = {_n}C_kp^kq^{n-k}$ 로 나타낼 수 있습니다.

## 최대우도추정법

사실 확률과 통계를 정리하게 된 계기가 바로 MLE(Maximum Liklihood Estimation)때문입니다.
자주 나오는 단어인데 도대체 무슨뜻인지 모르고 있기 답답해서 공부하게 되었습니다.

MLE란 어떤 확률변수에서 Sampling한 값들을 토대로 그 확률변수의 모수(θ)를 구하는 방법입니다.<br>
<br>

조건부확률과 Bayes정리를통해 저게 무슨뜻인지 이제 짐작할 수 있습니다.<br>

말로 풀어서 설명하자면
우도는 우리가 가진 데이터 x에 비추어봤을 때 모수 θ에 대한 추정이 그럴듯한 정도를 가르킵니다.
보통 모수와 모집단이 이미 알려져있고 여기서 어떤 사건이 관찰되는 가능성을 확률이라고 합니다.
우도는 이 개념의 정 반대입니다.
관측치가 고정되고, 이 관측치가 나오도록 가장 그럴듯한 모수값을 추정하는 것입니다.
이 때 관측치가 관찰될 가능성을 '우도'라고 하고, 함수로 표현하며,
우도가 가장 높아지게하여 모수를 추정하는 방법이 최대우도법입니다.

이걸 알고나니 왜 ML이나 DL에서 자주 언급되는지 이해하게 되었습니다.
저희가 가진 데이터는 항상 작을 수 밖에 없습니다.
일반화된 모델을 얻기위해 데이터의 크기를 늘리거나 파라미터를 조정하는데,
모수를 추정하는 방법이 바로 일반화된 모델을 얻는 것과 동일한 것 같습니다.

위에서 이항분포를 가르쳐 드렸으니 이항분포를 예시로 들어 보겠습니다.<br>
<br>
$max_{0≤p≤1}Pr(k|p,n)$ <br>
<br>
$≡ max_{0≤p≤1}ln[Pr(k|p,n)]$<br>

$≡ max_{0≤p≤1}[const. + kln(p)+(n-k)ln(1-p)]$<br>

$≡ max_{0≤p≤1} Φ(p),   Φ(p)=kln(p)+(n-k)ln(1-p)$<br>

이항 분포를 알고있기 때문에 대입해서 maximum 시켜줍니다.
log를 사용하는 이유는 계산량을 낮추기 위해서입니다.<br>
<br>
$Φ(p)=kln(p)+(n-k)ln(1-p)$ 식을 미분해서 극값을 찾습니다.<br>
$k/p - n-k/1-p = 0$이 되고, p에대해 정리하면 $p = k/n$일때 최적임을 알 수 있습니다.

사실 당연한 얘기입니다.
n = 동전의 시행횟수, k= 앞면이 나온 경우의수 라고 치면
n= 100, k=56일때 를 예로 들면 우리는 100번던졌을 때 앞면이 56번이 나올 것이란걸 알 수 있습니다.
이게만약 동전이아닌 어떤 가상의 물체라고 쳤을 때도 다음 시행에서 앞면이 나올 확률을 예측하는건 $k/n$임이 자명합니다.

실제 값을 통해서 한번 구현해봅시다.<br>
<br>
 $P(X=K|θ) = {_n}C_kp^kq^{n-k}$<br>
 <br>
$θ=0.4:0.75, n=100, k=56, p=0.5$<br>
## Implements

```python
import operator as op
from functools import reduce
data=[]
def Bn(n,r,p):
    if n<1 or r<0 or n<r:
        raise valueError
    numerator = reduce(op.mul, range(n,n-r,-1),1)
    denominator = reduce(op.mul, range(1,r+1),1)
    com = numerator//denominator
    data.append(round(com*(p**r)*((1-p)**(n-r)),5))
    return data[-1]

for i in np.arange(0.4,0.75,0.01):
    Bn(100,56,i)
    
print(data)
```

    [0.00044, 0.00085, 0.00154, 0.00267, 0.00444, 0.00707, 0.0108, 0.01582, 0.02224, 0.03003, 0.03895, 0.04854, 0.05812, 0.06688, 0.07395, 0.07856, 0.08016, 0.07855, 0.07387, 0.06664, 0.05763, 0.04774, 0.03784, 0.02867, 0.02075, 0.01431, 0.0094, 0.00587, 0.00347, 0.00195, 0.00103, 0.00051, 0.00024, 0.0001, 4e-05]



```python
import matplotlib.pyplot as plt
plt.plot(np.arange(0.4,0.75,0.01),data)
plt.show()
```

<img src = "https://py-tonic.github.io/images/Probability/Bn.png">

보시는 것 처럼 56/100일때 최대치임을 알 수 있습니다.

## Reference

[Ratsgo's blog]( https://ratsgo.github.io/statistics/2017/09/23/MLE/ )<br>

[Dilettante Zen](https://drnq.tistory.com/244)
