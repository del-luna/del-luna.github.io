---
layout: post
title: ISLR chapter.4
author: Jaeheon Kwon
categories: Ai
tags: [islr]
---



 3장에서 다룬 내용들은 반응 변수 $Y$가 정량적인 경우 였습니다. 하지만 반응 변수가 정성적인 경우도 많이 존재합니다. 예를 들면 눈의 색은 파란색, 갈색, 초록색 등 정성적으로 표현할 수 있습니다. 종종 이런 정성적인 변수를 $categorical$이라고 부릅니다.

이번 챕터에서는 $classification$으로 알려진 정성적인 반응을 예측하는 방법에 대해 알아봅니다.



## 4.1 An Overview of Classification

회귀에서와 마찬가지로 분류에서도 분류기를 만드는데 사용할 수 있는 일련의 관측치가 존재합니다. 우리는 분류기가 트레이닝 데이터 뿐만 아니라 테스트에서도 잘 동작하기를 원합니다.

이번 챕터에서는 시뮬레이션된 체납 데이터 셋을 사용한 분류 개념을 설명합니다.

우리는 연간 수입과 월별 신용카드 잔액을 기준으로 개인이 신용카드 비용을 체납할 것인지 여부를 예측하는데 관심이 있습니다.

![4.1](/Users/devcat/git/blog/images/islr/4.1.png)

위 그림은 연간 수입과 카드 잔액에 대한 데이터의 일부를 나타낸 것입니다.

왼쪽 패널에는 주어진 달에 체납한 사람은 주황색, 그렇지 않은 사람은 파란색으로 나타냈습니다. 전체 체납률은 약 3% 이므로 체납을 하지 않은 사람중 극히 일부만 표시했습니다. 체납한 사람은 그렇지 않은 사람보다 신용카드 잔액이 더 많은 경향이 있습니다.

위 그림은 예측 변수 balance와 체납 사이에 매우 뚜렷한 관계를 나타낸다는 점에 주목해야 합니다. 실제 데이터에서는 이런 뚜렷한 관계가 잘 나타나지 않습니다. 그러나 이 챕터에서는 분류를 설명하기 위해 예측 변수와 반응 변수의 관계가 다소 과장된 예시를 사용합니다.



## 4.2 Why Not Linear Regression?

우리는 선형 회귀가 정성적 반응의 경우 적절한 케이스가 아니라고 얘기했습니다. 왜 그럴까요?

응급실에 있는 환자의 증상에 근거하여 환자의 상태를 예측한다고 가정합시다. 이 단순화된 예시에서는 뇌줄중, 약물 과다복용, 간질 발작의 세 가지 가능한 진단이 존재합니다. 이 세 가지 케이스를 정량적 반응 변수 $Y$로 인코딩 하면 다음과 같습니다.

$$Y = \begin{cases} 1\quad if\ stroke\\              2 \quad if\ drug\ overdose \\ 3\quad if\ epileptic\ seizure\end{cases}$$

이 코딩을 사용하면 예측 변수에 기반하여 $Y$를 예측하는 선형 회귀 모델을 피팅시키는데 최소 제곱법을 사용할 수 있습니다.

불행히도, 이 코딩은 뇌졸중과 발작 사이에 약물 과다 복용이 있고, 뇌졸중과 약물 과다 복용의 차이가 약물 과다 복용과 간질 발작의 차이와 같다고 주장합니다.

실제로 위와 같은 순서는 특별한 의미가 없습니다. 

반응 변수의 값이 경도, 중간, 심각과 같은 자연적인 순서를 따르고 변수 사이의 차이가 유사하다면 1, 2, 3으로 인코딩 하는 것이 합리적입니다.

일반적으로 세 수준 이상의 정성적 반응 변수를 선형 회귀에 대비한 정량적 반응으로 변환할 수 있는 자연스로운 방법은 없습니다.

바이너리의 경우는 더 낫습니다. 예를 들어, 환자의 상태가 두 가지만 존재한다면 (뇌졸중, 과다복용) 우리는 회귀 때 처럼 더미 변수 방식으로 접근할 수 있습니다.

$$Y = \begin{cases} 0\quad if\ stroke\\              1 \quad if\ drug\ overdose \end{cases}$$

그런 다음 선형 회귀에 적합 시키고 $\hat Y>0.5$이면 과다복용, 그렇지 않으면 뇌졸중이라고 예측할 수 있습니다. 위와 같이 0/1 코딩이 있는 바이너리의 경우 최소 제곱에 의한 회귀는 의미가 있습니다. 선형 회귀 분석을 사용하여 얻은 $X\hat \beta$가 $Pr(drug\ overdose\vert X)$의 추정치임을 알 수 있습니다.

그러나 선형 회귀 분석을 사용할 경우 추정치의 일부가 [0,1] 구간을 벗어날 수 있으므로 확률로 해석하기 어렵습니다. 그럼에도 불구하고 예측은 순서를 제공하며 대략적인 확률 추정치로 해석될 수 있습니다.

그러나 더미 변수 접근 방식은 세 수준 이상의 정성적 반응을 수용하도록 쉽게 확장할 수 없습니다. 이러한 이유로 다음에 제시되는 것과 같이 정성적 반응 값에 적합한 분류 방법을 사용하는 것이 바람직합니다.



## 4.3 Logistic Regression

다시 체납 데이터셋으로 돌아가봅시다. 반응 변수는 두 가지 카테고리를 갖습니다.(Yes or no) 이 반응 $Y$를 직접 모델화 하는 대신, 로지스틱 회귀에서는 $Y$가 특정 범주에 속할 확률을 모델화합니다.

예를 들어, balance가 주어졌을 때 체납의 확률은 다음과 같습니다.

$$Pr(default = Yes\vert balance)$$



### 4.3.1 The Logistic Model

$p(X) = Pr(Y=1\vert X)$와 $X$의 관계를 어떻게 모델링해야 할까요?

섹션 4.2에서 우리는 선형 회귀 모델을 사용하여 확률을 표현하는 방법에 대해 얘기했습니다.

$$p(X) = \beta_0 +\beta_1X\tag{4.1}$$

![4.2](/Users/devcat/git/blog/images/islr/4.2.png)



만약 우리가 이 접근법을 사용하여 체납 예측을 한다면 우리는 위 그림의 왼쪽 패널에 표시된 모델을 얻습니다. 여기서 우리는 문제점을 발견할 수 있습니다. balance가 0에 가까우면 우리는 음의 확률을 예측합니다. 또한 우리가 매우 큰 balance에 대해 예측한다면 1보다 큰 값을 얻게 됩니다.

물론 신용카드 잔액과 관계없이 체납의 진정한 확률은 [0,1]에 있어야 하기 때문에 이러한 예측은 타당하지 않습니다. 이 문제는 현재 데이터셋에서만 발생하는 문제가 아닙니다. 바이너리 반응 변수에 대한 직선은 언제나 $p(X)<0,\ p(X)>1$을 가질 수 있습니다.

이런 문제를 피하기 위해 우리는 모델 $p(X)$의 주어진 아웃풋을 [0,1]값으로 만들어야 합니다. 로지스틱 회귀에서 우리는 로지스틱 함수를 만듭니다.

$$p(X) = \frac{e^{\beta_0+\beta_1X}}{1+e^{\beta_0+\beta_1X}} \tag{4.2}$$

모델 4.2를 피팅시키기 위해 MLE를 사용하며 다음 섹션에서 이를 설명합니다.

오른쪽 패널이 로지스틱 회귀 모델을 데이터에 피팅시킨 것을 보여줍니다. 이제 balance가 낮을 경우 확률은 0에 가깝지만 0아래로 내려가진 않습니다. 높은 balance의 경우 1에 가깝지만 1을 넘지는 않습니다. 

로지스틱 함수는 S자 모양을 가집니다. 위 식을 약간 조정해서 다음과 같이 쓸 수 있습니다.

$$\frac{p(X)}{1-p(X)} = e^{\beta_0+\beta_1X}\tag{4.3}$$

$p(X)/[1-p(X)]$를 $odds$ 라고 부르고 값은 $[0,\infty]$ 의 구간을 갖습니다. 이는 매우 낮고, 높은 체납 확률을 나타냅니다. 승산은 일반적으로 경마에서 확률 대신 사용됩니다. 경마에서 승산은 올바른 베팅 전략과 더 자연스럽게 연관됩니다.

> 위 식의 직관적 의미는 사건 X가 발생하지 않을 확률 대비 발생할 확률입니다.
>
> 사건이 발생할 확률이 1에 가까울 수록 승산은 무한대로 올라갑니다.

식 4.3을 다음과 같이 조정할 수 있습니다.

$$log(\frac{p(X)}{1-p(X)}) = \beta_0+\beta_1X \tag{4.4}$$ 

식의 왼쪽 부분을 $log-odds\ or\ logit$이라고 부릅니다. 로지스틱 회귀 모델 4.2는 X에 선형인 logit이 있음을 알 수 있습니다.

3장으로 돌아가봅시다. 선형 회귀 모델에서 $\beta_1$은 $X$의 단일 단위 증가와 관련된 $Y$의 평균 변화를 나타냅니다. 대조적으로 로지스틱 회귀 모형에서 X의 단위 유닛 증가는 로그 승산이 $\beta_1$으로 변경되거나, 동등하게 $e^{\beta_1}$로 승산이 곱해집니다.

그러나, 4.2에서 $p(X)$와 $X$의 관계는 직선이 아니기 때문에 $\beta_1$이 $X$의 단일 유닛과 관련된 $p(X)$의 변화에 해당하지는 않습니다. 선형적인 관계도 없고, $X$의 단위 변경당 $p(X)$의 변화율이 현재 값에 따라 달라집니다. (위 그림의 오른쪽 패널 참조)



### 4.3.2 Estimating the Regression Coefficients

식 4.2의 계수 $\beta_0,\beta_1$은 알려지지 않았으므로 훈련 데이터를 통해 추정해야 합니다.

3장에서는 최소 제곱법을 통해 선형 회귀 계수를 추정했습니다. (비선형) 최소 제곱법을 사용하여 모델 4.4를 피팅시킬 수 있지만, 더 나은 통계 특성을 가지는 MLE가 더 선호됩니다.





