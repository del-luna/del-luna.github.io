---
layout: post
title: RCNN
author: Jaeheon Kwon
categories: Paper
tags: [detection]
---

#  Rich feature hierarchies for accurate object detection and semantic segmentation 

Object detection공부를 위해 처음 읽은 논문입니다.<br>

리뷰라기 보단 번역에 가깝고 뒤의 실험 결과 내용은 필요하지 않아 넣지않았습니다.<br>

## Abstract

R-CNN(Regions with CNN features)은 VOC-2012 이전의 SOTA 모델들에 비하여 mean average precision(mAP)를 약 30% 개선하여 53.3%를 달성했습니다.<br>

combine two key insights

1. high-capacity CNN
2. Supervised pre-training & domain-specific fine-tuning

<br>

## Introduction

이전에는 SIFT & HOG 방식을 많이 사용했습니다.(사람의 시각 피질 영역과 유사하며 연관 시킬 수 있음)<br>
그러나 SVM방식에 밀려 인기가 없었던 CNN이 ImageNet Challenge에서 우승한 AlexNet 이후로 다시 주목받기 시작했고,<br>

**CNN을 Object Detection에 적용할 수 없을까?** 라는 생각에서 출발합니다.<br>
그러나 AlexNet은 Image Classification을 위한 모델이고 Object Detection과 가장 큰 차이점은 **Object Detection은 Localizing이 필요합니다**.<br>

우리는 이 Localizing을 Regression 문제로 생각 할 수 있습니다.<br>

CNN이 HOG 알고리즘에 비해 더 좋은 성능을 갖기 위해 두 가지에 초점을 맞춥니다.<br>

1. Localizing Object
2. small quantity detection data로 high-capacity CNN을 학습함

그러나 실제로  C. Szegedy, A. Toshev, and D. Erhan. Deep neural networks for object detection 라는 논문에서 이 방식을 사용했지만 생각만큼 잘 동작하지 않음을 볼 수 있습니다.<br>

그래서 대안으로 이전의 CNN에서 많이 사용됐던 방식인 '**Sliding Window detector**' 를 구축합니다.<br>

(같은 VOC-2012에서 우승한 OverFeat라는 모델이 위의 방식을 통해서 우승 한 것으로 알고 있습니다.)<br>

그러나 Sliding Window방식 또한 Very Large receptive field(195x195)&Stride(32x32)가 필요합니다.(그리고 직관적으로 생각해도 이미지를 전부 훑어야 되니까 상당히 느립니다.)<br>

대신에, Object Detection & semantice segmentation 두 가지 모두에서 성공한 '**recognition using regions**'를 사용하여 CNN Localizing 문제를 해결합니다.<br>

Test time에서 input image에 대하여 2000개의 category-independent region를 생성 → CNN을 통해 각 region에서 고정 길이 feature vector를 추출 → 각 region을 category-specific linear SVM으로 분류합니다.<br>

간단한 테크닉(affine image wraping)을 사용하여 region shape에 관계없이 각 region proposal에서 고정 크기 CNN 입력을 계산합니다.<br>

<img src = "https://py-tonic.github.io/images/rcnn/1.PNG">

Lable data가 대규모 CNN을 훈련하기에 대부분 부족합니다. 이를 해결하기 위해선 어떻게 해야 할까요?<br>

Large auxiliary dataset(ILSVRC)에 대한 supervised pre-training과 소규모 데이터 셋(PASCAL)에 대한 domain-specific fine-tuning이 대규모 CNN을 학습하는 데 효과적임을 보여줍니다.<br>

우리의 실험에서 detection을 위한 fine-tuning은 mAP 성능을 8% 향상 시킵니다.<br>

## Object detection with R-CNN

우리의 Object detection 시스템은 3개의 모듈로 구성됩니다.<br>

1. category-independent region proposals를 생성(detector에 사용 가능한 후보 set을 정의)
2. each region에서 고정 길이 feature vector를 추출하는 CNN
3. class-specific linear SVM

이번 섹션에서는 각 모듈에 대한 설계를 제시하고, 파라미터를 학습하는 방법을 자세히 설명합니다.<br>

### Module design

**Region proposals**.

최근 다양한 논문은 category-independent region proposals를 생성하는 방법을 보여줍니다.<br>

R-CNN은 특정 region proposals와 무관하지만 selective search(비슷한 질감이나 색, 강도를 가진 인접한 픽셀들을 연결하여 b-box를 구성하는 방법)을 사용하여 prior detection work와 비교를 제어할 수 있습니다.<br>

이 방법으로 생성한 b-box의 output을 다시 CNN layer의 input으로 활용하고, input으로 변환하는 과정에서 warping합니다.<br>

**Feature extraction**.

AlexNet을 기반으로 하여 각 region proposals에서 4096 차원의 feature vector를 추출합니다.<br>

5개의 conv layer와 2개의 fcn을 통해 mean-subtracted 227x227 RGB image를 앞으로 전파하여 feature를 계산합니다.<br>

region proposals에 대한 feature를 계산하려면 먼저 해당 region의 이미지 데이터를 CNN과 호환되는 형식으로 변환해야 합니다.(아키텍처에는 고정된 227x227 픽셀 크기 입력이 필요)<br>

warping전에 b-box를 확장하여 warped size에서 원래 상자 주위에 정확히 p pixels의 warp image context가 있도록 합니다.(p=16)<br>

### Test-time detection

test time에 test image에서 selective search를 실행하여 약 2000개의 region proposals를 추출합니다.<br>

각 proposals를 CNN의 input으로 사용하기 위해 wrap합니다.<br>

각 클래스에 대해 훈련된 SVM을 사용하여 추출된 feature vector의 점수를 매깁니다.<br>

이미지의 모든 점수가 매겨진 영역이 주어지면 greedy non-maximum supression(각 클래스에 대해 독립적인)을 적용합니다.<br>

두 가지 속성으로 인해 Detection은 효율적입니다.<br>

1. 모든 CNN 파라미터가 모든 카테고리에서 공유됩니다.<br>
2. CNN에 의해 계산된 벡터는 BOW인코딩을 가지는 spatial pyramids와 같은 다른 일반적인 접근법과 비교할 때 저차원 입니다.<br>

이러한 공유의 결과로 region proposals & feature를 계산하는데 소요된 시간이 모든 클래스에서 상환 됩니다.<br>

유일한 클래스 별 계산은 feature와 SVM 가중치 사이의 내적 및 non-maximum suppression입니다.<br>

