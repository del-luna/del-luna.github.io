---
layout: post
title: Machine Learning Introduction
author: Jaeheon Kwon
categories: Ai
tags: [ML]
---

# Curve Fitting



PRML에 나오는 내용을 정리한 것입니다.

확률과 통계 부분에 대한 설명은 수학적 백그라운드가 없이 작성했기 때문에 틀린 내용이 있을 수 있습니다.



목표 : 실수 범위 $x$를 관찰 후 이 관찰 값을 바탕으로 실수 범위의 타겟 $t$를 예측하고 싶다.

쉽게 말하면 데이터를 바탕으로 데이터들을 가장 잘 표현할 수 있는 식을 찾는 것이 우리의 목표이다.

타겟 $t$가 함수 $sin(2\pi x)$로 부터 발현되는 실수 값이라고 가정하자.(노이즈를 포함)

<img src = "https://py-tonic.github.io/images/curve/Figure1.2.png">

파란색 원이 우리가 가진 데이터이다.

그런데 파란색 원만 가지고 초록색 선을 예측하는 것은 매우 힘든 일이다.

우리가 해야할 일을 좀 더 구체적으로 명시해보자.

학습 데이터를 이용하여 모델을 근사 후 임의의 데이터 $\hat x$에 대해 예측 결과 $\hat t$를 제공해 주어야 한다.



## Polynomial

<hr>



근사 식의 종류엔 다양한 식이 있지만 우린 테일러 급수를 사용해 보자.

$$y(x,w) = w_0 + w_1x + w_2x^2 + ... + w_Mx^M = \sum\limits_{j=0}^M w_jx^j \tag{1}$$



일반적인 테일러 급수는 차수 $M$값을 늘릴 수록 특정 위치(지점)에서 더 잘 맞는 근사식을 만들어 낼 수 있다.

하지만 우리가 하고자 하는 목적과는 약간 다르다.

우리는 최대한 모델을 일반화 하여 강건한 모델을 만들어 내는 것이 목적이다.



> M을 늘리면 학습용 데이터에 대해서 아주 잘 맞는 근사식을 만들어 낼 수 있지만,
>
>  우리는 새로운 데이터에 대해서도 그 식이 적용되길 바란다.

이제 문제는 고정된 $M$값 내에서 가장 적합한 $w$를 구하는 문제로 전환된다.

식을 근사하기 위해 최적의 계수 $w$를 도입해야 하는데 보통 이런 문제는 에러 함수를 도입하여 문제를 해결한다.

모델로 부터 도출된 $y(x,w)$함수와 실제 타겟 값 $t$의 차이를 최소화 하는 방식을 통해 $w$값을 결정할 수 있다.

 그리고 이 때, 에러 함수는 보통 제곱합(sum-of-squares)를 사용한다.

변위의 합이 아닌 변위의 제곱 합을 사용하는 이유?

- $y$함수가 **convex**를 만족하는 경우 에러 함수도 convex를 만족하는 함수가 되고 미분 가능하게 된다.
- 에러 함수를 $w$에 대해 단순 미분하면 최소화 문제에서 유일한 해를 가지게 된다.

$E(w) = \frac{1}{2} \sum\limits_{n=1}^{N} \{y(x_n,w)-t_n\}^2 \tag{2}$

- 1/2는 미분 편하려고 적은 것.



<img src = "https://py-tonic.github.io/images/curve/Figure1.3.png

이제 이 함수 근사 문제를 $E(w)$ 값을 최소로 만드는 $w$를 구하는 문제로 생각하면 된다.

정의된 에러 함수가 $w$에 대해 **quadratic**의 함수 꼴이므로 이를 최소화 하는 값은 유일해를 가지게 됨을 보장받는다.

유일해를 가질 때의 $w$의 값을 $w^*$라고 하자.

따라서 이 때 얻어지는 함수 값은 $y(x,w^*)$가 된다.

- 원래 $y$함수는 $x$와 $w$에 대한 함수이지만 학습 데이터를 통해 $w$를 $w^*$로 고정하면
- $y$함수는 결국 단일 변수 $x$에 대해서만 처리되는 함수라고 생각할 수 있다.



## Likelihood in Frequentist

<hr>

빈도론적 관점에서는 $\mathbf{w}$는 알려지지 않은 고정된 파라미터 값이다.(그리고 이를 추정한다.)

Maximum Likelihood가 대표적인 estimator로 보통 $p(D\vert \mathbf w_{ML})$를 최대로 만드는 $\mathbf w_{ML}$를 구한다.

$\mathbf{w}_{ML}$은 고정된 값이지만 알려져 있지 않기 때문에 데이터로 부터 추정해야 한다.

머신러닝 분야에선 보통 log-likelihood 방식을 사용한다.



## Likelihood in Bayesian

<hr>

파라미터 $\mathbf{w}$를 랜덤 변수로 간주하여 확률 분포로 사용한다.

> 베이지안적 관점의 핵심은 발생하지 않은 사건에 대해서도 확률 변수로 생각 하여 문제를 해결한다는 것이다. ex: 이번 세기에 북극의 얼음이 녹을 확률
>
> 사전 확률 모델을 작성하고 일부 측량 정보를 통해 사후 확률을 보정하는 방식을 취한다.

따라서 $\mathbf{w}$는 고정된 값으로 얻어지는 것이 아니라 확률 함수 등으로 얻어지게 된다.

물론 실제 사용시에는 얻어진 확률 함수의 평균이나 최빈값 등을 고정된 값으로 사용할 수도 있다.(MAP를 떠올려 보라.)

$\mathbf{w}$가 확률 분포 이므로 사전(prior)지식을 자연스럽게 포함할 수 있다.

MLE에서는 동전을 3번 던져 앞면이 모두 나온 경우 파라미터 $\theta$값이 그냥 1이 되지만,

베이지안 방식에서는 사전 확률로 인해 이 값이 보정된다.

따라서 빈도론자 보다 덜 극단적인 결과를 얻을 수 있다.



기본적으로 최적의 $\mathbf{w}$를 얻는다는 건 같지만 polynomial 방식과 통계론적 방식의 차이가 있음을 알 수 있다.



