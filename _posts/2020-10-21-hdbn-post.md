---

---





## Abstract

BN은 빠르고 안정적으로 DNN을 학습시킬 수 있게 해줍니다. 그러나 BN의 인기에도 불구하고, 왜 잘 동작하는지에 대한 이유는 아직 잘 알려져 있지 않습니다.

대부분은 기존 논문에 언급한대로, 'internal covariate shift'를 줄이기 위해 훈련중에 레이어의 입력 분포를 제어하는 데서 비롯된다라고 믿습니다.

논문에서는 레이어의 입력에 대한 분산을 컨트롤 하는 것이 BN의 성공과 거의 관련이 없음을 보여줍니다.

대신, 훈련 과정에 대한 BN의 더 근본적인 영향을 발견합니다 최적화 환경(landscape)을 훨씬 더 매끄럽게 만듭니다.

이러한 변화는 그래디언트를 예측 가능하고 더 안정적으로 동작하도록 유도하여 더 빠른 훈련을 가능케합니다.



## Introduction

BN은 레이어의 입력 분포를 안정화하여 신경망 훈련을 개선하는 것을 목표로 하는 기술입니다.

이러한 분포의 처음 두 모멘트(mean, var)를 제어하는 추가 네트워크 층을 도입해서 사용합니다.

BN이 ISC를 해결함으로써 퍼포먼스의 향상을 이뤄냈다고 널리 받아들여지고 있지만, 이를 뒷받침하는 구체적인 증거가 딱히 존재하지 않습니다. 여전히 ISC와 트레이닝 퍼포먼스 사이의 연관성을 이해하지 못합니다.

시작점은 성능 향상과 ISC 이동의 감소 사이에 어떤 연관성이 없다는 것을 증명하는 것입니다. 사실 어떤 의미에서 BN은 ISC를 줄이지 않을 수도 있습니다.

그런 다음 BN 성공의 근본 원인을 파악하는데 집중합니다.

특히 BN이 기본적인 방식으로 네트워크 교육에 영향을 미친다는 것을 보여줍니다. 이는 해당 최적화 문제의 환경을 훨씬 더 매끄럽게 만듭니다.(앞서 언급) 이러한 smooth는 그래디언트를 예측 가능하고 더 안정적으로 동작하도록 유도하여 더 빠른 훈련을 가능케합니다.

우리는 이러한 발견과 이론적 정당성에 대한 경험적 증명을 제공합니다.

우리는 기본 조건에서 손실과 그래디언트($\beta-smoothness$ 라고도 불리는 )모두 Lipschitzness가 BN을 사용하는 모델에서 향상된다는 것을 증명합니다.

(We prove that, under natural conditions, the Lipschitzness of both the loss and the gradients (also known as β-smoothness [21]) are improved in models with BatchNorm)

- natural condition ?
- Lipschitzness?
- $\beta-smoothness$?



마지막으로, 이 smooth의 효과는 BN과 고유하게 연결되지 않습니다.

다른 많은 자연 정규화 기술은 유사한(때로는 더 강력한)효과를 가지고 있습니다. 특히 그들은 모두 트레이닝 퍼포먼스에서 유사한 개선을 제공합니다.

우리는 BN과 같은 기본 기술의 뿌리를 이해하면 신경망 훈련의 근본적인 복잡성을 훨씬 더 잘 이해할 수 있고 이 맥락에서 알고리즘 발전을 더 많이 알릴 수 있을 것이라고 믿습니다.



## Batch normalization and internal covariate shift

일반적으로 BN은 훈련중에 레이어에 대한 입력 분포(미니 배치를 통해)를 안정화 하는 것을 목표로 하는 메커니즘입니다.

앞서 말했듯, BN의 주요 개발 동기중 하나는 ICS의 감소였고, 이런 변화가 훈련과정에 해로운 영향을 미치는 것으로 여겨졌습니다.

> 이전 레이어의 파라미터 업데이트로 인한 네트워크 레이어의 입력 분포가 변경되는 현상

논문에서는 ISC와 BN간의 연관성을 조사합니다. 특히, BN을 사용하거나 사용하지 않고 CIFAR-10에서 표준 VGG 아키텍처를 학습합니다.

<img src = "https://py-tonic.github.io/images/hdbn/1.png">



당연하게도 BN을 사용한 모델의 퍼포먼스가 크게 향상되었음을 볼 수 있습니다.

위 그림의 오른쪽 패널은 임의의 입력 분포(배치에 대한)를 플로팅 하여 레이어 입력 분포를 시각화 한 것 입니다. 보면 알겠지만 분포의 안정성에 대해서는 별 차이가 없는 것 같습니다. 위를 통해 두 가지 의문점이 발생합니다.

- BN이 ISC와 관련이 있는 것이 맞는가?
- BN의 레이어 입력 분포의 안정화는 ICS를 줄이는 데도 효과적인가?



### Does BatchNorm's performance stem from controlling internal covariate shift?

기존의 핵심 주장(ICS의 감소)은 레이어 입력 분포의 평균과 분산을 제어하는 것이 훈련 성능 향상과 직접적으로 연결되어 있다는 것입니다. 그러나 이 주장을 입증할 수 있을까요?

BN 레이어 뒤에 무작위 노이즈가 추가된 네트워크를 훈련시키는 실험을 해봅시다. 이러한 노이즈의 주입은 모든 스텝에서 활성화를 왜곡하는 심각한 ICS를 유발합니다. 결과적으로 레이어의 모든 유닛은 각 타입 스텝에서 다른 입력 분포를 경험합니다. 

이후 의도적으로 주입한 불안정성이 BN의 성능에 미치는 영향을 측정합니다. 아래 그림은 표준 아킽텍처, BN 및 '노이즈가 있는' BN의 트레이닝을 시각화 합니다.

<img src = "https://py-tonic.github.io/images/hdbn/2.png">

결론은 BN레이어의 모델과 '노이즈를 포함한' BN 레이어를 포함한 모델 간의 성능은 거의 존재하지 않으며 둘 다 표준 네트워크에 비해 성능이 훨씬 뛰어납니다. 비록 '노이즈를 포함한' BN 네트워크가 덜 안정적인 분포를 가질지라도 훈련 측면에서 더 나은 성능을 보입니다.

이러한 결과는 BN으로 인한 성능 향상이 레이어 입력 분포의 안정성 증가에서 비롯된다는 주장과 일치하기 어렵습니다.



### Is BatchNorm reducing internal covariate shift?

앞선 섹션에서 ICS가 훈련 성능과 직접적으로 연결되지 않음을 보았습니다. 그러나 여전히 궁금한 점은 훈련 성능에 직접적으로 미치는 어떤 효과가 BN으로 인해서 발생한다는 점입니다. '어떤 효과' 가 BN으로 인해서 모델의 훈련 성능을 향상시킬까요?

각 레이어는 입력이 주어지면 일부 손실 함수를 최적화 하는 경험적 위험 최소화 문제(empirical risk minimization)를 해결하는 것으로 볼 수 있습니다.(뒤의 레이어를 포함할 수 있음)

> Empirical risk는 딥러닝에서 Cost라고 생각하면 됩니다.
>
> training set에서 Loss의 평균을 구해 risk를 근사한 것. risk를 최소화하는 대신 empirical risk를 최소화하는 $\hat f$를 찾는 것
>
> risk는 $R(f)=E[L(f(x),y)]$ 즉 ,loss function의 기댓값으로 정의할 수 있는데, 확률 변수 $X,Y$를 표현하기 위한 결합확률분포함수가 필요한데 $P(X,Y)$를 알 수 없으므로 근사해서 문제를 푸는 것.
>
> [출처: JIMIN](https://jiminsun.github.io/2018-04-30/erm/)

이전 레이어의 파라미터를 업데이트하면 이러한 입력이 변경되므로 경험적 위험 최소화 문제 자체가 변경됩니다. 이런 현상이 기존의 ICS의 감소를 통해 BN의 성능 향상을 주장하는 직관의 핵심입니다.(그러나 이게 아닌 것임을 이전 섹션에서 밝혔습니다.)

이 질문에 대답하기 위해 기본 최적화 작업과 더 밀접한 ICS에 대한 더 넓은 개념을 고려합니다.(결국 BN 성공의 대부분은 최적화 특성입니다.)

훈련 절차는 first-order method이므로 loss의 그래디언트에 관심을 가져 봅시다. 이전 레이어의 파라미터 업데이트에 대한 반응으로 레이어의 파라미터가 '조정'되어야 하는 정도를 정량화 하기 위해 모든 이전 레이어에 대한 업데이트 전후의 레이어 그래디언트간의 차이를 측정합니다.

**Deifinition 2.1**

$\mathcal L$을 loss, $W_1^{(t)},...,W_k^{(t)}$를 각 레이어의 파라미터, $(x^{(t)},y^{(t)})$를  시간 $t$에서 네트워크를 훈련시키는 데 사용되는 인풋-레이블 쌍의 배치라고 합시다.

시간 $t$에서 활성화 $i$의 ICS를 $\vert\vert G_{t,i}-G'_{t,i}\vert\vert_2$의 차이로 정의합니다.

$$G_{t,i} = \nabla_{w_i^{(t)}}\mathcal L(W_1^{(t)},...,W_k^{(t)};x^{(t)},y^{(t)})\\ G'_{t,i}=\nabla_{w_i^{(t)}}\mathcal L(W_1^{(t+1)},...,W_{i-1}^{(t+1)},W_i^{(t)},W_{(i+1)}^{(t)},...,W_k^{(t)};x^{(t)},y^{(t)})$$

$G_{t,i}$는 모든 레이어를 동시에 업데이트하는 동안 적용될 레이어 파라미터의 기울기에 해당합니다.(즉, 시점 $t$에서 $i$번째 레이어의 그래디언트이며, $W_i^{(t)}$에 대한 loss function의 derivative )

반면에 $G'_{t,i}$는 모든 이전 레이어가 새 값으로 업데이트 된 후 동일한 그래디언트입니다.

따라서 $G,G'$의 차이는 입력의 변경으로 인한 $W_i$의 최적화 환경의 변화를 반영합니다. 따라서 훈련에 문제가 될 수 있는 레이어 간 종속성의 효과를 정확하게 포착합니다.

위 정의를 사용하여 BN레이어가 있거나 없는 ICS의 범위를 측정합니다. BN에 대한 기존의 이해는 네트워크에 BN을 추가하면 $G$와 $G'$의 상관 관계가 증가하여 ICS를 줄여야 함을 시사합니다. 놀랍게 BN을 사용하는 네트워큰느 종종 ICS의 증가를 나타냅니다 이것은 특히 DLN(deep linear network)의 경우 두드러집니다.

<img src = "https://py-tonic.github.io/images/hdbn/3.png">

실제로 이 경우 표준 네트워크는 학습시 ICS를 거의 경험하지 않는 반면 BN의 경우 $G$와 $G'$은 거의 상관관계가 없는 것으로 보입니다.

우리는 BN네트워크가 달성된 정확도와 손실 측면에서 계속해서 훨씬 더 나은 성능을 발휘하더라도 ICS의 감소와는 관련이 없다는 것을 강조합니다.(최적화의 관점에서)



## Why does BatchNorm work?

