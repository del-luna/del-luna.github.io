---
layout: post
title: VGG
author: Jaeheon Kwon
categories: Papers
tags: [vision]
---

#  VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION



## Implementation

[Github](https://github.com/jaeheondev/CNN_cifar_pytorch)

## Abstract

이 논문에서는 대규모 이미지 인식을 위한 CNN이 깊이에 따라 정확도가 어떻게 달라지는지 알아볼 것 입니다.<br>

우리는 아주 작은 (3x3) convolution filters를 사용하여 네트워크의 깊이를 16~19개의 가중치를 갖는 레이어로 구성합니다.<br>

이러한 구조를 통해 ImageNet Challenge 2014에서 localization & classification 분야에서 각각 1,2등을 차지했습니다.<br>

또한 다른 데이터를 통해서 SOTA에 도달하여 일반화가 가능한 것을 보여줍니다.<br>

## Introduction

ConvNet이 컴퓨터 비젼 분야에서 필수적인 요소가 되어서 기존의 아키텍쳐를 향상시키기 위한 노력들이 많이 있었습니다.<br>

예를 들어, ILSVRC2013에서 가장 우수한 성과를 내었던 모델은 더 작은 receptive filed와 first convolutional layer의 stride를 활용했습니다.<br>

이 논문에서는 ConvNet 아키텍쳐 디자인의 또 다른 중요한 측면인 깊이에 대해서 다룹니다.<br>

이를 위해 우리는 아키텍쳐의 다른 파라미터를 수정하고 더 많은 convolutional layer를 추가하여 네트워크의 깊이를 꾸준히 증가시킵니다.<br>

이는 모든 레이어에서 매우 작은 (3x3) convolution filters를 사용하기 때문에 실현 가능합니다.<br>

결과적으로 우리는 ILCVRC에서 SOTA를 달성했을 뿐만 아니라 다른 이미지 인식 데이터 셋에서도 적용할 수 있는 더 정확한 ConvNet 아키텍쳐를 찾아냈습니다.<br>

## ConvNet Configurations

동일한 환경에서 ConvNet의 깊이 증가로 인한 성능 향상을 측정하기 위해 모든 레이어의 구성은  AlexNet에서 영감을 받았습니다.<br>

### Architecture

훈련하는 동안 ConvNet의 입력은 224x224 RGB 이미지로 고정됩니다.<br>

유일한 전처리는 각 픽셀에서 훈련 세트에서 계산 된 평균 RGB 값을 빼는 것입니다.<br>

이미지는 Conv layers를 통과합니다.<br>

우리는 앞서 말했듯이 아주 작은 receptive field를 가진 필터를 사용합니다.<br>

(3x3)은 (왼쪽/오른쪽, 위/아래, 가운데 개념을 포착하기 위한 가장 작은 크기)<br>

모델의 구성중에서 1x1 Conv filters를 볼 수 있는데, 이는 입력 채널의 선형 변환으로 볼 수 있습니다.(비 선형이 뒤따릅니다.)<br>

stride는 1로 고정됩니다.<br>

레이어의 입력은 Conv 연산 후 공간 해상도가 유지되도록 패딩은 3x3 Conv에 대하여 1pixel 입니다.<br>

공간 풀링은 5개의 Max pooling layer에 의해 수행되며, 이는 일부 Conv layer뒤에 놓여집니다.<br>

Max pooling은 stride값이 2인 2x2 pixel window에서 수행됩니다.<br>

Convolution layer stack(다른 아키텍쳐에서 서로 다른 깊이를 갖는) 뒤에는 3개의 FCN이 있습니다.<br>

처음 2개는 각각 4096개의 채널을 가지며 세 번째 레이어는 1000가지 클래스 분류(ImageNet)를 해야 하므로 1000개의 채널을 갖습니다.<br>

마지막 레이어는 softmax layer입니다. FCN의 구성은 모든 네트워크에서 동일합니다.<br>

모든 히든 레이어에는 ReLU를 사용합니다.<br>

우리는 한 가지 네트워크에만 LRN 정규화를 사용합니다.<br>

LRN은 ILCVRC 데이터 셋의 성능을 향상시키지도 않고 메모리 소비 및 계산 시간을 증가시킵니다.<br>

LRN을 적용한 네트워크에는 AlexNet의 파라미터를 사용합니다.<br>

### Configurations

###  <img src = "https://py-tonic.github.io/images/vgg/0.png">

### Discussion

우리의 ConvNet 구성은 이전의 ILCVRC 2012 & 2013에서 SOTA 모델과는 상당히 다릅니다.<br>

첫 번째 Conv layer에서 비교적 큰 receptive field를 사용하는 대신 (2012 모델은 11x11 & stride 4, 2013 모델은 7x7 & stride 2)에 우리는 매우 작은  3x3필터(stride = 1)를 사용합니다.<br>

2개의 3x3 필터는 5x5 필터와 같은 유효 receptive field를 가지며, 3개의 경우 7x7과 같습니다.<br>

그래서 우리는 이를 통해(단일 n x n 레이어가 아닌 3x3의 스택을 통하여) 무엇을 얻을 수 있을까요?<br>

먼저, 단일 필터 대신 3개의 비 선형 rectification layers를 통합하여 decision function을 더욱 차별화 합니다.<br>

또한 우리는 파라미터의 수를 줄입니다.<br>

3개의 3x3 conv 스택의 입력과 출력에 모두 C 채널이 있다고 가정하면  스택은 $3(3^2C^2) = 27C^2$의 가중치로 파라미터화 합니다.<br>

반면 7x7 단일 conv의 경우 $7^2C^2 = 49C^2$ 가 나와서 81% 이상의 많은 파라미터를 요구합니다.<br>

이 것은 7x7 conv에 정규화를 부과하는 것으로 볼 수 있습니다.  (with non-linearity injected in between)<br>

1x1 conv의 통합(Table.1_C)은 conv layer의 receptive field에 영향을 미치지 않으면서 decision function의 비 선형성을 증가시키는 방법입니다.(위에서 1x1 conv 뒤에 비 선형이 뒤따른다고 했으니까...?)<br>

우리의 구조에서 1x1 conv는 본질적으로 동일한 차원 공간에 linear projection 이지만(입력 및 출력 채널 수는 동일) rectification function(activation)에 의해 추가적인 non-linearity가 발생합니다.<br>

## Classification Framework

### Training

ConvNet 교육 절차는 일반적으로 AlexNet의 과정을 따릅니다.<br>

즉 학습은 momentum과 함께 미니 배치 gradient descent를 사용하여 다항 로지스틱 회귀를 최적화 함으로써 수행됩니다.<br>

batch_size = 256, momentum = 0.9로 설정되었습니다.<br>

학습은 weight decay($L_2$Penalty 는 $5*10^{-4}$로 설정)와 처음 두 개의 fcn layers에 대한 드롭 아웃 정규화(dropout ratio = 0.5)에 의해 정규화 되었습니다.<br>

Learning rate는 초기에 $10^{-2}$로 설정한 뒤 validation set 정확도가 올라가지 않으면 10배 감소했습니다.<br>

전체적으로 Learning rate가 3배 감소했으며 370K 반복(74epochs)후에 학습이 중단 되었습니다.<br>

AlexNet에 비해 더 많은 수의 파라미터에도 불구하고 정규화와 작은 conv fliter 및 특정 층의 사전 초기화로 인해 수렴에 필요한 epochs이 더 적었다고 생각합니다.<br>

네트워크 가중치 초기화는 중요합니다.<br>

잘못된 초기화는 기울기 불안정으로 인해 학습이 중단될 수 있습니다.<br>

이 문제를 피하기 위해 랜덤 초기화로 학습할 수 있을 정도로 얕은 구성 A(Table_1)를 교육하는 것으로 시작했습니다.<br>

그런 다음 더 깊은 구조를 학습할 때 첫 4개의 conv layer와 마지막 3개의 FCN layer를 layer of net A로 초기화 했습니다(중간 레이어는 임의로 초기화 되었습니다.)<br>

사전 초기화 된 레이어에 대한 learning rate를 줄이지 않아 학습 중에 변경될 수 있습니다.<br>

랜덤 초기화의 경우 mean = 0 , var = $10^{-2}$인 정규분포에서 샘플링 했습니다.<br>

bias 는 0으로 초기화 했습니다.<br>
고정 크기 224x224 ConvNet 입력 이미지를 얻기 위해 크기가 조정된 학습 이미지 (SGD 반복 당 하나의 crop image)에서 임의로 자릅니다.<br>

트레이닝 셋을 더욱 보강하기 위해 랜덤 수평 뒤집기와 무작위 RGB 색상 이동을 거쳤습니다.<br>

Training scale = 'S'<br>

자르는 크기는 224x224로 고정되어 있지만 원칙적으로 S는 224 이상의 값을 취할 수 있습니다.<br>

S는 두가지 설정값을 가질 수 있습니다.<br>

첫 째는 single-sclae training에 해당하는 S가 고정된 값입니다.<br>

우리의 실험에서 우리는 두가지 고정 척도(S = 256(기존의 Krizhevsky) 와 S = 384)로 모델을 평가했습니다.<br>

ConvNet 구성이 주어지면 먼저 S = 256을 사용하여 네트워크를 학습했습니다.<br>

S = 384 네트워크의 훈련 속도를 높이기 위해 S=256으로 사전 훈련된 네트워크로 가중치 초기화 했으며 낮은 lr ($10^{-3}$)을 사용했습니다.<br>

S를 설정하는 두 번째 방법은 mulit-scale training 입니다.<br>

여기서 각 트레이닝 이미지는 특정 범위[Smin(256), Smax(512)]에서 S를 무작위로 샘플링하여 개별적으로 크기를 조정합니다.<br>

이미지는 크기가 다를 수 있으므로 훈련중에 이것을 고려하는 것이 좋습니다.<br>

scale jittering에 의한 트레이닝 셋의 확대로도 볼 수 있습니다.<br>

속도상의 이유로 동일한 구성으로 single scale 모델의 모든 레이어를 finetuning하여 고정 scale S = 384로 사전 학습함으로써 multi-scale 모델을 학습했습니다.<br>

### Testing

테스트 타임에 훈련된 ConvNet 및 입력 이미지가 제공되면 다음과 같이 분류됩니다.<br>

Test Scale = 'Q'<br>

테스트 이미지를 미리 정한 Q로 크기 조절을 합니다.<br>

Q와 S는 반드시 같을 필요는 없습니다.(각 S에 대해 여러 Q의 값을 사용하여 성능을 향상시킬 수 있습니다.)<br>

그런 다음 리 스케일링된 테스트 이미지에 네트워크가 Sermanet과 유사한 방식으로 촘촘하게 적용됩니다.<br>

즉 FCN layer는 먼저 conv layer(첫 번째 FC layer를 7x7 conv layer로 변환하고 마지막 두 FC layer를 1x1 conv layer로 변환)로 변환합니다.<br>

결과적으로 fully-convolutional net이 전체(자르지 않은)이미지에 적용됩니다.<br>

출력은 입력 이미지 크기에 따라 클래스 수와 동일한 채널 수 및 가변공간 해상도를 가진 클래스 점수 맵입니다.<br>

마지막으로 이미지에 대한 클래스 크기의 고정 크기 벡터를 얻기 위해 클래스 점수 맵은 공간 평균 입니다.<br>

또한 이미지를 수평으로 뒤집어 테스트 셋을 보강합니다.<br>

원본 및 뒤집힌 이미지의 soft-max class posterior는 평균화 되어 이미지의 최종 점수를 얻습니다.<br>

fully-convolutional network가 전체 이미지에 적용되므로 테스트 타임에 여러 crops를 샘플링할 필요가 없어서 Krizhevsky의 모델보다 효율성이 높습니다.<br>

동시에 입력 이미지에 대한 미세한 샘플링으로 인해 정확도가 향상될 수 있습니다.(하지만 실제로 mulit-crops에 따른 계산량 증가가 정확도에 영향을 미치는지는 불분명합니다.)<br>

또한 mulit-crop evaluation는 다양한 conv 경계 조건으로 인해 dense evaluation에 보완적입니다.<br>

crop에 ConvNet을 적용 할 때 복잡한 feature map에 0이 채워지며 dense evaluation의 경우 동일한 crop에 대한 패딩이 자연스럽게 나타납니다.<br>

이미지의 인접 부분에서(conv와 spatial pooling으로 인해) 전체 네트워크 수용 필드를 실질적으로 증가시켜 더 많은 context가 캡처 됩니다.<br>

