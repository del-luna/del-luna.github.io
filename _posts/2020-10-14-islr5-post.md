---
layout: post
title: ISLR chapter.5
author: Jaeheon Kwon
categories: Ai
tags: [islr]
---

리샘플링은 근대 통계학에서 필수적인 방법입니다. 이는 모델에 대해 추가정보를 얻기 위해 트레이닝 세트에서 반복적으로 샘플을 추출하고, 각 샘플에 대해 모델을 피팅시켜 보는 것입니다.

하나의 트레이닝 세트에 대해 많은 샘플을 뽑아보고, 거기에 선형 회귀 모델을 피팅시켜봅니다. 이를 통해 기존에 한 번 피팅시켰을 때 할 수 없었던 우리 모델이 데이터가 달라짐에 따라 어느정도 범위에 존재할 것 인지를 평가할 수 있습니다.

이번 챕터에서는 가장 흔한 리샘플링 방법인 Cross-validation과 bootstrap에 대해서 다룹니다.

예를 들어, 교차 검증은 성능을 평가하거나 적절한 수준의 유연성을 선택하기 위해 주어진 통계적 학습 방법과 관련된 테스트 오류를 추정하는데 사용할 수 있습니다.

부트스트랩은 여러 맥락에서 사용되며, 가장 일반적으로 파라미터 추정 또는 주어진 통계 학습 방법의 정확도를 측정하기 위해 사용됩니다.



## 5.1 Cross-Validation

앞선 챕터에서 훈련 오류율과 테스트 오류율을 구분해서 다뤘습니다. 

지정된 테스트 셋을 사용할 수 있다면 테스트 오류율을 계산하는 것은 매우 쉬운 문제이지만 대부분은 존재하지 않습니다. 또한 트레이닝 오류율은 종종 테스트 오류율과 상당히 다르며, 특히 트레이닝은 테스트를 과소평과 하는 경향이 있습니다.

테스트 오류율을 측정하기 위한 테스트  셋이 없는 경우 사용 가능한 학습 데이터를 사용하여 추정할 수 있습니다. 일부 방법은 테스트 오류율을 추정하기 위해 훈련 오류율을 수학적으로 조정합니다.(몇몇 접근 방법은 6장에서 다룹니다.)

여기서는 holdout을 사용하여 테스트 오류율을 직접 추정하는 방법을 다룹니다.



### 5.1.1 The Validation Set Approach

가장 쉬운 접근 방법은 말그대로 '랜덤하게' 반으로 나누는 것입니다.

<img src = "https://py-tonic.github.io/images/islr/5.1.png">

모델은 반으로 나눈 트레이닝 세트로 피팅시키고, 나머지 절반인 검증 세트로 반응변수를 예측하는데 사용합니다. 검증 세트의 오류율(일반적으로 반응 변수가 정량적일 경우 MSE를 사용)은 테스트 오류율에 대한 추정치를 제공합니다.

하지만 이 방법은 절반을 자른다는 점에서 단점이 존재합니다. 데이터 셋을 어떻게 반으로 자르느냐에 따라 모델의 분산이 심해지고, 그에 따라 테스트 오류율에 대한 추정치도 심하게 변화하기 때문입니다.

<img src = "https://py-tonic.github.io/images/islr/5.2.png">

앞서 3장의 회귀분석에서 다항회귀 예시를 가져와 데이터를 반으로 자른 뒤 검증 세트로 에러율을 추정한 결과입니다. 보면 알겠지만 상당히 분산이 심한 것을 알 수 있습니다.

절반의 트레이닝 세트를 사용하기 대문에 전체 자료로 적합하였을 경우 모델이 가지는 test MSE보다 클 수 밖에 없습니다. 즉, 테스트 에러율을 과대추정하게 됩니다.



### 5.1.2 Leave-One-Out Cross-Validation

절반을 나눠서 검증용으로 빼는건 너무 과하니까 관측치에서 한개만 빼서 검증용으로 사용하면 어떨까? 라는 생각이 LOOCV입니다.(CV를 먼저 배우고 책을 읽는 입장에서 굉장히 극단적이라고 생각이 드네요..)

$n-1$개의 관측치에 대해 모델을 피팅시키고 빼놓은 한 개의 검증용 데이터에 대해 예측을 수행합니다.

<img src = "https://py-tonic.github.io/images/islr/5.3.png">



$(x_1,y_1)$을 빼놨다고 가정해봅시다.

$(y_1-\hat y_1)^2$은 '거의' 불편추정량입니다. 

> n-1개의 데이터를 사용해서 피팅시킨 모델이니까 그런걸까..요?
>
> 표본평균과 표본분산처럼 특정 값이 n-1개 정해지면 나머지 한개는 자동으로 정의되니까 자유도가 n-1로 나누는것과 연관이 있을 것 같은데..

그러나 위의 MSE가 테스트 오류율에 불편추정량이라 하더라도, 단일 관측치에 대한 값이기 때문에 매우 높은 분산을 갖게 됩니다.

그래서 총 n개의 데이터에 대해 반복 수행 하여 평균치를 통해 테스트 MSE를 추정합니다.

$$CV_{(n)} = \frac1n\sum\limits_{i=1}^nMSE_i\tag{5.1}$$

LOOCV는 두 가지 장점을 가집니다.

- validation set approach에 비해 많은 양의 데이터를 사용하여 피팅시키기 때문에 거의 가장 정확한 test MSE를 추정할 수 있습니다. (과대추정하지않고, bias가 적다.)
- 결과가 동일하다.(모든 경우에 대한 평균)

<img src = "https://py-tonic.github.io/images/islr/5.4.png">



데이터를 하나씩 빼서 n번 피팅시키고 에러를 구하는 것은 비용이 매우 큽니다. 그러나 최소제곱법으로 적합한 선형 회귀 혹은 다항 회귀에서는 leverage statistic을 이용하여 더 빠르게 구할 수 있습니다.

$$CV_{(n)}=\frac1n\sum\limits_{i=1}^n(\frac{y_i-\hat y_i}{1-h_i})^2\tag{5.2}$$

기존의 MSE의 분모에 $h_i$를 포함한 항이 추가된 식입니다.



### 5.1.3 K-Fold Cross-Validation

LOOCV의 대안이 교차검증입니다. 이 접근 방식은 관측치를 $k$개의 폴드(혹은 그룹)로 랜덤으로 나누는 접근 방식입니다. 첫 번째 폴드를 검증 세트로 사용하고 나머지 $k-1$ 폴드로 모델을 피팅시킵니다. 그리고 이 절차를 $k$번 반복합니다. 총 $k$개의 MSE가 생성되고, 평균을 계산할 수 있습니다.

![5.5](/Users/devcat/git/blog/images/islr/5.5.png)

$$CV_{(k)} = \frac1k \sum\limits_{i=1}^kMSE_i\tag{5.3}$$

$k$는 보통 5 혹은 10을 사용하는데 $k=n$인 LOOCV에 비해 어떤 장점을 가질까요?

가장 명백한 장점은 계산의 이점이 존재합니다. LOOCV는 n번 모델을 피팅시켜야 합니다. 이는 매우 큰 비용이 들어갑니다.(식 5.2는 최소제곱법을 사용하는 선형 모델의 경우에만 사용 가능함.)

그러나 교차검증은 매우 일반적인 접근 방식으로 대부분의 통계적 학습 방법에 사용 가능합니다.

![5.6](/Users/devcat/git/blog/images/islr/5.6.png)



실제 데이터를 조사할 때 실제 테스트 MSE를 알지 못하므로 교차 검증 추정의 정확성을 결정하기 어렵습니다. 그러나 시뮬레이션 된 데이터를 조사하면 계산가능하므로 교차 검증 결과의 정확성을 평가할 수 있습니다.

위 그림에서 파란 선이 true test MSE입니다. 검은 점선과 오렌지색 실선은 각각 LOOCV와 10-fold 교차검증 추정치입니다.

오른쪽 패널에서 실제 MSE와 교차 검증 곡선은 거의 동일하고, 중앙 패널에서는 유연성이 낮을 때는 동일하지만 CV곡선은 높은 유연성에서 테스트MSE를 과대평가합니다. 

왼쪽 패널에서 CV곡선은 올바른 모양을 갖지만 MSE를 과소평가합니다.



### 5.1.4 Bias-Variance Trade-Off for K-Fold Cross Validation

validation set approach에서는 사용 가능한 데이터의 수가 반으로 줄어서 정확한 테스트 에러를 제대로 추정하지 못할 것이라고 언급했습니다. 사실 추정의 편향은 전체 데이터를 쓰지 않는 시점에서 이미 편향이 발생합니다. 이러한 점에서 LOOCV는 $n-1$개의 관측치로 피팅하기 때문에 근사적인 불편추정이 가능합니다.

하지만 우리는 MSE는 Variance, bias, error 3개의 텀으로 구성된다는 점을 알고 있습니다. 즉 LOOCV가 상대적으로 낮은 bias를 가질 지라도, Variance는 상대적으로 높습니다.

LOOCV는 단 한개를 제외한 모든 관측치로 만든 모델들의 평균이기 때문에 각 모델간의 상관관계가 높고, 이는 높은 분산을 가지게 됩니다.

$$Var[\sum_{i=1}^nX_i] = \sum\sum Cov[X_i,X_j]$$

즉, 모집단에서 여러개의 트레이닝 데이터를 뽑을 수 있다면 매 번 LOOCV의 MSE추정치는 변합니다.(마치 오버피팅 처럼 데이터에 따라 바뀌는..?)

모든 CV방법은 겹치는 부분이 있기 마련인데 그에 따라 추정치의 분산이 변합니다. $k=n$인 LOOCV일 때 분산(상관관계)이 최대가 됩니다.



### 5.1.5 Cross-Validation on Classification Problems

