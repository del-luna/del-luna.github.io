---
layout: post
title: Two-stage Model for Automatic Playlist Continuation at Scale
author: Jaeheon Kwon
categories: Papers
tags: [recommendation]
---



# Two-stage Model for Automatic Playlist Continuation at Scale



## Abstract

<hr>

이 논문에서 우리는 Recsys2018 챌린지에 대한 접근법을 제시합니다.

첫 번째 단계는 빠른 검색을 위해 최적화 된 two-stage 모델을 사용하고, 두 번째 단계는 검색된 후보의 순위를 다시 매겨 추천 시스템의 최상위 목록의 정확도를 최대화합니다.

> 이 논문 저자들의 팀이 fisrt prize



## Introduction

<hr>

노래의 하위 집합이 보류되는 별도의 10K의 테스트 재생 목록 집합을 사용하여 모델을 평가합니다.

특히 테스트 재생 목록의 길이는 0곡(cold-start)에서 100곡까지 다양합니다.

이는 재생 목록 생성의 모든 단계에서 추천 모델이 제대로 작동해야하는 생산 시나리오를 시뮬레이션합니다.

우리의 접근 방식은 2단계 아키텍처를 기반으로 합니다.

첫 번째 단계는 큰 2.2M노래 검색 공간을 각 재생 목록에 대해 훨씬 더 작은 후보 집합으로 줄이는데 중점을 둡니다.

CF와 딥러닝 모델의 조합을 사용하여 90%가 넘는 리콜을 통해 각 재생목록에 대해 20K 후보를 검색할 수 있습니다. 또한 이 후보 집합의 상위 1K곡은 이미 60%에 가까운 리콜을 포함합니다.

리콜이 높으면 대부분 관련 곡이 검색된 집합에서 캡처되므로 후속 모델이 정확도를 크게 떨어 뜨리지 않고 이 집합에만 집중할 수 있습니다.

따라서 런타임에 미치는 영향을 최소화하면서 2단계에서 보다 정교한 모델을 적용할 수 있습니다.

두 번째 단계에서는 각(재생목록,노래) 쌍을 관련성 점수에 직접 매핑하는 pairwise 모델을 개발합니다.

재생 목록과 곡 기능을 입력에 통합하여 이 모델은 기존의 CF방법으로는 표현하기 어려운 pair-wise 관계를 캡처할 수 있습니다.

두 번째 단계의 목표는 추천 곡의 상단에서 정확도를 최대화 하는 후보 곡의 순위를 다시 매기는 것입니다.

다음 섹션에서는 데이터 분할, 교육 및 추론 절차 뿐만 아니라 두 단계 모두에 대해 자세히 설명합니다.



## Approach

<hr>

이 접근법의 모델 아키텍처는 Fig.1에 나와 있습니다.

첫 번째 단계에서 잠재 CF모델 WRMF(Weighted Regularized Matrix Factorization)를 사용하여 각 재생목록에 대해 20K후보 곡을 빠르게 검색합니다.

검색된 곡 마다 CNN, User-User, Item-Item 인접 모델의 임베딩을 사용하여 추가 모델 점수를 계산합니다.

선형 가중 조합과 함께 모든 모델 점수는 추출된 재생 목록 노래 피처와 연결되어 두 번째 단계에 대한 입력으로 사용됩니다.

<img src = "https://py-tonic.github.io/images/2stage/1.png">

GB 모델은 모든 후보 곡의 순위를 다시 매기고 최종 순위를 출력합니다.



cold-start 외에도 길이에 관계없이 모든 재생 목록에 단일 2-단계 모델이 사용됩니다.

복잡성을 줄이고 훈련 시간을 단축하기 위해 의도적으로 수행됩니다.

이 섹션에서는 각 단계에 대해 자세히 설명하며 다음과 같은 표기법이 사용됩니다.

- **R** : 재생 목록-노래 matrix, $R_{ij}=1$이면 노래 $i$가 재생 목록 $j$에 들어있고 0이면 존재하지 않음. 
- **U, V** : 재생 목록, 노래 잠재 표현. $U_i,V_j$는 각각 재생 목록 $i$및 노래 $j$에 대한 잠재 표현을 나타냄.
- **S** : 재생 목록 $i$및 노래 $j$에 대한 예측된 관련성 점수를 $S_{ij}$로 나타냄.



### First Stage

<hr>

첫 번째 단계의 주요 목표는 충분히 높은 리콜로 후보 곡 집합을 신속하게 검색하는 것입니다.

잠재 CF모델은 효율적인 추론과 높은 정확도로 잘 수행되는 것으로 나타났습니다.

경험적으로, 우리는 WRMF가 최상의 성능을 보여줌을 발견하고 초기 검색을 위해 이를 사용합니다.

그러나, WRMF는 재생 목록 연속에 중요한 것으로 표시된 재생 목록 내의 노래 순서를 무시합니다.

시간 정보를 통합하기 위해 노래 임베딩 보다 CNN을 사용하여 순서에 따른 재생 목록 임베딩을 생성하는 CNN 기반 잠재 모델을 개발합니다.

또한 잠재 모델은 전체적인 패턴에 초점을 맞추는 것으로 나타 났으며, 소량의 아이템들 사이에서 강한 국소화된 상관 관계를 탐지하는데 열악한 경향이 있습니다.

따라서 잠재 모델이 놓친 패턴을 포착하기 위해 첫 번째 단계에서 인접 기반 CF 모델을 추가로 통합합니다.

전체 검색을 여러번 반복하지 않으려면 WRMF에서 검색한 후보곡에만 이 모델을 적용하여 계산 오버헤드를 크게 줄입니다.

아래에서는 각 모델에 대해 자세히 설명합니다.

**WRMF** 는 binary/implicit CF에서 가장 많이 사용되는 잠재 모델 중 하나입니다.

10년 전에 출판 된 사실에도 불구하고, 우리는 충분한 튜닝으로 여전히 높은 경쟁력을 달성할 수 있음을 발견했습니다.

WRMF는 다음 목표를 최적화 하기 위해 반복적으로 최소-제곱을 적용합니다.

$argmin \sum\limits_{i,j}c_{ij}(R_{i,j}-U_iV_j)^2 + \lambda_U \vert\vert U_i\vert\vert^2 + \lambda_V\vert\vert V_j\vert\vert^2 \tag{1}$

$c_{ij} = 1+\alpha R_{i,j}$입니다. $c_{ij}$의 $\alpha$는 관측 된 재생 목록-노래 쌍에 얼마나 많은 가중치가 부여 되는지를 제어합니다. 실험 결과 $\alpha = 100, \lambda_U = \lambda_V = 0.001$을 사용하면 성능이 우수하다는 것을 알았습니다.

> implicit feedback에 대한 CF논문에서 사용하는 계수 c와 같이 confidence를 나타내는 것 같은데 ..?
>
> --> 그냥 그 논문 맞았다... collaborative filtering for implicit feedback datasets

**CNN** CF에서 시각적 패턴을 모델링하는 기존의 연구는 주로 RNN에 중점을 두었습니다.

그러나 RNN본질적으로 시퀀스이며, 병렬화가 어렵기 때문에 훈련과 추론이 느려집니다.

언어 모델링 및 기타 도메인의 최근 연구에 따르면 CNN은 RNN과 비교할 수 있거나 더 나은 성능을 가진 시퀀스 작업에 쉽게 적용될 수 있습니다.

RNN과 달리 CNN은 완전히 병렬화 가능하므로 GPU와 같은 최신 아키텍처에서 속도가 크게 향상됩니다. 이러한 결과에서 영감을 받아 재생 목록 내에서 노래 순서를 고려하여 생성하는 temporal CNN을 개발합니다.

모델 아키텍처는 Fig.2에 나와 있습니다. 이 모델에서 연결된 노래 임베딩은 게이트 선형 유닛(GLU) 컨볼 루션 블록의 여러 레이어를 통과합니다.

그런 다음 마지막 GLU 블록의 활성화는 Max-Pool을 사용하여 함께 집계되고 완전 연결 레이어로 전달되어 재생 목록 임베딩을 출력합니다.

공식적으로, 각 재생 목록 $i$에 대한 입력은 $i$에 존재하는 노래에 대한 연결된 임베딩으로 구성됩니다.

$\Phi_i^{1:k} = [V_1^{CNN},...,V_k^{CNN}]\tag{2}$

<img src = "https://py-tonic.github.io/images/2stage/2.png">

재생 목록 내의 노래 하위 시퀀스도 유효한 재생 목록을 형성하므로 for $k:1 \leq k \leq \vert V(i)\vert$의 범위를 갖습니다.

따라서 $\Phi$는 $p\times k$ 행렬이며, $p$는 입력 임베딩의 크기입니다.

GLU블록의 컨볼루션은 왼쪽에서 오른쪽으로 $\Phi_i^{1:k}$로 적용되며 각 연속 레이어는 노래 시퀀스 내에서 점점 더 긴 범위 구조를 캡처합니다.

다양한 길이의 입력을 다루기 위해서 마지막 컨볼 루션 레이어 다음에 max-pool을 사용했습니다.

Max-Pool은 각 컨볼루션 커널에 대해 가장 큰 활성화를 유지합니다. 예를 들어 마지막 컨볼루션 레이어에 500개의 커널이 있는 경우 max-pool의 출력은 길이가 500인 벡터가 됩니다.

따라서 출력의 길이는 입력 수가 아닌 커널 수에만 의존합니다. CNN을 통해 입력 시퀀스를 전달하면 재생 목록 임베딩이 생성됩니다:

$U_i^{cnn} = f(\Phi_i^{1:k},\theta) \tag{3}$

우리의 목표는 검색이므로, $U_i^{cnn}$은 $V_k^{cnn}$을 따르는 노래의 정확한 예측자가 되어야 합니다.

이것은 우리의 목적 함수의 기반을 형성합니다.

완전히 연결된 레이어의 크기를 적절하게 조정하여 재생 목록 임베딩 $U^{cnn}$을 입력 노래 임베딩 $V^{cnn}$과 동일한 크기로 만듭니다.

주어진 노래 $j$가 재생 목록 $i$에 포함될 확률은 다음과 같이 정의됩니다:

$P(V_j^{cnn}\vert U_j^{cnn}) = \frac1{1+e^{-U_i^{cnn}V_j^{cnn}}} \tag{4}$

훈련 중에 예측 포인트 $k$가 주어지면 $V_k^{cnn}$를 따르는 노래의 확률을 높이고 다른 모든 노래에 대해 낮추는 것을 목표로 합니다.

stochastic 최적화 접근법을 채택하여 각 미니 배치에서 재생 목록에 대한 예측 포인트 $k\in [1,\vert V(i)\vert]$를 반복적으로 샘플링합니다.

$k$가 주어질 때 우리는 위치 $k$ 다음에 나타나고, $j \notin V(i)$인 노래 $j \in V(i)$를 샘플링합니다. 

그런 다음 $L$의 그래디언트를 사용하여 모델을 업데이트 합니다.

다음 단어만 예측되는 언어 모델링과 달리, 미래를 향한 임의의 예측을 모두 훈련시킵니다.

결과적으로 다음 노래만 예측하면 모델이 입력의 마지막 노래에 크게 집중하여 성능이 크게 저하됩니다.



교육이 완료되면 각 재생 목록의 모든 노래를 사용하여 모델을 전달하여 임베딩 $U^{cnn}$을 얻습니다.

그런 다음 임베딩 공간에서 곱해져서 계산하여 검색을 수행합니다.

이 챌린지에서 CNN모델은 7개의 GLU블록으로 구성되며, 각 블록은 900개의 커널이 있는 컨볼 루션 레이어로 구성되며 배치 정규화 및 ReLU가 뒤따릅니다.

마지막 GLU 블록 다음에는 커널당 최대 3개의 값을 유지하는 top-3-max pool과 완전 연결층이 뒤따릅니다.

입력 및 출력 임베딩 차원이 200으로 설정되었으며, WRMF 모델의 노래 표현을 사용하여 입력 노래 임베딩$V^{cnn}$을 초기화 합니다.

이 임베딩은 모델 가중치와 함께 모델 훈련 중에 업데이트 됩니다.



**Neighbor-based Models.** 두 가지 인기있는 이웃 기반 CF 모델은 User-User 및 Item-Item입니다.

> [Paper](https://www.researchgate.net/profile/George_Karypis/publication/200121014_Item-based_collaborative_filtering_recommendation_algorithmus/links/54c6e9490cf289f0cecc97fa/Item-based-collaborative-filtering-recommendation-algorithmus.pdf) 

User-User 접근 방식은 $R$의 행 간 유사성을 계산하여 관련성을 추정합니다. 공식적으로 주어진 재생 목록-노래 쌍$(i,j$)에 대해 User-Users는 $j$가 $i$에서 나타나는 재생 목록을 비교합니다.

$S_{ij}^{user} = \sum\limits_{i'\in U(j)}\frac{R_{i:}R_{i':}}{\vert\vert R_{i:}\vert\vert\vert\vert R_{i':}\vert\vert} \tag{5}$

$R_{i:}$는 $R$의 $i$번째 행입니다.

여기서 직관은 노래 $j$가 $i$와 비슷한 많은 재생목록에 나타나면 $S_{ij}^{user}$ 가 높은 추천 목록에 포함되어야 한다는 것입니다.

유사하게 Item-Item 방식은 $R$의 열 간 유사성을 계산하여 관련성을 추정합니다. 방법은 $j$를 재생 목록 $i$의 모든 노래와 비교합니다.

$S_{ij}^{item} = \sum\limits_{j'\in V(i)}\frac{R_{:j}R_{:j'}}{\vert\vert R_{j:}\vert\vert\vert\vert R_{:j'}\vert\vert} \tag{6}$

$R_{:j}$는 $R$의 $j$번째 열입니다.

이웃 기반 모델의 성능 및 런타임을 향상 시키기 위해 수많은 확장 및 일반화가 제안되었습니다.

확인된 중요한 문제 중 하나는 인기 편향입니다.

인기도는 유사성 점수를 부풀려 밀도가 높은 행/열 로 변환되어 인기 항목에 대해 크게 왜곡된 추천을 합니다.

이 문제를 해결하기 위해 역률(inverse popularity)에 따라 유사성 점수를 재조정할 것을 제안합니다. 

> [Paper](https://www.kdd.org/exploration_files/Vol19-Issue1.pdf)

이 접근법을 채택하고 User-User및 Item-Item 점수에 $popularity_i^{-(1-\beta)}$를 곱합니다.

여기서 $\beta$는 실험적으로 선택된 상수이고, $popularity$는 정규화된 인기도 점수 입니다.

경험적으로 우리는 User-User에서 $\beta = 0.6$, Item-Item에서 $\beta = 0.9$로 설정합니다.



**Model Blend.** 이전 섹션에서 WRMF, CNN, User-User, Item-Item의 네 가지 CF모델에 대해 설명했습니다. 여기에서 이러한 모델이 어떻게 결합되는지 간략히 설명합니다.

단순한 솔루션은 최상의 단일 모델을 선택하는 것입니다.

그러나 특정 모델을 선택하면 특정 모델 가정에 찬성하여 모델 불확실성을 무시하기 때문에, overconfident prediction 및 분산이 높아질 수 있습니다.

결과적으로 여러 모델을 결합하는 것이 바람직합니다.

> [Paper](https://arxiv.org/pdf/1106.0257.pdf)

오버피팅을 피하기 위해 우리는 선형 가중치 앙상블 방법을 사용합니다. 여기서 모델 점수는 모델 별 가중치와 선형으로 결합됩니다.

$S^{blend}=w_1S^{wrmf}+w_2S^{cnn}+w_3S^{user}+w_4S^{item} \tag{7}$

각 모델의 점수는 평균을 빼고 표준 편차로 나누어 합치기 전에 표준화 됩니다.

표준화 점수는 동일한 범위로 재조정하여 모델 간의 비교가 가능하도록 합니다.

가중치는 집합 {0, 0.1, 0.2, 0.3, 0.4, 0.5}에서 greedily로 선택되며, 오버피팅을 줄이기 위해 이 집합을 작게 유지합니다.

Greedy 최적화 후에 우리는 다음 가중치 조합을 선택합니다. $w_1 =0.1, w_2=0.4,w_3=0.3,w_4=0.3$ , 이 조합은 최고의 검증 정확도를 달성했으며 모든 후속 실험에 사용됩니다. 5개의 점수 $S^{wrmf},S^{cnn},S^{user},S^{item},S^{blend}$는 각 후보 곡의 두 번째 단계에 대한 입력으로 사용됩니다.

> 각 모델별로 인풋으로는 candidate 아웃풋은 그 candidate의 임베딩을 뱉어내니까 
>
> 임베딩 == 유사도(논문에서는 예측된 관련성 점수) 라고 생각하고 각 노래별 유사도에 대해 모델별로 가중치를 적용해서 더한다..?

### Second Stage

<hr>

첫 번째 단계에서 검색된 후보를 고려할 때 두 번째 단계의 목표는 상위 추천 후보 목록의 정확도를 최대화하여 이러한 후보를 정확하게 다시 순위를 매기는 것입니다.

후보 세트가 작기 때문에 2 단계 모델은 더 비싸고 정확성을 위해 효율성을 절충할 필요가 있습니다.

따라서 pairwise 상호 작용에 초첨을 맞추고 (재생 목록, 노래)쌍을 관련성 점수에 공동으로 매핑하는 모델을 개발합니다.

이 접근법은 첫 번째 단계의 4 가지 모델이 pairwise 상호 작용을 고려하지 않는 점을 보완합니다.

> User-USer, Item-Item 이런 식의 모델이라 그런듯 하다.

두 번째 단계의 주요 구성 요소는 입력 피쳐와 모델 구조이며, 아래 섹션에 자세히 설명되어 있습니다.



**Feature Extraction.** 재생 목록-노래 관련성의 모든 중요한 측면을 캡처하기 위해 광범위한 feature engineering을 수행했습니다. 우리가 사용한 마지막 피쳐 집합을 5개의 그룹으로 나눌 수 있습니다.

- **Input From First Stage.** 첫 단계 부터 5개의 점수를 인풋 피쳐로 직접 사용합니다. 이를 통해 2 단계 모델은 1 단계의 성능을 빠르게 회복한 다음 개선에 집중할 수 있습니다.
- **Playlist Features.** 재생 목록 피쳐는 재생 목록의 컨텐츠 정보와 재생 목록에 있는 노래 유형을 요약합니다. 재생 목록의 타이틀, 길이, 노래, 아티스트, 앨범, 인기 등과 같은 메타데이터를 사용합니다. 동질성은 재생 목록 잠재 표현(WRMF, CNN 등)을 재생 목록에 나타나는 모든 노래와 비교하여 추정됩니다. 일부 재생 목록에는 대부분 특정 장르, 유형의 노래가 포함되어 있어 추천 작업을 쉽게 수행할 수 있으며 다른 재생 목록에는 훨씬 더 다양한 곡이 포함되어 있습니다. 동질성 점수는 노래 다양성과 관련이 있으며 이 그룹에서 가장 중요한 피쳐 중 하나입니다.
- **Song Features.** 재생 목록 피쳐와 마찬가지로 노래 컨텐츠 정보와 노래가 나타나는 재생 목록 유형을 요약하는데 중점을 둡니다.우리는 노래, 아티스트, 앨범, 타이틀 및 재생 목록 통계 피쳐를 사용합니다. 또한 노래 표현을 포함하는 모든 재생 목록과 노래 표현을 비교하여 동질성 점수를 계산합니다. 이 기능은 노래가 일반적으로 비슷한 유형의 재생 목록에 나타나는지 여부를 추정하므로 효과적임이 입증되었습니다.
- **Playlist-Song Features.** 이 것은 각 재생 목록-노래 간의 pairwise 유사성을 직접 설명하는 가장 중요한 기능입니다. 대상 노래와 재생 목록에 있는 노래, 대상 재생 목록과 대상 노래가 포함된 재생 목록 간의 유사성 피쳐를 계산합니다. 이러한 피쳐는 Item-Item 및 User-User 유사도와 비슷하지만 추가 컨텐츠 정보를 포함합니다. 예를 들어, 아티스트/앨범 겹침, 평균 잠재 점수 유사성, 기간 및 길이의 차이 등과 같은 통계를 계산합니다. 이 기능 그룹을 추가하면 첫 번째 단계에서 가장 큰 개선이 이루어 졌으므로 향후 노력에 집중해야 한다고 생각합니다.
- **Creative Track.** 창의적인 트랙을 위해 Spotify Audio Api에서 음향성, 음량, 모드, 템포, 박자 등 12가지 추가 피쳐를 사용했습니다. 이 피쳐를 추가하면 작지만 일관된 이득을 얻을 수 있습니다.



<img src = "https://py-tonic.github.io/images/2stage/3.png">



**Model Architecture.** 우리는 XGBoost 라이브러리를 사용하여 2 단계에서 트리 기반 그래디언트 부스팅 모델(GBM)을 사용하기로 했습니다.

트레이닝 세트를 만들기 위해 첫 번째 단계에서 반환 된 20K 노래 후보를 사용하고, 각 재생 목록에 대해 20개의 관련 노래와 20개의 관련되지 않은 노래를 무작위로 샘플링합니다.

이 샘플은 binary relevant/not relevant 대상으로 트레이닝 세트를 형성합니다. 그런 다음 훈련 목표로 pairwise ranking loss를 통해 GBM 모델을 훈련시킵니다.

경험적으로, 이 작업에 대한 binary cross entropy보다 ranking loss가 더 좋습니다.

모든 제출에서 우리는 150tree, depth10의 모델을 사용합니다.

> Ranking loss라는 용어는 처음 듣는데 직관적으로도 순서랑 관련이 있을 듯 하다.
>
> 일반적으로 입력에 대해 레이블, 값 등을 직접 예측하도록 배우는 것이 목적인 Cross entropy or Mean Sqaure error와 달리 Ranking loss는 상대적인 거리를 예측하는 것 같다.
>
> 우리의 XGBoost 모델의 인풋은 재생목록-노래 피쳐 + 모델 점수(= relevance scores = Embedding? = 유사도?) 이기 때문에 각 노래별로 유사도를 가지고 거리 측정을 통해 순서를 매길 수 있을 것 같음.







## Reference

<hr>

[Paper](http://www.cs.toronto.edu/~mvolkovs/recsys2018_challenge.pdf)

