---
layout: post
title: ISLR chapter.3
author: Jaeheon Kwon
categories: Ai
tags: [islr]
---



## 3.1 Simple Linear Regression

단순 선형 회귀는 이름에 걸맞게 단일 예측 변수 $X$를 통해 정량적 반응 $Y$를 예측하는 매우 간단한 접근 방법입니다. $X$와 $Y$사이에는 선형적 관계가 있다고 가정합니다.

수학적으로 선형적 관계는 다음과 같이 나타낼 수 있습니다.

$$Y\approx \beta_0+\beta_1X\tag{3.1}$$



위 식에서 $\beta_0, \beta_1$은 선형 모델의 절편 및 기울기를 나타내는 두 개의 알 수 없는 상수입니다.(계수 혹은 파라미터 라고도 불림)

훈련 데이터를 사용하여 모델 계수에 대한 추정치 $\beta_0,\beta_1$을 생성하면 다음 식을 계산하여 TV특정 값을 계산 기반으로 미래 매출을 예측할 수 있습니다.

$$\hat y = \hat\beta_0+\hat\beta_1x\tag{3.2}$$

$\hat y$는 $X=x$를 기반으로한 $Y$에 대한 예측값입니다. ^ 기호는 알 수 없는 파라미터 혹은 계수에 대한 추정 값이거나, 반응 변수에 대한 예측 값을 나타내는 기호입니다.



### 3.1.1 Estimating the Coefficients

베타 값들은 알 수 없으니 식 3.1을 사용하여 예측하기 전에 데이터를 사용해서 계수를 추정해야 합니다.

$$(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$$

$X,Y$에 대한 관측치로 구성된 $n$개의 페어가 있습니다.

광고의 예시에서 이 데이터 셋은 티비 광고 비용과 $n=200$개의 서로다른 시장에서의 제품 판매로 구성됩니다.

우리의 목표는 선형 모델 식 3.1이 데이터에 잘 맞도록  계수에 대한 추정 $\beta_0,\beta_1$을 얻는 것입니다. 즉, $i=1,...,n$에 대하여 $y_i \approx \hat\beta_0+\hat\beta_1x_i$가 됩니다.

다시말해서 200개의 데이터 포인트에 최대한 가까운 직선을 만들기 위해 편향과 기울기를 찾고 싶습니다.

거리를 측정하는 많은 방법이 존재하지만, 이 장에서는 최소 제곱을 기준으로 사용합니다.



$e_i=y_i-\hat y_i$는 $i$번째 관측된 반응과 반응 값에 대한 우리 선형 모델의 예측의 잔차입니다.

우리는 잔차 제곱 합 RSS를 다음과 같이 정의합니다.

$$RSS = e_1^2+e_2^2+\cdot\cdot\cdot+e_n^2$$

결국 최소 제곱법은 $RSS$를 최소화 하기 위해 $\beta_0,\beta_1$을 선택합니다.

$$\hat\beta_1 = \frac{\sum\limits_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sum\limits_{i=1}^n(x_i-\bar x)^2} \\\hat\beta_0=\bar y-\hat\beta_1\bar x \tag{3.4}$$

$\bar x, \bar y$는 각각 샘플의 평균입니다.

다시말해서, 위 식은 선형 회귀를 통한 최소 제곱 계수 추정을 정의합니다.



<img src = "https://py-tonic.github.io/images/islr/3.1.png">



위 그림은  $\hat\beta_0=7.03, \hat\beta_1=0.0475$일 때 광고 데이터에 대한 단순 선형 회귀를 적용한 것을 보여줍니다.

위 근사치를 통해 TV광고에 1000달러를 추가했을 때 약 47.5개의 제품을 추가로 판매할 수 있다는 것을 알 수 있습니다.



<img src = "https://py-tonic.github.io/images/islr/3.2.png">

위 그림은 여러 가지 $\beta_0,\beta_1$에 대해 RSS값을 계산한 것을 보여줍니다.

빨간 점이 $RSS$를 최소화 하는 최적의 페어입니다.



### 3.1.2 Assesing the Accuracy of the Coefficient Estimates

우리는 2장에서 $X,Y$의 관계를 알 수 없는 함수 $f$와 평균이 0 인 $\epsilon$으로 정의했습니다.

$f$는 근사시킨 선형 함수이고, 다음과 같은 관계를 나타낼 수 있습니다.

$$Y = \beta_0+\beta_1X+\epsilon \tag{3.5}$$

에러 텀은 이 단순한 모델에서 놓친 모든 것들을 포괄합니다. 실제 관계는 선형이 아닐 수 있습니다. $Y$를 설명하기 위한 추가적인 변수가 필요할 수도 있고, 측정에서 오류가 있었을 수 있습니다.

 우리는 일반적으로 에러 텀을 $X$와 독립이라고 가정합니다.

위 식에 의해 주어진 모델은 $X,Y$사이의 실제 관계에 대한 모집단 회귀 선을 정의합니다.

최소 제곱 회귀 계수 추정은 최소 제곱 선을 특징화 합니다.



<img src = "https://py-tonic.github.io/images/islr/3.3.png">

위 왼쪽 그림(Fig 3.3)은 단순한 시뮬레이팅 예시에 대한 두 직선입니다.

100개의 $X$ 와 $Y$를 모델로 부터 생성했습니다.

$$Y = 2+3X+\epsilon\tag{3.6}$$

왼쪽 그림의 붉은 직선은 $f(X)=2+3X$인 진짜 관계식을 나타내는 반면 파란 직선은 관측된 데이터를 바탕으로 최소 제곱 추정을 통한 직선을 나타낸 것입니다.

실제 데이터의 진짜 관계식은 일반적으로 알려져있지 않지만, 최소 제곱 직선은 항상 식 3.4를 통해 계수 추정을 계산할 수 있습니다.

오른쪽 그림은 식 3.6을 통해 생성한 다른 데이터셋에 대한 최소 제곱 직선을 그린 것입니다.

동일한 실제 모델에서 생성된 다른 데이터 셋은 약간 다른 최소 제곱 직선을 생성하지만 관찰되지 않은 모집단 회귀선은 변경되지 않습니다.

동일한 데이터셋에서 나온 서로 다른 두개의 직선이 입력변수와 반응 변수의 관계를 설명한다는 것을 무엇을 의미할까요?

이 개념은 표본의 정보를 사용하여 대규모 모집단의 특성을 추정하는 표준 통계 접근 방식의 자연스러운 확장입니다.

예를 들어, 임의 변수 $Y$의 모집단 평균 $\mu$를 알고 싶다고 가정합시다.

불행하게도 $\mu$는 알수 없습니다. 하지만 우리는 $Y$로 부터 $n$개의 관측치 $y_1,y_2,...,y_n$에 접근할 수 있고 이를 통해서 $\mu$를 추정할 수 있습니다.

합리적인 추정은 $\hat y = \bar y$이며, 여기서 $\frac1n\sum\limits_{i=1}^ny_i$는 표본 평균입니다.

물론 표본평균과 모집단 평균은 다르지만 일반적으로 표본 평균은 모집단 평균의 좋은 추정치를 제공합니다.

같은 방식으로, 선형 회귀에서 알려지지 않은 계수 $\beta_0,\beta_1$은 모집단 회귀선을 정의합니다. 우리는 식 3.4를 통해 $\hat\beta_0 , \hat\beta_1$을 사용하여 이러한 알려지지 않은 계수를 추정합니다. 이러한 계수 추정 값은 최소 제곱 선을 정의합니다.

선형 회귀와 확률 변수의 추정 사이의 유추는 편향의 개념을 기반으로합니다.

$\mu$를 추정하기 위해 표본 평균 $\hat \mu$를 사용하는 경우, 이 추정치는 평균적으로 $\mu$가 $\hat \mu$와 같을 것으로 기대한다는 의미에서 편향되지는 않습니다(unbiased).

이 뜻은, 특정 관측 세트$y_1,...,y_n,\hat \mu$가 $\mu$를 과대 추정할 수 있고, 다른 관측치를 기반으로 $\hat \mu$가 $\mu$를 과소 추정 할 수 있음을 의미합니다.

그러나 많은 수의 관측치에서 $\mu$의 추정치에 대한 평균을 구할 수 있다면 그 평균은 정확히 $\mu$와 같습니다.

따라서, 편향되지 않은 추정치는 실제 모수를 체계적으로 과대 추정, 과소 추정 하지 않습니다. unbiasedness에 대한 속성은 식 3.4에 주어진 최소 제곱 계수 추정에도 적용됩니다.

특정 데이터를 기반으로 $\beta_0,\beta_1$을 추정하면 추정 값이 $\beta_0,\beta_1$과 정확히 일치하지 않습니다. 하지만 많은 수의 데이터 셋에서 얻은 추정치를 평균화 할 수 있다면 이러한 추정치의 평균은 일치합니다.

실제로 Fig 3.3의 오른쪽 패널에서 각각 별도의 데이터 셋에서 추정된 많은 최소 제곱 선이 실제 모집단 회귀 선에 매우 가깝다는 것을 알 수 있습니다.

이제 자연스러운 질문이 발생할 수 있습니다. $\mu$의 추정치로서 표본 평균 $\hat \mu$는 얼마나 정확합니까? 우리는 많은 데이터 셋에 대한 추정치의 평균은 모집단의 평균과 매우 근사하지만 단일 추정치는 모집단의 평균을 과대 추정하거나 과소 추정 할 수 있음을 확인했습니다.

표본 평균의 단일 추정치는 얼마나 멀리 떨어져 있을까요? 일반적으로 우리는 $SE(\hat \mu)$로 표기된 $\hat \mu$의 standard error를 계산하여 이 질문에 대답할 수 있습니다.

$$Var(\hat\mu) = SE(\hat\mu)^2 = \frac{\sigma^2}{n}\tag{3.7}$$

러프하게 말하자면 표준 오차는 이 추정치가 모집단의 평균과 얼마나 다른지를 알려줍니다.

또한 위 식은 관측값이 많을 수록 표준 오차가 작아지는 이유를 말해줍니다.

비슷한 맥락으로 $\hat \beta_0,\hat\beta_1$이 $\beta_0,\beta_1$과 얼마나 가까운지를 다음 식을 통해 알 수 있습니다.

$$SE(\hat\beta_0)^2 = \sigma^2[\frac1n+\frac{\bar x^2}{\sum_{i=1}^n(x_i-\bar x)^2}],\quad SE(\hat\beta_1)^2=\frac{\sigma^2}{\sum_{i=1}^n(x_i-\bar x)^2}\tag{3.8}$$

여기서 $\sigma^2=Var(\epsilon)$입니다.

이 공식이 엄밀하게 유효하려면, 각 관측치의 오차 $\epsilon_i$가 공통 분산 $\sigma^2$와 상관이 없다고 가정해야 합니다.

이 것은 Fig 3.1에서 명백한 사실은 아니지만, 공식은 여전히 좋은 근사치로 밝혀졌습니다.

공식에 따르면 $SE(\hat\beta_1)$은 $x_i$가 더 넓어지면 작아집니다. 직관적으로 이 경우 기울기를 추정하는데 더 많은 레버리지가 존재하게됩니다.

또한 $\bar x$가 0이면 $SE(\hat \beta_0)$는 $SE(\hat \mu)$와 동일합니다.(이 경우 $\hat \beta_0$=$\bar y$)

일반적으로 $\sigma^2$은 알 수 없지만 데이터에서 추정할 수 있습니다. $\sigma$의 추정치는 residual standard error로 알려져 있으며 식으로는 다음과 같습니다. $RSE = \sqrt{RSS/(n-2)}$

표준 오차를 사용하여 신뢰 구간을 계산할 수 있습니다.

95%의 신뢰 구간은 95% 확률로 매개변수의 실제 알 수 없는 값이 포함되는 값의 범위로 정의됩니다.

범위는 데이터 샘플에서 계산된 하한 및 상한으로 정의됩니다.

선형 회귀에서 $\beta_1$에 대한 95%신뢰 구간은 대략 다음과 같은 형식을 취합니다.

$$\hat\beta_1\pm 2\cdot SE(\hat \beta_1) \tag{3.9}$$

95%확률에 대한 구간의 범위는 다음과 같습니다.

$$[\hat\beta_1 - 2\cdot SE(\hat\beta_1), \hat\beta_1 + 2\cdot SE(\hat\beta_1)]  \tag{3.10}$$

유사하게 $\beta_0$에 대한 신뢰 구간은 다음과 같은 형식을 취합니다.

$$\hat\beta_0\pm 2\cdot SE(\hat \beta_0) \tag{3.11}$$



광고 데이터의 예시로 돌아가봅시다. $\beta_0$에 대한 95%신뢰구간은 [6.130, 7.935]이며, $\beta_1$에 대한 신뢰 구간은 [0.042, 0.053]입니다. 그러므로 우리는 광고가 없을 때 판매량이 평균적으로 6,130 ~ 7940단위 사이에 떨어질 것이라는 결론을 내릴 수 있습니다. 또한 TV광고가 $1000 증가할 때마다 평균 판매량은 42~53대 증가할 것 입니다.



표준 오차를 사용하여 계수에 대한 가설 검정을 수행할 수 있습니다. 가장 일반적인 가설 검정은 다음의 귀무 가설을 검정하는 것입니다.

- $H_0$: There is no relationship between X and Y
- $H_1$: There is some relationship between X and Y



수학적으로는 다음과 같습니다.

- $H_0:\beta_1 = 0$
- $H_1:\beta_1\neq0$

$\beta_1 = 0$이면 모델 3.5가 $Y=\beta_0+\epsilon$으로 바뀌고 $X$는 $Y$와 관련이 없습니다.

귀무 가설을 테스트 하려면 $\beta_1$에 대한 추정치인 $\hat\beta_1$이 0에서 충분히 멀리 떨어져 $\beta_1$이 0이 아니라고 확신할 수 있는지 여부를 확인해야 합니다.

얼마나 멀어야 할까요? 물론 이것은 $\hat\beta_1$의 정확도에 따라 달라집니다. 즉, $SE(\hat\beta_1)$에 따라 달라집니다. 만약 $SE(\hat\beta_1)$이 작다면, 상대적으로 작은 값의 $\beta_1$이라도 $\beta_1 \neq0$이라는 강력한 증거가 될 수 있고, 이 것은 $X,Y$에 관계가 있음을 보여줍니다.

반대로 $SE(\hat\beta_1)$가 크면 귀무 가설을 기각하기 위해서는 $\hat\beta_1$의 절대 값이 커야 합니다. 실제로 우리는 다음과 같은 t-statistic을 계산합니다.

$$t = \frac{\hat\beta_1 -0}{SE(\hat\beta_1)} \tag{3.14}$$

> 검정 통계량 t는
>
> $\hat\beta_1$ 데이터로 부터 추정한 기울기 - (귀무가설에서 설정한 기울기 즉, 0)을, standard error로 스케일링함. t가 크면 데이터랑 내가 주장하는 바가 다르므로 귀무가설을 기각.
>
> t = 두 표본 그룹 평균의 차이 / 두 그룹 간 평균 차이에 대한 불확실도 
>
> 위에선 귀무가설을 0으로 설정해서 식이 저렇지만 원래는 식은
>
> $t= \frac{\bar X_1-\bar X_2}{s_{\bar X_1-\bar X_2}}$ 이며, $s_{\bar X_1-\bar X_2}=\sqrt{Var[\bar X_1-\bar X_2]}$ 입니다. 



$X,Y$사이에 관계가 없다면 $n-2$ 의 자유도를 갖는 t-분포를 가질 것으로 예상합니다. (t-분포는 종 모양이고 n>30인 경우에 대해 정규 분포와 매우 유사합니다.)

$\beta_1=0$이라고 가정하면,  $\vert t\vert$ 혹은 그 이상의 숫자를 절댓값으로 관측할 확률을 계산하는 것은 간단합니다. 우리는 이 확률을 $p-value$라고 부릅니다. (tip. 각 $\beta$에 대한 $p-value$값이 큰게 중요한 변수)

$p-value$를 다음과 같이 해석합니다. 작은 $p-value$는 예측 변수와 반응 사이에 실질적인 연관성이 있다는 것을 의미합니다.(즉, 우리의 기울기가 귀무가설에서 세운 0과 차이가 크다면 t값은 커지게 되고 이는 p-value가 매우 작아지는 것을 의미합니다. P(Y>t) 인데 여기서 t가 크다는 얘기이니까요.. 이렇게 되면 실제로 일어날 확률이 매우 작다는 뜻이고 이는 귀무 가설이 잘못되어서 기각한다는 결론으로 이어집니다.)

일반적으로 귀무가설을 기각하기위한 $p-value$의 값은 n=30일 때 1% 혹은 5%입니다.



<img src = "https://py-tonic.github.io/images/islr/t3.1.png">

위 표는 회귀 분석에 대한 최소 제곱 모델의 세부 정보를 제공합니다. 광고 데이터의 TV광고 예산으로 판매된 단위 수입니다.

계수 $\beta_0,\beta_1$은 표준 오차와 매우 큰 상관관계가 있고, 검정 통계량 또한 큽니다. $H_0$가 정답일 확률은 매우 낮습니다. 그러므로 $\beta_0, \beta_1 \neq 0$이라고 결론 지을 수 있습니다.



### 3.1.3 Assessing the Accuracy of the Model

귀무 가설을 기각하고 대립 가설을 채택하면 모델이 데이터에 얼마나 적합한지 정량화 하는 것 또한 당연합니다.

선형 회귀의 적합도를 일반적으로 RSE(residual standard error)와 $R^2$통계량을 이용하여 평가합니다.

<img src = "https://py-tonic.github.io/images/islr/t3.2.png">

위 표(table 3.2)는 TV광고 예산으로 판매된 선형 회귀에 대한 RSE, $R^2$통계 및 F-통계를 표시하고 있습니다.



**Residual Standard Error**

각 관측치와 관련이 있는 모델 3.5에서 에러 텀을 떠올려 봅시다.

이러한 에러 텀으로 인해 진짜 회귀선 ($\beta_0,\beta_1$을 알아도) 우리는 $X$를 통해 $Y$를 완벽하게 예측할 수 없습니다. RSE는 에러 텀에 대한 표준 편차를 추정하는 것입니다.

러프하게 말하면, 반응 변수와 진짜 회귀 직선 사이 편차의 평균입니다. 식으로는 다음과 같이 나타냅니다.

$$RSE = \sqrt{\frac{1}{n-2}RSS} = \sqrt{\frac{1}{n-2}\sum\limits_{i=1}^n(y_i-\hat y_i)^2}\tag{3.15}$$

$RSS$는 섹션 3.1.1에서 정의했습니다. 식은 다음과 같습니다. (여기서 자유도로 나누면 MSE)

$$RSS = \sum\limits_{i=1}^n(y_i-\hat y_i)^2\tag{3.16}$$

광고 데이터의 케이스에서 우리는 RSE가 3.26인 것을 테이블 3.2를 통해 볼 수 있습니다.

즉, 각 시장은 평균적으로 약 3,260단위 만큼 실제 회귀선에서 벗어납니다. 이 말은 실제 모델을 알아도 TV광고를 기반으로한 판매 예측은 여전히 평균 약 3,260단위 만큼 떨어진다는 의미입니다. 위 단위가 허용 가능한 예측 오류인지에 대한 여부는 문제에 따라 다릅니다.

광고 데이터 셋에서 판매에 대한 평균 값은 대략 14,000 유닛 입니다. 에러의 비율은 3,260/14,000 = 23% 정도 입니다.

만약 모델을 사용하여 실제 결과 값과 매우 가까운 예측 값을 얻는다면, RSE가 매우 작은 것이고 모델이 데이터에 잘 맞는다고 할 수 있습니다.

즉, $\hat y_i$가 $y_i$와 굉장히 멀다면 RSE는 매우 클 것이고, 모델이 데이터에 적합하지 않다는 것을 의미합니다.



**$R^2$ Statistic**

RSE는 데이터와 모델의 차이에 대한 메저를 제공했습니다. 그러나 $Y$의 단위로 측정되기 때문에 무엇이 좋은 RSE를 구성하는지  항상 명확하지는 않습니다. $R^2$ 통계량은 다른 적합도를 제공합니다. 이 메저는 비율을 사용하여 분산을 설명합니다. (비율이기 때문에 항상 0~1사이 값을 가집니다.) 또한 Y의 스케일에 독립적입니다.

$R^2$은 다음과 같이 계산합니다.

$$R^2 = \frac{TSS-RSS}{TSS} = 1-\frac{RSS}{TSS} \tag{3.17}$$

$TSS= \sum(y_i-\bar y)^2$ 입니다. TSS는 반응 변수 $Y$에 대한 변동성을 나타냅니다.(여기서 자유도로 나누면 분산이지만 뭐...편의상 분산이라고 언급해도 되지 않을까요...?)

위에서 다룬 $RSS$는 회귀 분석 수행 후 설명되지 않은 상태로 남아 있는 변동성(에러 텀)의 양을 측정합니다.

> 설명이 좀 ... 애매하긴한데 저는 이렇게 이해했습니다.
>
> TSS가 러프하게 따지면 전체 Y에 대한 분산이면
>
> RSS는 회귀분석 수행 후 남은 에러 텀에 대한 분산을 나타내겠죠?(입력 변수로 Y에대한 관계를 모두 설명 한경우 에러텀에 대한 분산만 남겠죠?)
>
> 그래서 TSS-RSS는 이 모델이 에러텀을 제외하고 얼마나 많은 분산을 표현(혹은 설명) 했는지 라고 해석했습니다.

$R^2$가 1에 가까울수록 회귀 모델이 반응 변수에대한 설명을 잘 하고 있는 것으로 볼 수 있습니다.

반대로 0에 가까울수록 모델이 너무 좋지 않거나 에러 텀의 분산이 매우 큰 것으로 볼 수 있습니다.

$R^2$는 RSE와 달리 0~1사이 값으로 표현되기 때문에 해석하는데 이점이 존재합니다.



선형 모델은 생물학, 심리학, 마케팅 및 기타 영역에서 복잡한 데이터에 대한 근사치정도로 밖에 쓰이지 못하고, 측정되지 않은 요인으로 인한 잔류 오차는 매우 큽니다.

이러한 환경에서 예측 변수에 의해 설명되는 반응의 분산은 극히 작은 비율만 예상되며 0.1보다 낮은 R2 값이 더 현실적입니다.

$R^2$통계량은 $X$와 $Y$의 선형 관계에 대한 척도임을 기억합시다. 상관 관계는 다음과 같이 정의됩니다.

$$Cor(X,Y) = \frac{\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum_{i=1}^n(x_i-\bar x)^2}\sqrt{\sum_{i=1}^n(y_i-\bar y)^2}}\tag{3.18}$$

위 식 또한 $X, Y$에 대한 선형 관계를 측정할 수 있습니다.

이는 선형 모델의 적합성을 평가하기 위해 $R^2$대신 $r=Cor(X,Y)$를 사용할 수 있음을 보여줍니다.

실제로 단순 선형 회귀 설정에서 $R^2=r^2$입니다.

하지만 다음 섹션에서 다룰 다중 선형 회귀는 여러 예측 변수를 사용하여 반응 변수를 예측합니다.

상관 관계는 단일 변수 쌍 간의 관계를 정량화하므로, 예측 변수와 반응 변수 사이의 상관 관계 개념은 자동으로 다중 회귀에서 확장되지는 않습니다. $R^2$가 이 역할을 할 수 있습니다.



## 3.2 Multiple Linear Regression

단순 선형 회귀는 단일 예측 변수를 기반으로하여 반응 변수를 예측하는 좋은 접근입니다.

그러나 현실에서는 우리는 하나 이상의 예측 변수와 마주하게 됩니다.

예를들어 광고 데이터의 경우 우리는 판매량과 TV광고 사이의 관계에 대해 설명했습니다. 또한 우리는 라디오나 신문에 사용된 광고 비용의 양을 나타내는 데이터 또한 가지고 있으므로, 두 플랫폼과 판매량의 관계에 대해서 알고 싶습니다.

한 가지 방법은 각각 다른 플랫폼에 대한 예측변수를 사용하여 세 개로 분리된 단순 선형 회귀를 사용하는 것입니다. 예를 들어 라디오 광고 비용에 기반하여 판매량을 예측하는 단순 선형 회귀를 생각할 수 있습니다.



<img src = "https://py-tonic.github.io/images/islr/t3.3.png">



결과는 위 테이블에 나와 있습니다.

우리는 $1,000의 라디오 광고를 통해 203개의 판매량 증가를 볼 수 있습니다.

그 아래의 테이블은 신문에 대한 단순 선형 회귀의 결과입니다. $1,000의 신문 광고는 약 55개의 판매량 증가를 이뤄냅니다.

그러나 각각의 예측 변수에대해 선형 회귀 모델을 분리시키는 것은 그다지 만족스럽지 않습니다.

첫 번째, 각각의 광고 비용이 별도의 회귀 방정식과 연관되어 있기 때문에 주어진 매출 수준을 어떻게 단일 예측해야 할지 불투명합니다.

두 번째, 각각의 세가지 회귀 방정식은 다른 두 가지 플랫폼에서 추정한 회귀계수를 무시합니다.

우리는 플랫폼 예산이 우리의 데이터 셋을 구성하는 200개 시장에서 서로 상관관계가 있다면, 이는 판매에 미치는 개별 플랫폼의 영향력에 대한 매우 잘못된 추정이 될 수 있다는 것을 알게 됩니다.

각각의 예측 변수에 대해 단순 선형 회귀 모델을 분리시키는 것 보다 더 나은 접근 방식은, 단순 선형 회귀를 여러 예측 변수에 대해 확장시키는 것입니다.

우리는 예측 변수마다 각각의 기울기를 부여하므로써 단일 모델을 구성할 수 있습니다.

$p$개의 예측 변수가 존재한다고 가정하면, 다중 선형 회귀 모델은 다음과 같이 정의됩니다.

$$Y = \beta_0 +\beta_1X_1+\beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p+\epsilon\tag{3.19}$$



### 3.2.1 Estimating the Regression Coefficients

3.19에서 정의한 $\beta_0,...,\beta_p$는 알 수 없으므로 추정해야 합니다.

추정치에 대한 식은 다음과 같이 적을 수 있습니다.

$$\hat y =\hat \beta_0 + \hat\beta_1x1+\cdot\cdot\cdot+\hat\beta_px_p\tag{3.21}$$

파라미터 추정은 단순 선형 회귀와 동일한 방식으로 최소 제곱 접근법을 사용합니다. 

$$RSS= \sum\limits_{i=1}^n(y_i-\hat y_i)^2 \tag{3.22}$$

3.4에 주어진 단순 선형 회귀에 대한 추정과 달리, 다중 회귀 계수 추정은 복잡하므로 행렬 대수의 형태로 쉽게 표현할 수 있습니다.

그런 이유로 여기서는 표기하지 않고 넘어갑니다.(R과 같은 통계패키지를 사용해서 나타낼 수 있습니다.)



<img src = "https://py-tonic.github.io/images/islr/3.4.png">

위 그림은 $p=2$에 대한 예제 데이터셋을 최소 제곱법을 통해 피팅시킨 예시입니다.



<img src = "https://py-tonic.github.io/images/islr/t3.4.png">



위 테이블(3.4)은 TV, 라디오, 신문 광고 예산에 대한 다중 회귀 계수 추정을 나타냅니다.

우리는 위와 같은 결과를 다음과 같이 해석합니다. TV와 신문 광고의 일정 금액에 대해 라이도 광고에 $1,000를 추가 지출하면 약 189대의 판매량 증가로 이어진다.

테이블 3.1, 3.3과 비교해봤을 때 TV와 라디오에 대한 다중 회귀 분석 계수 추정은 단순 선형 회귀 계수 추정과 비슷하다는 것을 알 수 있습니다.

그러나 신문의 회귀 계수 추정치는 테이블 3.3에는 0이 아니었으나 다중 회귀 분석에서는 0에 가깝고 p-value 값 또한 매우 높습니다. 이를 통해 단순 선형 회귀와 다중 회귀 분석이 다른 것을 알 수 있습니다.

왜 신문 예산에 대해서만 단순 회귀 분석과 반대의 결과가 나왔을까요? 테이블 3.5에 나와있는 세 가지 예측 변수와 반응 변수에 대한 상관 관계를 고려해봅시다.

<img src = "https://py-tonic.github.io/images/islr/t3.5.png">



라디오와 신문 사이의 상관관계를 보면 0.35입니다. 이 것은 신문에 광고를 내는 시장은 라디오에 더 많은 광고를 내는 경향이 있다는 것을 보여줍니다.

이 것은 신문 판매가 라디오 광고의 대용으로 생각할 수 있습니다. 이런 반 직관적인 상황은 일상에서 흔합니다.

일정 기간 동안 주어진 해변에서 수집된 데이터에 대해 상어 공격과 아이스크림 판매의 회귀 분석을 실행하는 것은 판매와 신문 사이에 나타난 것과 유사한 긍정적인 관계를 보여줄 것입니다. 물론, 누구도 상어의 공격을 줄이기 위해 아이스크림 판매를 금지해야한다고 제안하지 않습니다.

실제로 높은 온도는 많은 사람들이 해변을 방문하게 만들고, 많은 아이스크림 판매량과 많은 상어의 공격이라는 결과를 초래합니다.

아이스크림 판매와 온도 대비 공격의 다중 회귀 분석은 직관적으로 알 수 있듯, 이전의 예측 변수가 온도에맞게 조정된 후 더이상 중요하지 않다는 것을 보여줍니다.



### 3.2.2 Some Important Questions

우리가 다중 선형 회귀를 수행할 때 우리는 일반적으로 몇 가지 중요한 질문에 답하는 것에 관심이 있습니다.

1. 최소한 하나의 예측 변수는 반응 변수를 예측하는 데 유용한가?
2. 모든 예측 변수가 Y를 설명하기 위해 필요한가? 아니면 예측 변수의 일부만 유용한가?
3. 어떻게 모델을 데이터에 잘 피팅 시킬 수 있을까?
4. 예측 변수의 집합이 주어질 때 어떻게 반응 변수 값을 예측해야 하고 예측에 대한 정확도를 어떻게 측정할까?



질문들에 대해 해결해봅시다.



**One: Is There a Relationship Between the Response and Predictors?**

단순 선형 회귀를 떠올려 봅시다. 반응 변수와 예측 변수의 관계를 결정하기 위해서 우리는 단순히 $\beta_1 = 0$인지 체크했습니다.

$p$개의 예측 변수를 사용하는 다중 회귀 분석에서는 $\beta_0=\beta_1=\cdot\cdot\cdot=\beta_p=0$인지 확인해봐야 합니다.

단순 선형 회귀에서는 가설 검정을 통해 이 질문에 대답했습니다. 귀무 가설을 테스트해봅시다.

- $H_0 :\beta_0=\beta_1=\cdot\cdot\cdot=\beta_p=0$
- $H_1:$ 최소한 하나의 $\beta_j\neq0$

가설 검정은 $F-statistic$을 통해 수행됩니다.

$$F =\frac{(TSS-RSS)/p}{RSS/(n-p-1)}\tag{3.23}$$

> $R^2$와 차이점은 분자가 TSS가 아닌 RSS라는 것..!
>
> 보통 MSR/MSE 로 나타내며, 단일 회귀 분석에서 p=1이니까 n-p-1 = n-2이고,
>
> $\frac1{n-2}RSS = MSE$ 입니다.
>
> MSE는 우리가 알다 시피, 에러텀의 분산으로 나타내지는 값들을 표현하므로 ''회귀로 좁힐 수 없는 거리''로 해석하면 편할 것 같습니다.
>
> MSR은 $R^2$와 똑같은 분자입니다. TSS가 y의 분산 같은 느낌이고(엄밀힌 아니지만)거기서 회귀로 좁힐 수 없는 거리를 빼주면 실질적인 의미는 '전체 편차 - 회귀로 줄일 수 없는 거리 = 회귀로 줄일 수 있는 거리'가 되겠죠? 즉 회귀로 거리를 많이 줄이면 줄일수록 MSR이 커지고 F통계량이든 t-value든 커지게 됩니다!



$TSS=\sum(y_i-\bar y)^2, RSS=\sum(y_i-\hat y_i)^2$ 처럼 선형 회귀의 가정과 동일하면 다음과 같은걸 볼 수 있습니다.

$$E[RSS/(n-p-1)]=\sigma^2$$

$$E[TSS-RSS/p]=\sigma^2$$

따라서 반응 변수와 예측 변수의 관계가 없을 때 $F-statisic$은 1 근처의 값을 가지게 됩니다.

반면 $H_1$이 맞다면, $E[(TSS-RSS)/p]>\sigma^2$이기 때문에 $F$는 1보다 큽니다.



라디오, TV, 신문 판매량에 대한 $F$통계량을 포함한 다중 회귀 모델은 아래 표에 있습니다.

 <img src = "https://py-tonic.github.io/images/islr/t3.6.png">

이 예에서는 $F$ 통계량이 570입니다. 이는 1보다 훨씬 크기 때문에 귀무 가설 $H_0$에 반대하는 설득력 있는 증거를 제공합니다.

즉 $F$가 크다는 것은 적어도 하나의 광고 플랫폼이 판매량과 관련 있다는 것입니다.

그러나, $F$통계량이 어느정도 값을 가져야 귀무가설을 기각하고 관련이 있다고 결론지을 수 있을까요?

식에서 알 수 있듯, $n,p$ 값에 따라 다릅니다. 만약 $n$이 크다면, $F$통계량은 커지고 귀무 가설을 기각하는 증거가 됩니다.

만약 $H_0$가 진실이고, $\epsilon_i$가 정규분포를 따른다면, $F$통계량은 $F$분포를 따릅니다.

광고 데이터의 경우 위 테이블의 $F$통계량과 관련된 $p-value$값은 본질적으로 0이므로, 우리는 적어도 하나의 플랫폼이 매출 증가와 연관되어 있다는 강력한 증거를 가집니다.

3.23에서 $H_0$은 모든 회귀 계수가 0인지 테스트하고 있습니다. 때때로 계수의 부분집합 $q$가 0인지 테스트하고 싶습니다.

이에 대한 귀무 가설은 다음과 같습니다.

$$H_0: \beta_{p-q+1} = \beta_{p-q+2}=\cdot\cdot\cdot=\beta_p=0$$

이 경우 마지막 $q$를 제외한 모든 변수를 사용하는 두 번째 모델을 피팅시킵니다.

해당 모델에 대한 $RSS = RSS_0$라고 가정합시다. 그렇다면 적절한 $F$통계량은 다음과 같습니다.

$$F = \frac{(RSS_0 - RSS)/q}{RSS/(n-p-1)}\tag{3.24}$$



 테이블 3.4에서 각 개별 예측 변수에 대한 t-통계량및 $p-value$ 값을 알고 있습니다.

이 값은 각 예측 변수가 다른 예측 변수에 대해 조정된 후 반응 변수와 관련 있는지 여부에 대한 정보를 제공합니다. 모델에 변수를 추가하는 부분적인 효과를 알 수 있습니다. 예를 들어, 앞에서 논의한 바와 같이 이러한 $p-value$는 TV와 라디오가 판매량과 관련이 있지만, 이 두가지 상황에서 신문이 판매와 연관되어 있다는 증거가 없음을 나타냅니다.

각 변수에 대해 이런 개별 $p-value$가 주어졌는데도 왜 $F$통계량을 고려해야 할까요? 결국 개별 변수에 대한 $p-value$중 하나가 매우 작을 경우 적어도 하나의 예측 변수가 반응과 관련 있을 가능성이 존재합니다. 하지만 이 논리에는 특히 $p$가 큰 경우 결함이 존재합니다.

$p=100$일 때 모든 베타값이 0인 예시를 고려해봅시다. 모든 변수가 실제로 반응과 관련이 없습니다. 이 상황에서는 각 변수와 관련된 $p-value$의 5%가 우연한 기회로 인해 0.05 이하가 될 수 있습니다.

다시말해서, 예측 변수와 반응 변수 사이 진정한 연관성이 없는 경우에도, 약 5개의 작은 $p-value$를 볼 수 있습니다. 사실 우리는 우연히 0.05 이하의 $p-value$를 최소한 한 개 이상 관찰할 것이라고 거의 장담하고 있습니다.

따라서 변수와 반응 사이에 연관성이 있는지 여부를 결정하기 위해 개별 t-통계량 및 관련 $p-value$를 사용하는 것은 관계가 존재한다고 잘못 결론 내릴 가능성이 매우 높습니다.

$F$-통계량을 사용하여 예측 변수와 반응 변수의 연관성을 검정하는 방법은 상대적으로 $p$가 작을 때($n$ 보다) 효과가 있습니다. 하지만 우리는 때때로 많은 수의 변수를 다룹니다.

$p>n$일 경우 추정할 계수 $\beta_j$가 관측치 보다 많습니다.

이런 경우에는 최소제곱법을 사용해서 모델을 피팅시킬 수 없으므로 $F$-통계량 또한 사용할 수 없습니다. 

이런 고차원 설정에 대해서는 6 장에서 다룹니다.



**Two: Deciding on Important Variables**

이전 섹션에서 설명한 바와 같이 다중 회귀 분석의 첫 번째 단계는 $F$-통계량을 계산하고 관련$p-value$를 검토하는 것입니다.

만약 우리가 $p-value$에 기반하여 적어도 하나의 예측 변수가 반응과 관련이 있다고 결론을 내린다면, 어느 것이 중요한지 궁금한 것은 당연합니다.

우리는 테이블 3.4와 같이 개별 $p-value$를 볼 수 있지만, 논의된 바와 같이 $p$가 크면 우리는 몇 가지 잘못된 발견을 할 가능성이 있습니다.

모든 예측 변수가 반응과 관련이 있을 순 있겠지만 예측 변수의 부분집합이 반응과 관련이 있는게 더 흔한 케이스 입니다.

관련이 있는 예측 변수를 포함한 단일 모델을 피팅시키기 위해서 반응과 관련있는 예측 변수를 결정하는 문제를 $variable$ $selection$이라고 합니다. 자세한건 6장에서 다루므로 여기서는 고전적인 변수 선택에 대해서 살펴봅니다.

이상적으로는 예측 변수의 서로 다른 부분집합을 포함하는 여러 모델을 실험하여 변수 선택을 수행하고자 합니다. 예를 들어 $p=2$인 경우 4개의 모델을 고려할 수 있습니다.

1. 모델이 변수를 포함하지 않는 경우
2. $X_1$만 포함하는 경우
3. $X_2$만 포함하는 경우
4. $X_1,X_2$를 포함하는 경우

우리가 고려한 모델중의 가장 좋은 모델을 선택하면 됩니다.

어떻게 최고의 모델을 선정할까요? 다양한 통계량을 사용해서 모델을 판단할 수 있습니다.(물론 이것도 6장에서 다룹니다.)

우리는 또한 패턴을 찾기위해서, 잔차 등 어떤 모델의 출력이 가장 좋은지 결정할 수 있습니다.

하지만 이런 방식의 모든 모델을 비교하는건 $p$가 크면 기하 급수적으로 늘어나므로 비현실적입니다.

세 가지 고전적 접근 방식을 살펴봅시다.

- $Forward$ $selection$
    - 절편은 포함하지만 예측 변수는 없는 Null 모델에서 출발하여 단순한 p개의 선형 회귀를 피팅시킨 후 가장 낮은 RSS를 생성하는 변수를 null모델에 추가
- $Backward$ $selection$
    - 모든 변수가 존재하는 모델로 시작해서 $p-value$가 큰 변수들을 제거합니다. 제거한 뒤 또 피팅시키고 또 제거를 반복합니다. 
- $Mixed$ $selection$
    - 위 두 선택을 섞은 버전입니다. 처음엔 Forward 처럼 변수 없이 시작합니다.그리고 가장 적합한 변수를 하나씩 추가합니다. 물론 광고 예제에서 지적했듯 변수에 대한 $p-value$는 모델에 대한 새로운 예측 변수가 추가됨에 따라 더 커질 수  있습니다. 따라서 모델의 변수 중 하나에 대한 $p-value$가 특정 임계값을 초과하면 해당 변수를 모델에서 제거합니다.





**Three: Model Fit**

일반적인 모델의 적합도를 수치적으로 측정하는 방법은 $RSE$ 와 $R^2$입니다.

이런 수량은 단순 선형 회귀 분석과 동일한 방식으로 계산 및 해석됩니다.

단순 회귀에서 $R^2$는 반응과 예측 간의 상관 관계의 제곱이었습니다. 사실 적합된 선형 모델의 한가지 특성은 가능한 모든 선형 모델 간의 상관 관계를 최대화 합니다.

$R^2$값이 1에 가까우면 모델이 반응 변수 분산의 많은 부분을 설명한다는 것을 나타냅니다.

광고 데이터에서 세 가지 광고 플랫폼을 모두 사용하여 매출을 예측하는 모델의 $R^2 = 0.8972$이고, TV와 라디오만 사용하여 매출을 예측하는 모델은 $R^2=0.89719$ 입니다.

우리는 신문 광고를 포함한 모델이 비록 $p-value$가 유의미하지 않더라도 $R^2$값을 증가시킨다는 것을 볼 수 있습니다.

즉 $R^2$는 반응과 약한 관계를 갖는 변수를 모델에 추가하더라도 항상 증가하는 것을 볼 수 있습니다.

이는 최소 제곱 방정식에 다른 변수를 추가하면 훈련 데이터를 더 정확하게 피팅시킬 수 있기 때문입니다.

본질적으로 신문은 훈련 샘플에 피팅된 모델에 대한 실질적인 향상을 가져오지 않으므로, 신문을 포함하는 모델은 오버피팅으로 인해 독립적인 테스트 케이스에 대해 낮은 결과를 초래할 가능성이 존재합니다.

대조적으로 오직 TV에 대한 변수만 포함하는 모델의 $R^2$는 0.61입니다. 라디오를 추가하면 (당연히) $R^2$의 향상이 존재합니다. TV와 라디오 지출을 이용해 판매량을 예측하는 모델이 TV만 사용하는 모델보다 훨씬 낫습니다.

> $R^2$식을 떠올려 보면 결국 저건 분자식인 TSS-RSS와 관련이 있는데,
>
> 여기서 RSS가 더 작아지므로 회귀 분석으로 설명할 수 있는 거리가 늘어나므로 $R^2$값이 커지게 됩니다.

TV, 라디오만 예측변수로 사용하는 모델은 RSE가 1.681이고, 신문을 포함하는 모델은 1.686(테이블 3.6)입니다.

어떤 이유로 RSE 값이 증가했는지 알아봅시다. 우선 RSE는 다음과 같의 정의 할 수 있습니다.

$$RSE = \sqrt{\frac{1}{n-p-1}RSS}\tag{3.25}$$

RSS의 감소가 $p-value$의 증가에 비해 작은 경우, 변수가 더 많은 모델은 더 높은 RSE를 가질 수 있습니다.

> $p-value$가 높다는 것은 일반적으로 $\beta$값이 0일 확률이 높은 얘기입니다.
>
> 딱히 모델의 설명력을 올리지는 않는 변수가 RSS를 조금 떨어뜨리면 그 변수는 좋지 않다는 얘기입니다.

앞서 논의한 RSE, $R^2$를 보는 것 외에도 데이터를 플로팅 하는 것이 유용할 수 있습니다.

그래프를 통해 수치 통계에서 볼 수 없는 모델의 문제점을 드러낼 수 있습니다. 예를 들어, Fig 3.5는 TV와 라디오에 대한 판매량을 3차원 그래프를 통해 나타냅니다.

일부 관측치는 위에있고, 일부 관측치는 최소 제곱 평면 아래에 존재합니다. 특히 선형 모델은 광고비의 대부분이 TV나 라디오에 독점적으로 사용되었던 사례에 대해서는 판매량을 과대 추정하는 것 같습니다. 반대로 예산이 두 플랫폼으로 나눠진 경우 과소 추정합니다. 이는 비선형 패턴을 선형 회귀 분석을 사용하여 정확하게 모델링 할 수 없음을 나타냅니다.

<img src = "https://py-tonic.github.io/images/islr/3.5.png">

광고 매체들 사이의 시너지 효과나 상호작용 효과를 시사하는데, 플랫폼을 결합함으로써 어떤 단일 매체를 사용하는 것 보다 더 큰 판매량 증가를 초래합니다. 섹션 3.3.2에서는 상호 작용 항을 사용하여 이러한 시너지 효과를 수용하도록 선형 모델을 확장하는 것에 대해 다룹니다.

**Four: Predictions**

다중 회귀 모형을 피팅 시킨 후에는 예측 변수에 대한 일련의 값을 기반으로 반응을 예측하기 위해 3.21을 적용하는 것이 간단합니다. 그러나 이 예측과 관련된 불확실성에는 세 가지 종류가 있습니다.

1. 진짜 계수$(\beta)$에 대한 추정치 $(\hat \beta)$로 이루어진 최소 제곱 평면은 실제 모집단 회귀 평면의 추정치일 뿐입니다.

    $$\hat Y =  \hat \beta_0 + \hat\beta_1 X_1+\cdot\cdot\cdot + \hat\beta_pX_p$$

    $$f(X) = \beta_0+\beta_1X_1+\cdot\cdot\cdot + \beta_pX_p$$

    계수 추정치에 대한 불확실성은 2장에서 다룬 reducible error와 관련이 있습니다. $\hat Y$가 $f(X)$에 얼마나 가까운지 결정하기 위해 신뢰구간을 계산할 수 있습니다.

2. 물론 실제로 $f(X)$에 대한 선형 모델을 가정하는 것은 거의 항상 현실의 근사치이므로, 우리가 모델 편향이라고 부르는 잠재적으로 reducible error의 추가적인 소스가 있습니다. 그래서 우리가 선형 모델을 사용할 때 우리는 사실 모집단의 평면에 대한 가장 좋은 선형 근사치를 추정합니다. 그러나 여기서는 이러한 불일치를 무시하고 선형 모델이 올바른 것 처럼 작동합니다.

3. 앞서 얘기한 것 처럼 f(X)를 알아도 모델의 랜덤 오차 부분 때문에 반응 값은 완벽하게 예측할 수 없습니다. 2장에선 irreducible error라고 언급했습니다. $\hat Y$와 $Y$는 얼마나 다를까요? 우리는 이 질문에 대답하기 위해 예측 구간을 사용합니다. 예측 구간은 $f(X)$에 대한 추정치의 오차(reducible error)와 개별 점이 모집단의 회귀 평면(irreducible error)과 얼마나 다를 것인지에 대한 불확실성을 모두 포함하기 때문에 항상 신뢰 구간보다 넓습니다.

우리는 신뢰 구간을 사용하여 많은 도시에 대한 평균 판매량을 둘러싼 불확실성을 정량화합니다.

예를 들어, 각 도시의 TV광고에 10만 달러가 지출되고, 라디오 광고에 2만 달러가 지출된다는 점을 고려하면, 95%의 신뢰 구간은 [10,985, 11,528]입니다.

우리는 이것을 이 형태의 구간 95%가 $f(X)$의 실제 값을 포함할 것 이라는 의미로 해석합니다. 반면에, 예측 구간은 특정 도시의 판매를 둘러싼 불확실성을 정량화 하는데 사용될 수 있습니다.

그 도시에서 10만 달러가 TV광고에 사용되고, 2만 달러가 라디오 광고에 쓰인다면, 95% 예측 간격은 [7,930, 14,580]입니다.

우리는 이 것을 구간의 95%가 이 도시에 대한 $Y$의 진짜 값을 포함할 것 이라는 의미로 해석합니다. 두 구간 모두 11,256을 중심으로 하지만, 예측 구간은 신뢰 구간보다 상당히 넓어 여러 장소에 대한 평균 판매량에 비해 특정 도시의 판매에 대한 불확실성이 증가했음을 반영합니다.



## 3.3 Other Considerations in the Regression Model

 

### 3.3.1 Qualitative Predictors

지금까지의 논의에서, 우리는 선형 회귀 모델의 모든 변수가 정량적이라고 가정했습니다. 그러나 실제로 이것은 꼭 그렇지는 않습니다. 종종 일부 입력 변수들은 정성적입니다.

예를 들어, 아래 그림에 표시된 신용 데이터는 잔액과 연령, 카드, 교육, 소득, 한도, 등급 등 몇 가지 정량적 예측 변수를 포함합니다.



<img src = "https://py-tonic.github.io/images/islr/3.6.png">



**Predictors with Only Two Levels**

다른 변수를 무시하고 남성과 여성의 신용카드 잔액 차이를 조사한다고 가정합시다. 정성적 예측 변수(인자 라고도 불리는)가 두 단계 혹은 가능한 값만 가지고 있는 경우 회귀 모형에 이를 통합하는 것은 매우 간단합니다.

단순히 두 개의 가능한 숫자 값을 갖는 지표나 더미 변수를 만들면 됩니다.

$$x_i = \begin{cases} 1\quad if\ ith\ person\ is\ female\\0\quad if\ ith\ person\ is\ male \end{cases}\tag{3.26}$$



회귀 방정식에 적용하면 다음과 같습니다.

$$y_i = \beta_0+\beta_1x_i+\epsilon_i = 
\begin{cases} 
\beta_0+\beta_1+\epsilon_i & if \ ith\ person\ is\  female\\ \beta_0+\epsilon_i & if \ ith\ person\ is\ male  
\end{cases}\tag{3.26}$$



이제 $\beta_0$는 남성의 평균 신용카드 잔액, $\beta_0+\beta_1$은 여성의 평균 신용카드 잔액이고, $\beta_1$을 그 차이로 해석할 수 있습니다.

아래의 테이블은 모델 3.27와 관련된 계수 추정과 다른 정보를 보여줍니다.

<img src = "https://py-tonic.github.io/images/islr/t3.7.png">

여기서 주목해야할 점은 더미 변수에 대한 $p-value$값이 매우 높다는 것입니다. 성별 간 평균 신용카드 잔액 차이에 대한 통계적 증거가 없다는 의미입니다.

성별을 통해 식을 3.27로 변경하는 결정은 임의적이며, 회귀 적합성에는 영향을 미치지 않지만 계수의 해석을 변경합니다.(해석을 변경한다는게 0,1을 어떤 성별에 매칭시키느냐에 따라 부호가 바뀔 수 있다는 점을 얘기하는듯.)

0/1로 바꾸는 것 대신 다음과 같이 더미 변수를 생성할 수 있습니다.

$$x_i = \begin{cases} 1\quad if\ ith\ person\ is\ female\\              -1 \quad if\ ith\ person\ is\ male \end{cases}$$

모델은 다음과 같이 변경됩니다.

$$y_i = \beta_0+\beta_1x_i+\epsilon_i = 
\begin{cases} 
\beta_0+\beta_1+\epsilon_i & if \ ith\ person\ is\  female\\ \beta_0-\beta_1+\epsilon_i & if \ ith\ person\ is\ male  
\end{cases}$$

이제 $\beta_0$는 성별 효과를 무시하고 평균 신용카드 잔액으로 해석할 수 있습니다.

물론 최종 예측은 위 테이블과 동일합니다, 다만 이제 해석하는 방식이 바뀝니다. 성별에 대한 계수가 각각 평균으로 부터 $\pm 19.73/2$가 됩니다.



**Qualitative Predictions with More than Two Levels**

정성적 예측 변수의 레벨이 세 개 이상인 경우 단일 더미 변수는 가능한 모든 값을 나타낼 수 없습니다. 이런 상황에서 우리는 추가적인 더미 변수를 만들 수 있습니다.

첫 번째는 다음과 같습니다.

$$x_{i1} = \begin{cases} 1\quad if\ ith\ person\ is\ Asian\\              0 \quad if\ ith\ person\ is\ not\ Asian \end{cases}\tag{3.28}$$

두 번째는 다음과 같습니다.

$$x_{i2} = \begin{cases} 1\quad if\ ith\ person\ is\ Caucasian\\              0 \quad if\ ith\ person\ is\ not\ Caucasian \end{cases}\tag{3.29}$$

이러한 변수들은 모델에 적용하면 다음과 같아집니다.

$$y_i = \beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\epsilon_i = 
\begin{cases} 
\beta_0+\beta_1+\epsilon_i & if \  Asian\\ \beta_0+\beta_2+\epsilon_i & if \ Caucasian\\
\beta_0+\epsilon_i & if \ African\ American
\end{cases}\tag{3.30}$$



이제 $\beta_0$는 아프리카계 미국인의 평균 신용카드 잔액으로 해석 가능하며, $\beta_1$은 아시아인과 아프리카계 미국인의 평균 잔액의 차이이며, $\beta_2$는 코카시안계열과 아프리카계 미국인의 평균 잔액 차이로 해석할 수 있습니다.

위 예시를 통해 더미 변수가 레벨보다 하나 적은 것을 알 수 있으며, 더미 변수가 없는 레벨은 (이 예시에서 아프리칸 아메리칸)은 베이스라인 입니다.

<img src = "https://py-tonic.github.io/images/islr/t3.8.png">

위 표를 통해 아프리카계 미국인의 추정 잔액은 531달러 임을 알 수 있습니다. 아시아계 카테고리는 아프리카계 미국인 카테고리보다 부채가 18.69달러 적어지고, 코카시안 계는 아프리카계 미국인 보다 부채가 ​12.5달러 적어지는 것으로 추정됩니다.

그러나 두 더미 변수에 대한 계수 추정치와 관련된 $p-value$가 매우 크므로, 인종 간의 신용카드 잔액의 실제 차이에 대한 통계적 증거가 없음을 나타냅니다.

다시 말하자면, 기준 카테고리는 임의로 선정되므로, 이 선택과 상관없이 각 그룹의 최종 예측은 동일합니다. 그러나 계수와 $p-value$는 더미 변수의 코딩 선택에 따라 달라집니다.

개별 계수에 의존하기 보다는 F-test를 사용하여 $H_0: \beta_1=\beta_2=0$을 시험할 수 있습니다.

이는 코딩에 따라 달라지지 않습니다. 이 F-test는 $p-value$가 0.96으로 귀무가설을 기각할 수 없음을 나타냅니다. (잔액과 인종 사이에 상관관계가 없다.)



### 3.3.2 Extension of the Linear Model

표준 선형 회귀 모델(식 3.19)은 해석 가능한 결과를 제공하며 많은 실제 문제에서 상당히 효과적입니다. 그러나, 그것은 종종 실제로 몇 가지 매우 제한적인 가정을 생성합니다.

가장 중요한 두 가지 가정은 예측 변수와 반응 변수의 관계가 추가적(additive)이고 선형적이라는 점입니다.

'추가적'이라는 의미는 예측 변수 $X_j$의 변화가 반응 $Y$에 미치는 영향은 다른 예측 변수의 값과 무관하다는 뜻이고 '선형적'이라는 의미는 $X_j$의 단일 단위 변화에 따른 반응$Y$의 변화가 $X_j$의 값에 관계없이 일정하다는 것입니다.

이 책에서는 두 가지 가정을 완화시키는 여러가지 정교한 방법들을 검토합니다. 여기서는 선형 모델을 확장하기 위한 몇 가지 일반적인 고전적 접근법을 간략히 살펴봅니다.



**Removing the Additive Assumption**

이전에 분석했던 광고 데이터에서 우리는 TV와 라디오가 판매량과 관련이 있는 것으로 결론지었습니다.

이러한 결론의 근거를 형성한 선형 모델은 판매량의 증가가 각각의 변수에 대해 독립적이라고 가정했습니다. 예를 들어, 선형 모델(3.20)은 TV의 단일 단위 증가가 라디오에 소비되는 금액에 관계없이 항상 $\beta_1$이라고 기술하고 있습니다.

그러나 이 단순한 모델은 틀릴 수 있습니다. 라디오 광고에 돈을 쓰는 것이 실제로 TV광고의 효과를 증가시키므로, 라디오가 증가함에 따라 TV의 기울기 부분이 증가해야 한다고 가정해봅시다.

이런 상황에서 10만 달러의 고정 예산을 감안할 때, 라디오에 반을 쓰고 TV에 반을 쓰는 것은 한 쪽에 모두 사용하는 것 보다 더 많은 매출을 올릴 수 있습니다.

마케팅에서는 시너지 효과로 알려져있고, 통계에서는 상호작용 효과 라고 언급합니다.



<img src = "https://py-tonic.github.io/images/islr/3.5.png">





위 그림은 광고 데이터에 그러한 경향이 있음을 보여줍니다.

TV 또는 라디오의 레벨이 낮을 때 실제 판매량은 선형 모델에 의해 예측된 것 보다 낮다는 점에 주목해야합니다. 그러나 광고가 두 매체 사이에 분할될 때 모델은 판매를 과소 평가하는 경향이 있습니다.

두 가지 변수를 가지는 표준 선형 회귀 모델을 고려해봅시다.

$$Y = \beta_0+\beta_1X_1 + \beta_2X_2+\epsilon$$

이 모델에 따르면 우리가 $X_1$을 단일 단위 만큼 증가시키면, $Y$는 평균적으로 $\beta_1$단위 만큼 증가할 것 입니다. $X_2$의 존재는 이 상태를 변경하지 않는다는 점에 주목해야합니다. 즉 $X_2$의 값에 관계없이 $X_1$의 단일 단위 증가는 $Y$의 $\beta_1$단위 증가를 유발할 것 입니다.

상호 작용 효과를 허용하도록 이 모델을 확장하는 한 가지 방법은 $X_1$과 $X_2$의 곱을 계산하여 구성된 상호 작용 텀이라는 세 번째 예측 변수를 포함하는 것입니다.

$$Y = \beta_0+\beta_1X_1+\beta_2X_2+\beta_3X_1X_2+\epsilon \tag{3.31}$$

이 상호작용 텀을 포함하면 '추가적' 가정이 어떻게 완화될까요? 위 식은 다음과 같이 변경할 수 있습니다.

$$Y = \beta_0+(\beta_1+\beta_3X_2)X_1 + \beta_2x_2+\epsilon \\ =\beta_0+\tilde \beta_1X_1+\beta_2X_2+\epsilon \tag{3.32}$$

이제 $X_1$항이 $X_2$와 관련이 있으므로 $X_1$의 $Y$에 대한 효과는 더이상 예측 변수들에 대해 독립적이지 않습니다.

예를 들어, 우리가 공장의 생산성에 관심이 있다고 가정합시다. 생산 라인 수와 전체 근로자 수를 기준으로 생산 단위를 예측하려고 합니다.

생산 라인 증설 효과는 생산 라인을 운용할 수 있는 인력이 없으면 생산량을 늘리지 않기 때문에 근로자 수에 따라 달라질 것으로 보입니다.

직관적으로 우리가 말한 상호 작용 텀을 모델에 포함해야 할 것 같습니다.

$$units \approx 1.2+3.4\times lines +0.22\times workers + 1.4\times(lines\times workers) \\ \quad\quad\  = 1.2+(3.4+1.4\times workers)\times lines + 0.22\times workers$$

즉, 라인을 추가하면 3.4+1.4 x 노동자가 생산한 단위 만큼 늘어날 것 입니다. 즉 노동자가 늘어날수록 생산 라인의 효과는 더 강해집니다.

다시 돌아와서 광고 데이터의 선형 모델에 상호작용 텀을 추가해봅시다.

$$sales = \beta_0+\beta_1\times TV +\beta_2\times radio + \beta_3(radio\times TV)+\epsilon \\ = \beta_0+(\beta_1+\beta_3\times radio)TV +\beta_2\times radio + \epsilon \tag{3.33}$$

우리는 $\beta_3$를 라디오 광고의 단일 단위 증가에 대한 TV광고의 효과 증가로 해석할 수 있습니다.

위 모델의 피팅 결과는 아래의 테이블에서 확인할 수 있습니다.

<img src = "https://py-tonic.github.io/images/islr/t3.9.png">

위 테이블은 추가된 상호 작용 텀이 기존의 모델 보다 우수하다는 점을 보여줍니다.

$R^2$ 또한 96.8%로 기존의 모델(89.7%)보다 훨씬 우수합니다. 즉 (96.7 - 89.7)/(100 - 89.7) = 69%가 상호작용 항으로 설명되었음을 의미합니다.

hierarchical principle은 상호작용 텀을 모델에 포함시킬 경우, 계수와 관련된 $p-value$가 유의미하지 않더라도 main effect도 포함해야한다고 명시합니다.

즉, $X_1$과 $X_2$의 상호작용이 중요해 보이면 계수 추정치의 $p-value$가 크더라도 $X_1,X_2$모두를 모델에 포함해야 합니다.

이 원리의 근거는 $X_1\times X_2$가 반응과 관련이 있다면 $X_1\times X_2$의 계수가 0인지 아닌지는 관심이 없고, 또한 $X_1\times X_2$가 일반적으로$X_1, X_2$와 관련이 있으므로 이를 배제하는 것은 상호작용의 의미를 바꾸는 경향이 있습니다.

앞선 예시에서 양적 변수인 TV와 라디오의 상호작용을 고려했습니다. 그러나 상호작용은 정성적 변수와 정량적 변수의 조합에도 똑같이 적용할 수 있습니다.

사실 정량적, 정성적 변수의 상호작용은 특히 좋은 해석을 가집니다.

우리는 소득(정량적)과 학생(정성적)변수를 사용하여 반응을 예측하고 싶습니다. 상호작용 텀이 없을 때 모델은 다음과 같은 형태를 취합니다.

$$balance_i \approx \beta_0+\beta_1x\times income_i + 
\begin{cases} 
\beta_2 & if \ ith\ person\ is\  a\ student\\ 
0 & if \ ith\ person\ is\ not\ a\ student
\end{cases}\\
\quad\quad\quad =\beta_1\times income_i +
\begin{cases}
\beta_0+\beta_2 & if\ ith\ person\ is\ a\ student\\ 
\beta_0 & if\ ith\ person\ is\ not\ a\ student
\end{cases}
\tag{3.34}$$

학생과 비학생을 위한 라인은 절편이 다르지만 수입에 대한 기울기가 $\beta_1$로 동일합니다.

이는 아래 그림의 왼쪽에 나와있습니다.

<img src = "https://py-tonic.github.io/images/islr/3.7.png">

선이 평행하다는 의미는 소득의 단위 증가의 반응에 대한 평균적인 영향은 개인이 학생인지 여부에 달려있지 않다는 의미입니다. 소득의 변화가 학생의 신용카드 잔액과 학생이 아닌 신용카드 잔액에 매우 다른 영향을 미칠 수 있기 때문에 이는 모델에 대한 잠재적인 한계를 나타냅니다.

이러한 제한은 학생의 더미 변수와 소득을 곱하여 만든 상호작용 변수를 추가함으로써 해결 가능합니다.

$$balance_i \approx \beta_0+\beta_1x\times income_i + 
\begin{cases} 
\beta_2+\beta_3\times income_i & if \ student\\ 
0 & if \ not\ student
\end{cases}\\
\quad\quad\quad\  =\beta_1\times income_i +
\begin{cases}
(\beta_0+\beta_2)+(\beta_1+\beta_3)\times income_i & if\ student\\ 
\beta_0+\beta_1\times income_i & if\ not\ student
\end{cases}
\tag{3.35}$$



우리는 학생과 비 학생에 대한 회귀 직선을 두 개 가지고 있습니다. 하지만, 회귀 직선은 이제 다른 편향 뿐만 아니라 다른 기울기도 가집니다.

이는 소득의 변화가 학생과 비 학생의 신용카드 잔액에 영향을 다르게 미치도록 허용합니다.(위 그림의 오른쪽 판넬)

우리는 학생의 기울기가 비 학생의 기울기 보다 낮다는 점에 주목해야 합니다. 이는 소득의 증가가 학생이 비 학생에 비해 신용카드 잔액이 적은 것과 관련이 있습니다.



**Non-linear Relationships**

앞에서 설명한 것 처럼 식 3.19의 선형 회귀 모델은 독립변수와 반응 변수간의 선형 관계를 가정합니다.

하지만 특정 케이스에서 반응변수와 종속변수간의 관계가 비선형일 수 있습니다. 여기서는 다항 회귀 분석을 사용하여 비선형 관계를 수용하도록 선형 모델을 직접 확장하는 간단한 방법을 제시합니다.

아래 그림을 살펴보면 자동차 데티어 셋에 대한 여러 자동차에 대해 mpg(갤런 당 마일 수) vs 마력이 표시됩니다.



<img src = "https://py-tonic.github.io/images/islr/3.8.png">

오렌지색 선이 선형 회귀 직선입니다. mpg와 마력 사이에는 뚜렷한 관계가 있는 것 같습니다. 그러나 그 관계가 비선형인 것 처럼 보입니다.

선형 모델에 비선형 연관성을 통합하기 위한 간단한 접근 방법은 변환된 예측 변수 버전을 모델에 포함하는 것입니다.

예를 들어, 위 그림의 경우 2차원 형태인 것 처럼 보이므로 모델의 형태를 다음과 같이 만들 수 있습니다.

$$mpg = \beta_0 + \beta_1 \times horsepower +\beta_2 \times horsepower^2 + \epsilon \tag{3.36}$$

위 식은 마력에 대한 비선형 함수를 사용하여 mpg를 예측합니다. 하지만 여전히 선형 모델 입니다. 식은 단순히 $X_1=horsepower,\ X_2 = horsepower^2$을 가지는 다중 회귀 분석 모델입니다. 그래서 우리는 표준 선형 회귀를 다루듯 $\beta$값들을 추정 할 수 있습니다.

파란 선은 데이터에 대한 2차원 피팅 결과를 보여줍니다. 2차원 피팅이 단순 선형 회귀에 비해 더 나은 결과를 보여줍니다.

<img src = "https://py-tonic.github.io/images/islr/t3.10.png">



입력 변수에 대한 제곱항이 더 나은 결과를 보여준다면, 왜 세제곱, 네제곱, 다섯제곱을 포함하지 않을까요?

녹샌 선은 5차원 다항식에 대한 결과값을 보여줍니다. 너무 심하게 굴곡지며 이는 추가된 항이 데이터를 피팅시키는데 도움이 되지 않는 것 같습니다.

비선형 관계를 수용하도록 선형 모델을 확장하기 위해 방금 설명한 접근법을 다항 회귀라고 하는데, 이는 회귀식에 예측 변수의 다항식을 포함한 형태입니다.

자세한건 7장에서 다룹니다.



## 3.3.3 Potential Problems

우리가 특정 데이터에 선형 회귀 모델을 피팅시킬 때 많은 문제들이 발생합니다.

대표적인 예시는 다음과 같습니다.

1. $Non-linearity\ of\ the\ response-predictor\ relationships.$
2. $Correlation\ of\ error\ terms.$
3. $Non-constant\ variance\ of\ error\ terms.$
4. $Outliers.$
5. $High-leverage\ points.$
6. $Collinearity.$

선형 회귀 모델이 이 책의 주요 내용이 아니기 때문에 일부 핵심 사항들에 대해서만 간략히 요약합니다.



**1. Non-linearity of  the Data**

선형 회귀 모델은 입력과 반응 사이에 직선 관계가 있다고 가정합니다. 만약 진짜 관계가 비선형이라면, 우리가 적합을 통해 도출한 결론은 모두 의심해봐야합니다. 게다가, 모델의 예측 정확도 또한 줄어듭니다.

잔차 플롯은 비선형을 식별하기 위한 유용한 그래픽 도구 입니다.

단순 선형 회귀 모델이 주어질 때, 우리는 잔차 $e_i=y_i-\hat y_i$를 예측 변수 $x_i$와 비교해서 그릴 수 있습니다.

다중 회귀 모델의 경우, 예측 변수가 여러개 이므로 잔차 vs 예측(또는 피팅)값 $\hat y_i$를 그림으로 표시합니다.

이상적인 경우 잔차 플롯은 구분 가능한 패턴을 보이지 않습니다. 패턴의 존재는 선형 모델의 일부 측면에 문제가 있음을 나타냅니다. 



<img src = "https://py-tonic.github.io/images/islr/3.9.png">

위 그림의 왼쪽 판넬은 자동차 데이터 셋에 대한 선형 회귀의 잔차 플롯을 보여줍니다. 빨간 직선은 잔차에 매끄럽게 맞는 것으로, 트렌드를 쉽게 파악할 수 있도록 표시됩니다. 잔차가 명백히 U-shape을 띄는 것은 데이터가 비선형이라는 것을 강하게 나타냅니다. 

대조적으로 오른쪽 판넬은 2차식을 포함한 모델의 잔차 플롯을 나타냅니다. 잔차 그림이 데이터에 비선형 연관성이 있음을 나타내는 경우 간단한 접근법은 회귀 모델에서 $log\ x, \sqrt{x}, x^2$과 같은 예측 변수의 비선형 변환을 사용하는 것입니다.



**Correlation of Error Terms**

선형 회귀의 중요한 가정은 에러 텀 $\epsilon_1,\epsilon_2,...,\epsilon_n$이 상관관계가 없다는 것입니다.

에러가 상관관계가 없다는 뜻은 예를 들어, $\epsilon_i$가 positive라는 사실이 $\epsilon_{i+1}$의 부호에 대해 전혀 정보를 제공하지 않는다는 것입니다. 표준 오차는 추정된 회귀 계수 혹은 에러 텀의 상관관계가 없다는 가정 하에 피팅된 값을 통해서 계산됩니다.

실제로 에러 사이에 상관관계가 있다면 추정된 표준 오차는 실제 표준 오차를 과소평가하는 경향이 있을 것입니다. 따라서 신뢰 구간과 예측 구간이 필요 이상으로 좁아지게 됩니다. 예를 들어, 95%의 신뢰 구간은 모수의 실제 값을 포함하는 0.95보다 훨씬 낮은 확률을 가질 수 있습니다. 또한, 모델과 관련된 $p-value$는 해당 값보다 낮을 것입니다.

이것은 모수가 통계적으로 유의하다는 잘못된 결론을 내리게 할 수 있습니다. 간단히 말해서, 에러간의 상관관계가 있다면, 우리는 우리의 모델에 대한 신뢰도를 느낄 수 없습니다.

극단적인 예시로, 실수로 데이터를 두 배로 증가시켜 관측치와 오차항이 쌍으로 동일하다고 가정합시다. 만약 우리가 이것을 무시한다면 우리의 표준 오차 계산은 우리가 $2n$크기의 샘플을 가지고 있는 것 처럼 될 것입니다.  추정된 모수는 $2n$표본에 대해 $n$표본과 동일하지만 신뢰 구간은 $\sqrt 2$로 더 좁아질 것입니다.

왜 에러 텀 사이의 상관관계가 발생할 수 있을까요?

이런 상관관계는 종종 시계열 데이터에서 발생하는데, 시계열 데이터는 개별 지점에서 측정이 얻어지는 관측치로 구성됩니다. 많은 경우, 인접한 시점에서 얻은 관찰은 positive 상관관계가 있는 에러를 가질 것입니다.

이것이 주어진 데이터 집합의 경우인지 판단하기 위해 우리는 모델의 잔차를 시간의 함수로 표시할 수 있습니다. 에러의 상관관계가 없다면 인식 가능한 패턴이 없을 것입니다. 반면에 에러 텀이 양의 상관관계인 경우  잔차에서 트래킹이 가능합니다. 즉, 인접한 잔차의 값이 비슷할 수 있습니다.



<img src = "https://py-tonic.github.io/images/islr/3.10.png">

위 그림의 상단 패널은 상관관계가 없는 에러와 생성된 데이터에 대해 선형 회귀 피팅을 시켰을 때 나타나는 잔차입니다. 잔차에서 시간과 관련있는 경향에 대한 증거가 없습니다. 반대로, 아래 패널은 인접한 에러의 상관관계가 0.9인 데이터 셋에 대한 잔차를 나타냅니다. 이제 인접한 잔차는 비슷한 값을 가지는 명백한 패턴이 보입니다. 마지막으로 중앙 패널은 상관 관계가 0.5인 적당한 케이스에 대한 잔차를 나타냅니다. 여전히 증거를 추적할 수 있지만 패턴은 덜 뚜렷합니다.

에러 텀의 상관관계는 시계열 뿐만 아니라 다른 경우에도 발생할 수 있습니다. 예를 들어, 개인의 키를 몸무게로부터 예측하는 연구를 생각해봅시다. 연구 대상 개인 중 일부가 같은 가족 구성원이거나 같은 식단을 섭취 하거나 동일한 환경 요인에 노출된 경우 관련되지 않은 오류에 대한 가정은 위반될 수 있습니다.

일반적으로, 상관관계가 없는 에러에 대한 가정은 선형회귀 뿐만 아니라 다른 통계적 방법에서도 매우 중요합니다. 또한 이런 상관관계에 대한 위험을 줄이기 위해서는 좋은 실험 설계가 중요합니다.



**3. Non-constant Variance of Error Terms**

선형 회귀 모델에서 또 다른 중요한 가정은 에러 텀이 상수 분산을 가지는 것입니다.$(Var(\epsilon_i)=\sigma^2)$

표준오차의 신뢰 구간과 가설 검정은 이 가정에 의존합니다.

불행하게도 에러 텀의 분산은 종종 상수가 아닙니다. 예를 들어, 에러의 분산은 반응 값과 함께 증가할 수 있습니다.

잔차 플롯에 깔때기 모양의 존재로 부터 오차의 일정하지 않은 분산 혹은 이분산을 식별할 수 있습니다.

<img src = "https://py-tonic.github.io/images/islr/3.11.png">

위 그림의 왼쪽 패널이 잔차의 값이 피팅된 값과 함께 증가하는 경향을 보여줍니다. 이러한 문제와 직면하면, 한가지 가능한 솔루션은 반응 $Y$를 concave 함수를 사용하여 $log\ Y,\ \sqrt{Y}$처럼 변형시키는 것입니다.  

이러한 변환은 더 큰 반응의 감소를 통해 이분산의 감소로 이어집니다. 오른쪽 패널은 $log\ Y$를 사용해 반응을 변환시킨 후 잔차 플롯을 나타낸 것입니다. 데이터에 약간의 비선형 관계가 있다는 증거가 있지만 잔차는 이제 일정한 분산을 갖는 것으로 보입니다.



**4. Outliers**

아웃라이어는 모델의 예측값으로 부터 $y_i$가 먼 지점을 말합니다. 아웃라이어는 데이터 수집 중에 관찰을 잘못 기록하는 등 다양한 이유로 발생할 수 있습니다.

<img src = "https://py-tonic.github.io/images/islr/3.12.png">

왼쪽 패널에 있는 빨간 점은 일반적으로 아웃라이어를 나타냅니다.

빨간색 직선은 최소 제곱법 피팅인 반면 파란색 점선은 아웃라이어를 제거한 후 최소 제곱법을 사용해 피팅시킨 경우입니다. 이 경우 아웃라이어의 제거는 최소 제곱선에 거의 영향을 미치지 않습니다. 즉, 기울기에 거의 변화가 없고, 절편도 미세하게 감소합니다.

비정상적인 예측 변수 값이 없는 아웃라이어가 최소 제곱 적합치에 거의 영향을 미치지 않는 것이 일반적입니다. 그러나 아웃라이어가 최소 제곱 적합치에 큰 영향을 미치지 않더라도 다른 문제를 일으킬 수 있습니다. 예를 들어, 이 예제에서 아웃라이어를 회귀 분석에 포함하면 RSE가 1.09이지만 아웃라이어를 제거 하면 0.77에 불과합니다. 이후 RSE의 모든 신뢰 구간과 $p-value$를 계산하는데 사용되기 때문에 단일 데이터 포인트에 의해 야기되는 급격한 증가는 피팅의 해석에 영향을 미칠 수 있다.

마찬가지로 아웃라이어를 포함하면 $R^2$가 0.892에서 0.805로 감소합니다. 잔차 플롯은 아웃라이어를 식별하는 데 사용될 수 있습니다. 이 예시에서 아웃라이어는 Fig 3.12의 중간 패널에 표시된 잔차 플롯에서 명확하게 볼 수 있습니다. 그러나 실제로 우리가 특정 포인트를 아웃라이어로 간주하기 전에 잔차가 얼마나 커야 하는지를 결정하는 것은 어려울 수 있습니다. 이 문제를 해결하기 위해 잔차를 표시하는 대신 각 잔차 $e_i$를 추정된 표준 오차로 나누어 계산한 $studentized\ residuals$를 표시할 수 있습니다.

Studentized residuals가 절대값에서 3보다 큰 관측치는 아웃라이어를 가질 수 있습니다. 오른쪽 패널에서 아웃라이어의 Studentized residuals는 6을 초과하는 반면 다른 모든 관측치는 -2, 2사이의 잔차를 가집니다.

만약 우리가 데이터 수집이나 기록의 오류로 아웃라이어가 발생했다고 생각된다면, 한 가지 해결책은 단순히 관측치를 제거하는 것입니다. 그러나 아웃라이어는 예측 변수 누락과 같이 모델에 결함이 있음을 나타낼 수 있으므로 주의해야합니다.



**High Leverage Points**



