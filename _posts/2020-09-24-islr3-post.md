---
layout: post
title: ISLR chapter.3
author: Jaeheon Kwon
categories: Ai
tags: [islr]
---



온라인 스터디 발표용 자료로 슬라이드를 만들었습니다.(퀄리티는 매우 낮습니다...)

혹시 쓰신다면 출처만 남겨주세요.

[G-drive](https://drive.google.com/drive/u/0/folders/1eJscbAKj5ImG7kjKOxyOlvklDDBDgzWC)

## 3.1 Simple Linear Regression

단순 선형 회귀는 이름에 걸맞게 단일 예측 변수 $X$를 통해 정량적 반응 $Y$를 예측하는 매우 간단한 접근 방법입니다. $X$와 $Y$사이에는 선형적 관계가 있다고 가정합니다.

수학적으로 선형적 관계는 다음과 같이 나타낼 수 있습니다.

$$Y\approx \beta_0+\beta_1X\tag{3.1}$$



위 식에서 $\beta_0, \beta_1$은 선형 모델의 절편 및 기울기를 나타내는 두 개의 알 수 없는 상수입니다.(계수 혹은 파라미터 라고도 불림)

훈련 데이터를 사용하여 모델 계수에 대한 추정치 $\beta_0,\beta_1$을 생성하면 다음 식을 계산하여 TV특정 값을 계산 기반으로 미래 매출을 예측할 수 있습니다.

$$\hat y = \hat\beta_0+\hat\beta_1x\tag{3.2}$$

$\hat y$는 $X=x$를 기반으로한 $Y$에 대한 예측값입니다. ^ 기호는 알 수 없는 파라미터 혹은 계수에 대한 추정 값이거나, 반응 변수에 대한 예측 값을 나타내는 기호입니다.



### 3.1.1 Estimating the Coefficients

베타 값들은 알 수 없으니 식 3.1을 사용하여 예측하기 전에 데이터를 사용해서 계수를 추정해야 합니다.

$$(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$$

$X,Y$에 대한 관측치로 구성된 $n$개의 페어가 있습니다.

광고의 예시에서 이 데이터 셋은 티비 광고 비용과 $n=200$개의 서로다른 시장에서의 제품 판매로 구성됩니다.

우리의 목표는 선형 모델 식 3.1이 데이터에 잘 맞도록  계수에 대한 추정 $\beta_0,\beta_1$을 얻는 것입니다. 즉, $i=1,...,n$에 대하여 $y_i \approx \hat\beta_0+\hat\beta_1x_i$가 됩니다.

다시말해서 200개의 데이터 포인트에 최대한 가까운 직선을 만들기 위해 편향과 기울기를 찾고 싶습니다.

거리를 측정하는 많은 방법이 존재하지만, 이 장에서는 최소 제곱을 기준으로 사용합니다.



$e_i=y_i-\hat y_i$는 $i$번째 관측된 반응과 반응 값에 대한 우리 선형 모델의 예측의 잔차입니다.

우리는 잔차 제곱 합 RSS를 다음과 같이 정의합니다.

$$RSS = e_1^2+e_2^2+\cdot\cdot\cdot+e_n^2$$

결국 최소 제곱법은 $RSS$를 최소화 하기 위해 $\beta_0,\beta_1$을 선택합니다.

$$\hat\beta_1 = \frac{\sum\limits_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sum\limits_{i=1}^n(x_i-\bar x)^2} \\\hat\beta_0=\bar y-\hat\beta_1\bar x \tag{3.4}$$

$\bar x, \bar y$는 각각 샘플의 평균입니다.

다시말해서, 위 식은 선형 회귀를 통한 최소 제곱 계수 추정을 정의합니다.



<img src = "https://py-tonic.github.io/images/islr/3.1.png">



위 그림은  $\hat\beta_0=7.03, \hat\beta_1=0.0475$일 때 광고 데이터에 대한 단순 선형 회귀를 적용한 것을 보여줍니다.

위 근사치를 통해 TV광고에 1000달러를 추가했을 때 약 47.5개의 제품을 추가로 판매할 수 있다는 것을 알 수 있습니다.



<img src = "https://py-tonic.github.io/images/islr/3.2.png">

위 그림은 여러 가지 $\beta_0,\beta_1$에 대해 RSS값을 계산한 것을 보여줍니다.

빨간 점이 $RSS$를 최소화 하는 최적의 페어입니다.



### 3.1.2 Assesing the Accuracy of the Coefficient Estimates

우리는 2장에서 $X,Y$의 관계를 알 수 없는 함수 $f$와 평균이 0 인 $\epsilon$으로 정의했습니다.

$f$는 근사시킨 선형 함수이고, 다음과 같은 관계를 나타낼 수 있습니다.

$$Y = \beta_0+\beta_1X+\epsilon \tag{3.5}$$

에러 텀은 이 단순한 모델에서 놓친 모든 것들을 포괄합니다. 실제 관계는 선형이 아닐 수 있습니다. $Y$를 설명하기 위한 추가적인 변수가 필요할 수도 있고, 측정에서 오류가 있었을 수 있습니다.

 우리는 일반적으로 에러 텀을 $X$와 독립이라고 가정합니다.

위 식에 의해 주어진 모델은 $X,Y$사이의 실제 관계에 대한 모집단 회귀 선을 정의합니다.

최소 제곱 회귀 계수 추정은 최소 제곱 선을 특징화 합니다.



<img src = "https://py-tonic.github.io/images/islr/3.3.png">

위 왼쪽 그림(Fig 3.3)은 단순한 시뮬레이팅 예시에 대한 두 직선입니다.

100개의 $X$ 와 $Y$를 모델로 부터 생성했습니다.

$$Y = 2+3X+\epsilon\tag{3.6}$$

왼쪽 그림의 붉은 직선은 $f(X)=2+3X$인 진짜 관계식을 나타내는 반면 파란 직선은 관측된 데이터를 바탕으로 최소 제곱 추정을 통한 직선을 나타낸 것입니다.

실제 데이터의 진짜 관계식은 일반적으로 알려져있지 않지만, 최소 제곱 직선은 항상 식 3.4를 통해 계수 추정을 계산할 수 있습니다.

오른쪽 그림은 식 3.6을 통해 생성한 다른 데이터셋에 대한 최소 제곱 직선을 그린 것입니다.

동일한 실제 모델에서 생성된 다른 데이터 셋은 약간 다른 최소 제곱 직선을 생성하지만 관찰되지 않은 모집단 회귀선은 변경되지 않습니다.

동일한 데이터셋에서 나온 서로 다른 두개의 직선이 입력변수와 반응 변수의 관계를 설명한다는 것을 무엇을 의미할까요?

이 개념은 표본의 정보를 사용하여 대규모 모집단의 특성을 추정하는 표준 통계 접근 방식의 자연스러운 확장입니다.

예를 들어, 임의 변수 $Y$의 모집단 평균 $\mu$를 알고 싶다고 가정합시다.

불행하게도 $\mu$는 알수 없습니다. 하지만 우리는 $Y$로 부터 $n$개의 관측치 $y_1,y_2,...,y_n$에 접근할 수 있고 이를 통해서 $\mu$를 추정할 수 있습니다.

합리적인 추정은 $\hat y = \bar y$이며, 여기서 $\frac1n\sum\limits_{i=1}^ny_i$는 표본 평균입니다.

물론 표본평균과 모집단 평균은 다르지만 일반적으로 표본 평균은 모집단 평균의 좋은 추정치를 제공합니다.

같은 방식으로, 선형 회귀에서 알려지지 않은 계수 $\beta_0,\beta_1$은 모집단 회귀선을 정의합니다. 우리는 식 3.4를 통해 $\hat\beta_0 , \hat\beta_1$을 사용하여 이러한 알려지지 않은 계수를 추정합니다. 이러한 계수 추정 값은 최소 제곱 선을 정의합니다.

선형 회귀와 확률 변수의 추정 사이의 유추는 편향의 개념을 기반으로합니다.

$\mu$를 추정하기 위해 표본 평균 $\hat \mu$를 사용하는 경우, 이 추정치는 평균적으로 $\mu$가 $\hat \mu$와 같을 것으로 기대한다는 의미에서 편향되지는 않습니다(unbiased).

이 뜻은, 특정 관측 세트$y_1,...,y_n,\hat \mu$가 $\mu$를 과대 추정할 수 있고, 다른 관측치를 기반으로 $\hat \mu$가 $\mu$를 과소 추정 할 수 있음을 의미합니다.

그러나 많은 수의 관측치에서 $\mu$의 추정치에 대한 평균을 구할 수 있다면 그 평균은 정확히 $\mu$와 같습니다.

따라서, 편향되지 않은 추정치는 실제 모수를 체계적으로 과대 추정, 과소 추정 하지 않습니다. unbiasedness에 대한 속성은 식 3.4에 주어진 최소 제곱 계수 추정에도 적용됩니다.

특정 데이터를 기반으로 $\beta_0,\beta_1$을 추정하면 추정 값이 $\beta_0,\beta_1$과 정확히 일치하지 않습니다. 하지만 많은 수의 데이터 셋에서 얻은 추정치를 평균화 할 수 있다면 이러한 추정치의 평균은 일치합니다.

실제로 Fig 3.3의 오른쪽 패널에서 각각 별도의 데이터 셋에서 추정된 많은 최소 제곱 선이 실제 모집단 회귀 선에 매우 가깝다는 것을 알 수 있습니다.

이제 자연스러운 질문이 발생할 수 있습니다. $\mu$의 추정치로서 표본 평균 $\hat \mu$는 얼마나 정확합니까? 우리는 많은 데이터 셋에 대한 추정치의 평균은 모집단의 평균과 매우 근사하지만 단일 추정치는 모집단의 평균을 과대 추정하거나 과소 추정 할 수 있음을 확인했습니다.

표본 평균의 단일 추정치는 얼마나 멀리 떨어져 있을까요? 일반적으로 우리는 $SE(\hat \mu)$로 표기된 $\hat \mu$의 standard error를 계산하여 이 질문에 대답할 수 있습니다.

$$Var(\hat\mu) = SE(\hat\mu)^2 = \frac{\sigma^2}{n}\tag{3.7}$$

러프하게 말하자면 표준 오차는 이 추정치가 모집단의 평균과 얼마나 다른지를 알려줍니다.

또한 위 식은 관측값이 많을 수록 표준 오차가 작아지는 이유를 말해줍니다.

비슷한 맥락으로 $\hat \beta_0,\hat\beta_1$이 $\beta_0,\beta_1$과 얼마나 가까운지를 다음 식을 통해 알 수 있습니다.

$$SE(\hat\beta_0)^2 = \sigma^2[\frac1n+\frac{\bar x^2}{\sum_{i=1}^n(x_i-\bar x)^2}],\quad SE(\hat\beta_1)^2=\frac{\sigma^2}{\sum_{i=1}^n(x_i-\bar x)^2}\tag{3.8}$$

여기서 $\sigma^2=Var(\epsilon)$입니다.

이 공식이 엄밀하게 유효하려면, 각 관측치의 오차 $\epsilon_i$가 공통 분산 $\sigma^2$와 상관이 없다고 가정해야 합니다.

이 것은 Fig 3.1에서 명백한 사실은 아니지만, 공식은 여전히 좋은 근사치로 밝혀졌습니다.

공식에 따르면 $SE(\hat\beta_1)$은 $x_i$가 더 넓어지면 작아집니다. 직관적으로 이 경우 기울기를 추정하는데 더 많은 레버리지가 존재하게됩니다.

또한 $\bar x$가 0이면 $SE(\hat \beta_0)$는 $SE(\hat \mu)$와 동일합니다.(이 경우 $\hat \beta_0$=$\bar y$)

일반적으로 $\sigma^2$은 알 수 없지만 데이터에서 추정할 수 있습니다. $\sigma$의 추정치는 residual standard error로 알려져 있으며 식으로는 다음과 같습니다. $RSE = \sqrt{RSS/(n-2)}$

표준 오차를 사용하여 신뢰 구간을 계산할 수 있습니다.

95%의 신뢰 구간은 95% 확률로 매개변수의 실제 알 수 없는 값이 포함되는 값의 범위로 정의됩니다.

범위는 데이터 샘플에서 계산된 하한 및 상한으로 정의됩니다.

선형 회귀에서 $\beta_1$에 대한 95%신뢰 구간은 대략 다음과 같은 형식을 취합니다.

$$\hat\beta_1\pm 2\cdot SE(\hat \beta_1) \tag{3.9}$$

95%확률에 대한 구간의 범위는 다음과 같습니다.

$$[\hat\beta_1 - 2\cdot SE(\hat\beta_1), \hat\beta_1 + 2\cdot SE(\hat\beta_1)]  \tag{3.10}$$

유사하게 $\beta_0$에 대한 신뢰 구간은 다음과 같은 형식을 취합니다.

$$\hat\beta_0\pm 2\cdot SE(\hat \beta_0) \tag{3.11}$$



광고 데이터의 예시로 돌아가봅시다. $\beta_0$에 대한 95%신뢰구간은 [6.130, 7.935]이며, $\beta_1$에 대한 신뢰 구간은 [0.042, 0.053]입니다. 그러므로 우리는 광고가 없을 때 판매량이 평균적으로 6,130 ~ 7940단위 사이에 떨어질 것이라는 결론을 내릴 수 있습니다. 또한 TV광고가 $1000 증가할 때마다 평균 판매량은 42~53대 증가할 것 입니다.



표준 오차를 사용하여 계수에 대한 가설 검정을 수행할 수 있습니다. 가장 일반적인 가설 검정은 다음의 귀무 가설을 검정하는 것입니다.

- $H_0$: There is no relationship between X and Y
- $H_1$: There is some relationship between X and Y



수학적으로는 다음과 같습니다.

- $H_0:\beta_1 = 0$
- $H_1:\beta_1\neq0$

$\beta_1 = 0$이면 모델 3.5가 $Y=\beta_0+\epsilon$으로 바뀌고 $X$는 $Y$와 관련이 없습니다.

귀무 가설을 테스트 하려면 $\beta_1$에 대한 추정치인 $\hat\beta_1$이 0에서 충분히 멀리 떨어져 $\beta_1$이 0이 아니라고 확신할 수 있는지 여부를 확인해야 합니다.

얼마나 멀어야 할까요? 물론 이것은 $\hat\beta_1$의 정확도에 따라 달라집니다. 즉, $SE(\hat\beta_1)$에 따라 달라집니다. 만약 $SE(\hat\beta_1)$이 작다면, 상대적으로 작은 값의 $\beta_1$이라도 $\beta_1 \neq0$이라는 강력한 증거가 될 수 있고, 이 것은 $X,Y$에 관계가 있음을 보여줍니다.

반대로 $SE(\hat\beta_1)$가 크면 귀무 가설을 기각하기 위해서는 $\hat\beta_1$의 절대 값이 커야 합니다. 실제로 우리는 다음과 같은 t-statistic을 계산합니다.

$$t = \frac{\hat\beta_1 -0}{SE(\hat\beta_1)} \tag{3.14}$$

> 검정 통계량 t는
>
> $\hat\beta_1$ 데이터로 부터 추정한 기울기 - (귀무가설에서 설정한 기울기 즉, 0)을, standard error로 스케일링함. t가 크면 데이터랑 내가 주장하는 바가 다르므로 귀무가설을 기각.
>
> t = 두 표본 그룹 평균의 차이 / 두 그룹 간 평균 차이에 대한 불확실도 
>
> 위에선 귀무가설을 0으로 설정해서 식이 저렇지만 원래는 식은
>
> $t= \frac{\bar X_1-\bar X_2}{s_{\bar X_1-\bar X_2}}$ 이며, $s_{\bar X_1-\bar X_2}=\sqrt{Var[\bar X_1-\bar X_2]}$ 입니다. 



$X,Y$사이에 관계가 없다면 $n-2$ 의 자유도를 갖는 t-분포를 가질 것으로 예상합니다. (t-분포는 종 모양이고 n>30인 경우에 대해 정규 분포와 매우 유사합니다.)

$\beta_1=0$이라고 가정하면,  $\vert t\vert$ 혹은 그 이상의 숫자를 절댓값으로 관측할 확률을 계산하는 것은 간단합니다. 우리는 이 확률을 $p-value$라고 부릅니다. (tip. 각 $\beta$에 대한 $p-value$값이 큰게 중요한 변수)

$p-value$를 다음과 같이 해석합니다. 작은 $p-value$는 예측 변수와 반응 사이에 실질적인 연관성이 있다는 것을 의미합니다.(즉, 우리의 기울기가 귀무가설에서 세운 0과 차이가 크다면 t값은 커지게 되고 이는 p-value가 매우 작아지는 것을 의미합니다. P(Y>t) 인데 여기서 t가 크다는 얘기이니까요.. 이렇게 되면 실제로 일어날 확률이 매우 작다는 뜻이고 이는 귀무 가설이 잘못되어서 기각한다는 결론으로 이어집니다.)

일반적으로 귀무가설을 기각하기위한 $p-value$의 값은 n=30일 때 1% 혹은 5%입니다.



<img src = "https://py-tonic.github.io/images/islr/t3.1.png">

위 표는 회귀 분석에 대한 최소 제곱 모델의 세부 정보를 제공합니다. 광고 데이터의 TV광고 예산으로 판매된 단위 수입니다.

계수 $\beta_0,\beta_1$은 표준 오차와 매우 큰 상관관계가 있고, 검정 통계량 또한 큽니다. $H_0$가 정답일 확률은 매우 낮습니다. 그러므로 $\beta_0, \beta_1 \neq 0$이라고 결론 지을 수 있습니다.



### 3.1.3 Assessing the Accuracy of the Model

귀무 가설을 기각하고 대립 가설을 채택하면 모델이 데이터에 얼마나 적합한지 정량화 하는 것 또한 당연합니다.

선형 회귀의 적합도를 일반적으로 RSE(residual standard error)와 $R^2$통계량을 이용하여 평가합니다.

<img src = "https://py-tonic.github.io/images/islr/t3.2.png">

위 표(table 3.2)는 TV광고 예산으로 판매된 선형 회귀에 대한 RSE, $R^2$통계 및 F-통계를 표시하고 있습니다.



**Residual Standard Error**

각 관측치와 관련이 있는 모델 3.5에서 에러 텀을 떠올려 봅시다.

이러한 에러 텀으로 인해 진짜 회귀선 ($\beta_0,\beta_1$을 알아도) 우리는 $X$를 통해 $Y$를 완벽하게 예측할 수 없습니다. RSE는 에러 텀에 대한 표준 편차를 추정하는 것입니다.

러프하게 말하면, 반응 변수와 진짜 회귀 직선 사이 편차의 평균입니다. 식으로는 다음과 같이 나타냅니다.

$$RSE = \sqrt{\frac{1}{n-2}RSS} = \sqrt{\frac{1}{n-2}\sum\limits_{i=1}^n(y_i-\hat y_i)^2}\tag{3.15}$$

$RSS$는 섹션 3.1.1에서 정의했습니다. 식은 다음과 같습니다. (여기서 자유도로 나누면 MSE)

$$RSS = \sum\limits_{i=1}^n(y_i-\hat y_i)^2\tag{3.16}$$

광고 데이터의 케이스에서 우리는 RSE가 3.26인 것을 테이블 3.2를 통해 볼 수 있습니다.

즉, 각 시장은 평균적으로 약 3,260단위 만큼 실제 회귀선에서 벗어납니다. 이 말은 실제 모델을 알아도 TV광고를 기반으로한 판매 예측은 여전히 평균 약 3,260단위 만큼 떨어진다는 의미입니다. 위 단위가 허용 가능한 예측 오류인지에 대한 여부는 문제에 따라 다릅니다.

광고 데이터 셋에서 판매에 대한 평균 값은 대략 14,000 유닛 입니다. 에러의 비율은 3,260/14,000 = 23% 정도 입니다.

만약 모델을 사용하여 실제 결과 값과 매우 가까운 예측 값을 얻는다면, RSE가 매우 작은 것이고 모델이 데이터에 잘 맞는다고 할 수 있습니다.

즉, $\hat y_i$가 $y_i$와 굉장히 멀다면 RSE는 매우 클 것이고, 모델이 데이터에 적합하지 않다는 것을 의미합니다.



**$R^2$ Statistic**

RSE는 데이터와 모델의 차이에 대한 메저를 제공했습니다. 그러나 $Y$의 단위로 측정되기 때문에 무엇이 좋은 RSE를 구성하는지  항상 명확하지는 않습니다. $R^2$ 통계량은 다른 적합도를 제공합니다. 이 메저는 비율을 사용하여 분산을 설명합니다. (비율이기 때문에 항상 0~1사이 값을 가집니다.) 또한 Y의 스케일에 독립적입니다.

$R^2$은 다음과 같이 계산합니다.

$$R^2 = \frac{TSS-RSS}{TSS} = 1-\frac{RSS}{TSS} \tag{3.17}$$

$TSS= \sum(y_i-\bar y)^2$ 입니다. TSS는 반응 변수 $Y$에 대한 변동성을 나타냅니다.(여기서 자유도로 나누면 분산이지만 뭐...편의상 분산이라고 언급해도 되지 않을까요...?)

위에서 다룬 $RSS$는 회귀 분석 수행 후 설명되지 않은 상태로 남아 있는 변동성(에러 텀)의 양을 측정합니다.

> 설명이 좀 ... 애매하긴한데 저는 이렇게 이해했습니다.
>
> TSS가 러프하게 따지면 전체 Y에 대한 분산이면
>
> RSS는 회귀분석 수행 후 남은 에러 텀에 대한 분산을 나타내겠죠?(입력 변수로 Y에대한 관계를 모두 설명 한경우 에러텀에 대한 분산만 남겠죠?)
>
> 그래서 TSS-RSS는 이 모델이 에러텀을 제외하고 얼마나 많은 분산을 표현(혹은 설명) 했는지 라고 해석했습니다.

$R^2$가 1에 가까울수록 회귀 모델이 반응 변수에대한 설명을 잘 하고 있는 것으로 볼 수 있습니다.

반대로 0에 가까울수록 모델이 너무 좋지 않거나 에러 텀의 분산이 매우 큰 것으로 볼 수 있습니다.

$R^2$는 RSE와 달리 0~1사이 값으로 표현되기 때문에 해석하는데 이점이 존재합니다.



선형 모델은 생물학, 심리학, 마케팅 및 기타 영역에서 복잡한 데이터에 대한 근사치정도로 밖에 쓰이지 못하고, 측정되지 않은 요인으로 인한 잔류 오차는 매우 큽니다.

이러한 환경에서 예측 변수에 의해 설명되는 반응의 분산은 극히 작은 비율만 예상되며 0.1보다 낮은 R2 값이 더 현실적입니다.

$R^2$통계량은 $X$와 $Y$의 선형 관계에 대한 척도임을 기억합시다. 상관 관계는 다음과 같이 정의됩니다.

$$Cor(X,Y) = \frac{\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum_{i=1}^n(x_i-\bar x)^2}\sqrt{\sum_{i=1}^n(y_i-\bar y)^2}}\tag{3.18}$$

위 식 또한 $X, Y$에 대한 선형 관계를 측정할 수 있습니다.

이는 선형 모델의 적합성을 평가하기 위해 $R^2$대신 $r=Cor(X,Y)$를 사용할 수 있음을 보여줍니다.

실제로 단순 선형 회귀 설정에서 $R^2=r^2$입니다.

하지만 다음 섹션에서 다룰 다중 선형 회귀는 여러 예측 변수를 사용하여 반응 변수를 예측합니다.

상관 관계는 단일 변수 쌍 간의 관계를 정량화하므로, 예측 변수와 반응 변수 사이의 상관 관계 개념은 자동으로 다중 회귀에서 확장되지는 않습니다. $R^2$가 이 역할을 할 수 있습니다.



## 3.2 Multiple Linear Regression

단순 선형 회귀는 단일 예측 변수를 기반으로하여 반응 변수를 예측하는 좋은 접근입니다.

그러나 현실에서는 우리는 하나 이상의 예측 변수와 마주하게 됩니다.

예를들어 광고 데이터의 경우 우리는 판매량과 TV광고 사이의 관계에 대해 설명했습니다. 또한 우리는 라디오나 신문에 사용된 광고 비용의 양을 나타내는 데이터 또한 가지고 있으므로, 두 플랫폼과 판매량의 관계에 대해서 알고 싶습니다.

한 가지 방법은 각각 다른 플랫폼에 대한 예측변수를 사용하여 세 개로 분리된 단순 선형 회귀를 사용하는 것입니다. 예를 들어 라디오 광고 비용에 기반하여 판매량을 예측하는 단순 선형 회귀를 생각할 수 있습니다.



<img src = "https://py-tonic.github.io/images/islr/t3.3.png">



결과는 위 테이블에 나와 있습니다.

우리는 $1,000의 라디오 광고를 통해 203개의 판매량 증가를 볼 수 있습니다.

그 아래의 테이블은 신문에 대한 단순 선형 회귀의 결과입니다. $1,000의 신문 광고는 약 55개의 판매량 증가를 이뤄냅니다.

그러나 각각의 예측 변수에대해 선형 회귀 모델을 분리시키는 것은 그다지 만족스럽지 않습니다.

첫 번째, 각각의 광고 비용이 별도의 회귀 방정식과 연관되어 있기 때문에 주어진 매출 수준을 어떻게 단일 예측해야 할지 불투명합니다.

두 번째, 각각의 세가지 회귀 방정식은 다른 두 가지 플랫폼에서 추정한 회귀계수를 무시합니다.

우리는 플랫폼 예산이 우리의 데이터 셋을 구성하는 200개 시장에서 서로 상관관계가 있다면, 이는 판매에 미치는 개별 플랫폼의 영향력에 대한 매우 잘못된 추정이 될 수 있다는 것을 알게 됩니다.

각각의 예측 변수에 대해 단순 선형 회귀 모델을 분리시키는 것 보다 더 나은 접근 방식은, 단순 선형 회귀를 여러 예측 변수에 대해 확장시키는 것입니다.

우리는 예측 변수마다 각각의 기울기를 부여하므로써 단일 모델을 구성할 수 있습니다.

$p$개의 예측 변수가 존재한다고 가정하면, 다중 선형 회귀 모델은 다음과 같이 정의됩니다.

$$Y = \beta_0 +\beta_1X_1+\beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p+\epsilon\tag{3.19}$$



### 3.2.1 Estimating the Regression Coefficients

3.19에서 정의한 $\beta_0,...,\beta_p$는 알 수 없으므로 추정해야 합니다.

추정치에 대한 식은 다음과 같이 적을 수 있습니다.

$$\hat y =\hat \beta_0 + \hat\beta_1x1+\cdot\cdot\cdot+\hat\beta_px_p\tag{3.21}$$

파라미터 추정은 단순 선형 회귀와 동일한 방식으로 최소 제곱 접근법을 사용합니다. 

$$RSS= \sum\limits_{i=1}^n(y_i-\hat y_i)^2 \tag{3.22}$$

3.4에 주어진 단순 선형 회귀에 대한 추정과 달리, 다중 회귀 계수 추정은 복잡하므로 행렬 대수의 형태로 쉽게 표현할 수 있습니다.

그런 이유로 여기서는 표기하지 않고 넘어갑니다.(R과 같은 통계패키지를 사용해서 나타낼 수 있습니다.)



<img src = "https://py-tonic.github.io/images/islr/3.4.png">

위 그림은 $p=2$에 대한 예제 데이터셋을 최소 제곱법을 통해 피팅시킨 예시입니다.



<img src = "https://py-tonic.github.io/images/islr/t3.4.png">



위 테이블(3.4)은 TV, 라디오, 신문 광고 예산에 대한 다중 회귀 계수 추정을 나타냅니다.

우리는 위와 같은 결과를 다음과 같이 해석합니다. TV와 신문 광고의 일정 금액에 대해 라이도 광고에 $1,000를 추가 지출하면 약 189대의 판매량 증가로 이어진다.

테이블 3.1, 3.3과 비교해봤을 때 TV와 라디오에 대한 다중 회귀 분석 계수 추정은 단순 선형 회귀 계수 추정과 비슷하다는 것을 알 수 있습니다.

그러나 신문의 회귀 계수 추정치는 테이블 3.3에는 0이 아니었으나 다중 회귀 분석에서는 0에 가깝고 p-value 값 또한 매우 높습니다. 이를 통해 단순 선형 회귀와 다중 회귀 분석이 다른 것을 알 수 있습니다.

왜 신문 예산에 대해서만 단순 회귀 분석과 반대의 결과가 나왔을까요? 테이블 3.5에 나와있는 세 가지 예측 변수와 반응 변수에 대한 상관 관계를 고려해봅시다.

<img src = "https://py-tonic.github.io/images/islr/t3.5.png">



라디오와 신문 사이의 상관관계를 보면 0.35입니다. 이 것은 신문에 광고를 내는 시장은 라디오에 더 많은 광고를 내는 경향이 있다는 것을 보여줍니다.

이 것은 신문 판매가 라디오 광고의 대용으로 생각할 수 있습니다. 이런 반 직관적인 상황은 일상에서 흔합니다.

일정 기간 동안 주어진 해변에서 수집된 데이터에 대해 상어 공격과 아이스크림 판매의 회귀 분석을 실행하는 것은 판매와 신문 사이에 나타난 것과 유사한 긍정적인 관계를 보여줄 것입니다. 물론, 누구도 상어의 공격을 줄이기 위해 아이스크림 판매를 금지해야한다고 제안하지 않습니다.

실제로 높은 온도는 많은 사람들이 해변을 방문하게 만들고, 많은 아이스크림 판매량과 많은 상어의 공격이라는 결과를 초래합니다.

아이스크림 판매와 온도 대비 공격의 다중 회귀 분석은 직관적으로 알 수 있듯, 이전의 예측 변수가 온도에맞게 조정된 후 더이상 중요하지 않다는 것을 보여줍니다.



### 3.2.2 Some Important Questions

우리가 다중 선형 회귀를 수행할 때 우리는 일반적으로 몇 가지 중요한 질문에 답하는 것에 관심이 있습니다.

1. 최소한 하나의 예측 변수는 반응 변수를 예측하는 데 유용한가?
2. 모든 예측 변수가 Y를 설명하기 위해 필요한가? 아니면 예측 변수의 일부만 유용한가?
3. 어떻게 모델을 데이터에 잘 피팅 시킬 수 있을까?
4. 예측 변수의 집합이 주어질 때 어떻게 반응 변수 값을 예측해야 하고 예측에 대한 정확도를 어떻게 측정할까?



질문들에 대해 해결해봅시다.



**One: Is There a Relationship Between the Response and Predictors?**

단순 선형 회귀를 떠올려 봅시다. 반응 변수와 예측 변수의 관계를 결정하기 위해서 우리는 단순히 $\beta_1 = 0$인지 체크했습니다.

$p$개의 예측 변수를 사용하는 다중 회귀 분석에서는 $\beta_0=\beta_1=\cdot\cdot\cdot=\beta_p=0$인지 확인해봐야 합니다.

단순 선형 회귀에서는 가설 검정을 통해 이 질문에 대답했습니다. 귀무 가설을 테스트해봅시다.

- $H_0 :\beta_0=\beta_1=\cdot\cdot\cdot=\beta_p=0$
- $H_1:$ 최소한 하나의 $\beta_j\neq0$

가설 검정은 $F-statistic$을 통해 수행됩니다.

$$F =\frac{(TSS-RSS)/p}{RSS/(n-p-1)}\tag{3.23}$$

> $R^2$와 차이점은 분자가 TSS가 아닌 RSS라는 것..!
>
> 보통 MSR/MSE 로 나타내며, 단일 회귀 분석에서 p=1이니까 n-p-1 = n-2이고,
>
> $\frac1{n-2}RSS = MSE$ 입니다.
>
> MSE는 우리가 알다 시피, 에러텀의 분산으로 나타내지는 값들을 표현하므로 ''회귀로 좁힐 수 없는 거리''로 해석하면 편할 것 같습니다.
>
> MSR은 $R^2$와 똑같은 분자입니다. TSS가 y의 분산 같은 느낌이고(엄밀힌 아니지만)거기서 회귀로 좁힐 수 없는 거리를 빼주면 실질적인 의미는 '전체 편차 - 회귀로 줄일 수 없는 거리 = 회귀로 줄일 수 있는 거리'가 되겠죠? 즉 회귀로 거리를 많이 줄이면 줄일수록 MSR이 커지고 F통계량이든 t-value든 커지게 됩니다!



$TSS=\sum(y_i-\bar y)^2, RSS=\sum(y_i-\hat y_i)^2$ 처럼 선형 회귀의 가정과 동일하면 다음과 같은걸 볼 수 있습니다.

$$E[RSS/(n-p-1)]=\sigma^2$$

$$E[TSS-RSS/p]=\sigma^2$$

따라서 반응 변수와 예측 변수의 관계가 없을 때 $F-statisic$은 1 근처의 값을 가지게 됩니다.

반면 $H_1$이 맞다면, $E[(TSS-RSS)/p]>\sigma^2$이기 때문에 $F$는 1보다 큽니다.



라디오, TV, 신문 판매량에 대한 $F$통계량을 포함한 다중 회귀 모델은 아래 표에 있습니다.

 <img src = "https://py-tonic.github.io/images/islr/t3.6.png">

이 예에서는 $F$ 통계량이 570입니다. 이는 1보다 훨씬 크기 때문에 귀무 가설 $H_0$에 반대하는 설득력 있는 증거를 제공합니다.

즉 $F$가 크다는 것은 적어도 하나의 광고 플랫폼이 판매량과 관련 있다는 것입니다.

그러나, $F$통계량이 어느정도 값을 가져야 귀무가설을 기각하고 관련이 있다고 결론지을 수 있을까요?

식에서 알 수 있듯, $n,p$ 값에 따라 다릅니다. 만약 $n$이 크다면, $F$통계량은 커지고 귀무 가설을 기각하는 증거가 됩니다.

만약 $H_0$가 진실이고, $\epsilon_i$가 정규분포를 따른다면, $F$통계량은 $F$분포를 따릅니다.

광고 데이터의 경우 위 테이블의 $F$통계량과 관련된 $p-value$값은 본질적으로 0이므로, 우리는 적어도 하나의 플랫폼이 매출 증가와 연관되어 있다는 강력한 증거를 가집니다.

3.23에서 $H_0$은 모든 회귀 계수가 0인지 테스트하고 있습니다. 때때로 계수의 부분집합 $q$가 0인지 테스트하고 싶습니다.

이에 대한 귀무 가설은 다음과 같습니다.

$$H_0: \beta_{p-q+1} = \beta_{p-q+2}=\cdot\cdot\cdot=\beta_p=0$$

이 경우 마지막 $q$를 제외한 모든 변수를 사용하는 두 번째 모델을 피팅시킵니다.

해당 모델에 대한 $RSS = RSS_0$라고 가정합시다. 그렇다면 적절한 $F$통계량은 다음과 같습니다.

$$F = \frac{(RSS_0 - RSS)/q}{RSS/(n-p-1)}\tag{3.24}$$



 테이블 3.4에서 각 개별 예측 변수에 대한 t-통계량및 $p-value$ 값을 알고 있습니다.

이 값은 각 예측 변수가 다른 예측 변수에 대해 조정된 후 반응 변수와 관련 있는지 여부에 대한 정보를 제공합니다. 모델에 변수를 추가하는 부분적인 효과를 알 수 있습니다. 예를 들어, 앞에서 논의한 바와 같이 이러한 $p-value$는 TV와 라디오가 판매량과 관련이 있지만, 이 두가지 상황에서 신문이 판매와 연관되어 있다는 증거가 없음을 나타냅니다.

각 변수에 대해 이런 개별 $p-value$가 주어졌는데도 왜 $F$통계량을 고려해야 할까요? 결국 개별 변수에 대한 $p-value$중 하나가 매우 작을 경우 적어도 하나의 예측 변수가 반응과 관련 있을 가능성이 존재합니다. 하지만 이 논리에는 특히 $p$가 큰 경우 결함이 존재합니다.

$p=100$일 때 모든 베타값이 0인 예시를 고려해봅시다. 모든 변수가 실제로 반응과 관련이 없습니다. 이 상황에서는 각 변수와 관련된 $p-value$의 5%가 우연한 기회로 인해 0.05 이하가 될 수 있습니다.

다시말해서, 예측 변수와 반응 변수 사이 진정한 연관성이 없는 경우에도, 약 5개의 작은 $p-value$를 볼 수 있습니다. 사실 우리는 우연히 0.05 이하의 $p-value$를 최소한 한 개 이상 관찰할 것이라고 거의 장담하고 있습니다.

따라서 변수와 반응 사이에 연관성이 있는지 여부를 결정하기 위해 개별 t-통계량 및 관련 $p-value$를 사용하는 것은 관계가 존재한다고 잘못 결론 내릴 가능성이 매우 높습니다.

$F$-통계량을 사용하여 예측 변수와 반응 변수의 연관성을 검정하는 방법은 상대적으로 $p$가 작을 때($n$ 보다) 효과가 있습니다. 하지만 우리는 때때로 많은 수의 변수를 다룹니다.

$p>n$일 경우 추정할 계수 $\beta_j$가 관측치 보다 많습니다.

이런 경우에는 최소제곱법을 사용해서 모델을 피팅시킬 수 없으므로 $F$-통계량 또한 사용할 수 없습니다. 

이런 고차원 설정에 대해서는 6 장에서 다룹니다.



**Two: Deciding on Important Variables**

이전 섹션에서 설명한 바와 같이 다중 회귀 분석의 첫 번째 단계는 $F$-통계량을 계산하고 관련$p-value$를 검토하는 것입니다.

만약 우리가 $p-value$에 기반하여 적어도 하나의 예측 변수가 반응과 관련이 있다고 결론을 내린다면, 어느 것이 중요한지 궁금한 것은 당연합니다.

우리는 테이블 3.4와 같이 개별 $p-value$를 볼 수 있지만, 논의된 바와 같이 $p$가 크면 우리는 몇 가지 잘못된 발견을 할 가능성이 있습니다.

모든 예측 변수가 반응과 관련이 있을 순 있겠지만 예측 변수의 부분집합이 반응과 관련이 있는게 더 흔한 케이스 입니다.

관련이 있는 예측 변수를 포함한 단일 모델을 피팅시키기 위해서 반응과 관련있는 예측 변수를 결정하는 문제를 $variable$ $selection$이라고 합니다. 자세한건 6장에서 다루므로 여기서는 고전적인 변수 선택에 대해서 살펴봅니다.

이상적으로는 예측 변수의 서로 다른 부분집합을 포함하는 여러 모델을 실험하여 변수 선택을 수행하고자 합니다. 예를 들어 $p=2$인 경우 4개의 모델을 고려할 수 있습니다.

1. 모델이 변수를 포함하지 않는 경우
2. $X_1$만 포함하는 경우
3. $X_2$만 포함하는 경우
4. $X_1,X_2$를 포함하는 경우

우리가 고려한 모델중의 가장 좋은 모델을 선택하면 됩니다.

어떻게 최고의 모델을 선정할까요? 다양한 통계량을 사용해서 모델을 판단할 수 있습니다.(물론 이것도 6장에서 다룹니다.)

우리는 또한 패턴을 찾기위해서, 잔차 등 어떤 모델의 출력이 가장 좋은지 결정할 수 있습니다.

하지만 이런 방식의 모든 모델을 비교하는건 $p$가 크면 기하 급수적으로 늘어나므로 비현실적입니다.

세 가지 고전적 접근 방식을 살펴봅시다.

- $Forward$ $selection$
    - 절편은 포함하지만 예측 변수는 없는 Null 모델에서 출발하여 단순한 p개의 선형 회귀를 피팅시킨 후 가장 낮은 RSS를 생성하는 변수를 null모델에 추가
- $Backward$ $selection$
    - 모든 변수가 존재하는 모델로 시작해서 $p-value$가 큰 변수들을 제거합니다. 제거한 뒤 또 피팅시키고 또 제거를 반복합니다. 
- $Mixed$ $selection$
    - 위 두 선택을 섞은 버전입니다. 처음엔 Forward 처럼 변수 없이 시작합니다.그리고 가장 적합한 변수를 하나씩 추가합니다. 물론 광고 예제에서 지적했듯 변수에 대한 $p-value$는 모델에 대한 새로운 예측 변수가 추가됨에 따라 더 커질 수  있습니다. 따라서 모델의 변수 중 하나에 대한 $p-value$가 특정 임계값을 초과하면 해당 변수를 모델에서 제거합니다.





**Three: Model Fit**

일반적인 모델의 적합도를 수치적으로 측정하는 방법은 $RSE$ 와 $R^2$입니다.

이런 수량은 단순 선형 회귀 분석과 동일한 방식으로 계산 및 해석됩니다.

단순 회귀에서 $R^2$는 반응과 예측 간의 상관 관계의 제곱이었습니다. 사실 적합된 선형 모델의 한가지 특성은 가능한 모든 선형 모델 간의 상관 관계를 최대화 합니다.

$R^2$값이 1에 가까우면 모델이 반응 변수 분산의 많은 부분을 설명한다는 것을 나타냅니다.

광고 데이터에서 세 가지 광고 플랫폼을 모두 사용하여 매출을 예측하는 모델의 $R^2 = 0.8972$이고, TV와 라디오만 사용하여 매출을 예측하는 모델은 $R^2=0.89719$ 입니다.

우리는 신문 광고를 포함한 모델이 비록 $p-value$가 유의미하지 않더라도 $R^2$값을 증가시킨다는 것을 볼 수 있습니다.

즉 $R^2$는 반응과 약한 관계를 갖는 변수를 모델에 추가하더라도 항상 증가하는 것을 볼 수 있습니다.

이는 최소 제곱 방정식에 다른 변수를 추가하면 훈련 데이터를 더 정확하게 피팅시킬 수 있기 때문입니다.

본질적으로 신문은 훈련 샘플에 피팅된 모델에 대한 실질적인 향상을 가져오지 않으므로, 신문을 포함하는 모델은 오버피팅으로 인해 독립적인 테스트 케이스에 대해 낮은 결과를 초래할 가능성이 존재합니다.

대조적으로 오직 TV에 대한 변수만 포함하는 모델의 $R^2$는 0.61입니다. 라디오를 추가하면 (당연히) $R^2$의 향상이 존재합니다. TV와 라디오 지출을 이용해 판매량을 예측하는 모델이 TV만 사용하는 모델보다 훨씬 낫습니다.

> $R^2$식을 떠올려 보면 결국 저건 분자식인 TSS-RSS와 관련이 있는데,
>
> 여기서 RSS가 더 작아지므로 회귀 분석으로 설명할 수 있는 거리가 늘어나므로 $R^2$값이 커지게 됩니다.

TV, 라디오만 예측변수로 사용하는 모델은 RSE가 1.681이고, 신문을 포함하는 모델은 1.686(테이블 3.6)입니다.

어떤 이유로 RSE 값이 증가했는지 알아봅시다. 우선 RSE는 다음과 같의 정의 할 수 있습니다.

$$RSE = \sqrt{\frac{1}{n-p-1}RSS}\tag{3.25}$$

RSS의 감소가 $p-value$의 증가에 비해 작은 경우, 변수가 더 많은 모델은 더 높은 RSE를 가질 수 있습니다.

> $p-value$가 높다는 것은 일반적으로 $\beta$값이 0일 확률이 높은 얘기입니다.
>
> 딱히 모델의 설명력을 올리지는 않는 변수가 RSS를 조금 떨어뜨리면 그 변수는 좋지 않다는 얘기입니다.

앞서 논의한 RSE, $R^2$를 보는 것 외에도 데이터를 플로팅 하는 것이 유용할 수 있습니다.

그래프를 통해 수치 통계에서 볼 수 없는 모델의 문제점을 드러낼 수 있습니다. 예를 들어, Fig 3.5는 TV와 라디오에 대한 판매량을 3차원 그래프를 통해 나타냅니다.

일부 관측치는 위에있고, 일부 관측치는 최소 제곱 평면 아래에 존재합니다. 특히 선형 모델은 광고비의 대부분이 TV나 라디오에 독점적으로 사용되었던 사례에 대해서는 판매량을 과대 추정하는 것 같습니다. 반대로 예산이 두 플랫폼으로 나눠진 경우 과소 추정합니다. 이는 비선형 패턴을 선형 회귀 분석을 사용하여 정확하게 모델링 할 수 없음을 나타냅니다.

<img src = "https://py-tonic.github.io/images/islr/3.5.png">

광고 매체들 사이의 시너지 효과나 상호작용 효과를 시사하는데, 플랫폼을 결합함으로써 어떤 단일 매체를 사용하는 것 보다 더 큰 판매량 증가를 초래합니다. 섹션 3.3.2에서는 상호 작용 항을 사용하여 이러한 시너지 효과를 수용하도록 선형 모델을 확장하는 것에 대해 다룹니다.

**Four: Predictions**

다중 회귀 모형을 피팅 시킨 후에는 예측 변수에 대한 일련의 값을 기반으로 반응을 예측하기 위해 3.21을 적용하는 것이 간단합니다. 그러나 이 예측과 관련된 불확실성에는 세 가지 종류가 있습니다.

1. 진짜 계수$(\beta)$에 대한 추정치 $(\hat \beta)$로 이루어진 최소 제곱 평면은 실제 모집단 회귀 평면의 추정치일 뿐입니다.

    $$\hat Y =  \hat \beta_0 + \hat\beta_1 X_1+\cdot\cdot\cdot + \hat\beta_pX_p$$

    $$f(X) = \beta_0+\beta_1X_1+\cdot\cdot\cdot + \beta_pX_p$$

    계수 추정치에 대한 불확실성은 2장에서 다룬 reducible error와 관련이 있습니다. $\hat Y$가 $f(X)$에 얼마나 가까운지 결정하기 위해 신뢰구간을 계산할 수 있습니다.

2. 물론 실제로 $f(X)$에 대한 선형 모델을 가정하는 것은 거의 항상 현실의 근사치이므로, 우리가 모델 편향이라고 부르는 잠재적으로 reducible error의 추가적인 소스가 있습니다. 그래서 우리가 선형 모델을 사용할 때 우리는 사실 모집단의 평면에 대한 가장 좋은 선형 근사치를 추정합니다. 그러나 여기서는 이러한 불일치를 무시하고 선형 모델이 올바른 것 처럼 작동합니다.

3. 앞서 얘기한 것 처럼 f(X)를 알아도 모델의 랜덤 오차 부분 때문에 반응 값은 완벽하게 예측할 수 없습니다. 2장에선 irreducible error라고 언급했습니다. $\hat Y$와 $Y$는 얼마나 다를까요? 우리는 이 질문에 대답하기 위해 예측 구간을 사용합니다. 예측 구간은 $f(X)$에 대한 추정치의 오차(reducible error)와 개별 점이 모집단의 회귀 평면(irreducible error)과 얼마나 다를 것인지에 대한 불확실성을 모두 포함하기 때문에 항상 신뢰 구간보다 넓습니다.

우리는 신뢰 구간을 사용하여 많은 도시에 대한 평균 판매량을 둘러싼 불확실성을 정량화합니다.

예를 들어, 각 도시의 TV광고에 10만 달러가 지출되고, 라디오 광고에 2만 달러가 지출된다는 점을 고려하면, 95%의 신뢰 구간은 [10,985, 11,528]입니다.

우리는 이것을 이 형태의 구간 95%가 $f(X)$의 실제 값을 포함할 것 이라는 의미로 해석합니다. 반면에, 예측 구간은 특정 도시의 판매를 둘러싼 불확실성을 정량화 하는데 사용될 수 있습니다.

그 도시에서 10만 달러가 TV광고에 사용되고, 2만 달러가 라디오 광고에 쓰인다면, 95% 예측 간격은 [7,930, 14,580]입니다.

우리는 이 것을 구간의 95%가 이 도시에 대한 $Y$의 진짜 값을 포함할 것 이라는 의미로 해석합니다. 두 구간 모두 11,256을 중심으로 하지만, 예측 구간은 신뢰 구간보다 상당히 넓어 여러 장소에 대한 평균 판매량에 비해 특정 도시의 판매에 대한 불확실성이 증가했음을 반영합니다.





 