---
layout: post
title: ISLR chapter.2
author: Jaeheon Kwon
categories: Ai
tags: [islr]
---



## 2.1 What Is Statistical Learning?

통계적 학습에 대해 알아보기 위해 한가지 예시를 들어봅시다.

우리는 특정 상품의 판매량을 향상시키는 방법에 대해 조언해주기 위해 클라이언트에게 고용된 통계 컨설턴트입니다.

광고 데이터셋은 세 가지 플랫폼에 대한 각 시장의 제품 광고 예산과 함께 200개의 서로 다른 제품 판매량으로 구성됩니다.



<img src = "https://py-tonic.github.io/images/islr/2.1.png">



클라이언트가 직접 제품의 판매량을 증가시킬 순는 없지만 각각의 플랫폼에 대한 광고 비용의 지출을 컨트롤 할 수는 있습니다.

따라서,광고와 판매량 사이의 연관성을 판단하여 클라이언트에게 광고 예산을 컨트롤해서 간접적으로 매출을 증가시키도록 해야합니다.

즉, 우리의 목표는 세 가지 플랫폼에 대한 예산을 기반으로 매출을 예측하는 데 사용할 수 있는 정확한 모델을 개발하는 것입니다.



$X$축은 각각의 플랫폼에 대한 광고비용, $Y$축은 판매량입니다.

- $X$ = input variable, predictors, independent variable, features
- $Y$ = output variable, response variable, dependent variable 

각각의 그래프는 판매량에 대해 simple least squares를 적용한 선을 하나 가집니다.(이건 3장에서 다룹니다.)



위 관계를 일반화하여 식으로 나타내봅시다.

$p$ 개의 입력 변수 $X_1,X_2,...,X_p$와 종속 변수 $Y$의 관계는 다음과 같이 나타냅니다.

$$Y=f(X)+\epsilon \tag{2.1}$$

$f$는 입력 변수에 대한 알 수 없는 함수이고 $X$가 $Y$에 대해 제공하는 체계적인 정보를 나타내며, $\epsilon$은 $X$와 독립이며 평균이 0인 랜덤 에러 입니다.



또 다른 예시를 고려해봅시다.

아래의 왼쪽 그래프는 소득 데이터 셋에서 30명의 개인에 대한 소득과 교육 연수를 나타낸 그래프입니다.

<img src = "https://py-tonic.github.io/images/islr/2.2.png">



그래프는 교육 연수를 입력 변수로하여 소득을 예측할 수 있음을 보여줍니다.

그러나 $f$는 여기에서도 여전히 알 수 없습니다. 이 상황에서 관찰된 점을 기반으로 $f$를 추정해야 합니다.

수입은 시뮬레이션된 데이터 셋이므로 $f$가 알려져 있으며 위 그림의 오른쪽에서 파란색 곡선으로 표시됩니다. 여기서 수직 선은 오차 $\epsilon$을 나타냅니다.

오른쪽 그래프를 보면 30개의 관측치 중 일부는 파란색 곡선 위에 있고, 일부는 그 아래에 있습니다. 전반적으로 오차의 평균은 약 0입니다.



일반적으로 함수 $f$는 하나 이상의 입력 변수를 갖습니다. 아래의 그림은 교육 연수와 나이에 대한 수입의 함수를 나타냅니다. 여기서 $f$는 관측된 데이터를 바탕으로 추정한 2차원 평면입니다.(Fig 2.3)



<img src = "https://py-tonic.github.io/images/islr/2.3.png">



본질적으로, 통계적 학습은 $f$를 추정하기 위한 접근 방법을 의미합니다. 이번 챕터에서는 주요 이론적 개념과 획득한 추정치를 평가하기 위한 도구를 설명합니다.



### 2.1.1 Why Estimate f?

$f$를 추정하는 두 가지 이유가 있습니다.

- Prediction
- Inference



**Prediction**

대부분의 상황에서 입력 $X$는 쉽게 사용 가능하지만, 출력 $Y$는 쉽게 얻을 수 없습니다.

이러한 설정에서 오차항은 평균이 0이므로 다음 식을 사용하여 $Y$를 예측할 수 있습니다.

$$\hat Y = \hat f(X) \tag{2.2}$$

$\hat f$는 $f$에 대한 추정치를 나타내고, $\hat Y$는 $Y$에 대한 결과 예측을 나타냅니다.

일반적으로 $Y$에 대한 정확한 예측을 제공하는 경우 $\hat f$의 형태에 관심이 없다는 의미에서 종종 블랙박스로 취급됩니다.

예를 들어, $X_1,...,X_p$는 실험실에서 쉽게 측정 가능한 환자 혈액 샘플의 특성이고, $Y$는 특정 약물의 심각한 부작용에 대한 환자의 위험을 인코딩한 변수입니다.

$X$를 사용하여 $Y$를 예측하는 것은 당연합니다. 이를 통해서 부작용의 위험이 높은 환자 즉, $Y$의 추정치가 높은 환자에게 해당 약물을 투여하는 것을 피할 수 있기 때문입니다.

$Y$에 대한 예측으로서 $\hat Y$의 정확도는 두 가지 양에 따라 달라지며, 이를 reducible error​와 ​irreducible error라고 합니다.

일반적으로 $\hat f$는 $f$를 위한 완벽한 추정이 아니기 때문에 약간의 오류를 유발합니다. 

이 때의 오류를 reducible  error​ 라고 하며 $f$를 추정하기 위해 가장 적절한 통계적 학습 기법을 사용하여 $\hat f$의 정확도를 잠재적으로 향상시킬 수 있습니다.

그러나, $f$에 대해 완벽한 추정치를 형성할 수 있어도, 추정된 응답이 $\hat Y=f(X)$ 형식을 취했더라도 예측에는 여전히 약간의 오류가 있을 것입니다.

이는 $Y$또한 $\epsilon$의 함수이기 때문이며 정의에 따라 $X$를 사용하여 예측할 수 없습니다.

따라서 $\epsilon$과 관련된 변동성은 예측의 정확성에도 영향을 미칩니다.

이것은 우리가 $f$를 아무리 잘 추정하더라도 $\epsilon$에 의해 발생하는 오류를 줄일 수 없기 때문에 irreducible error​라고 알려져 있습니다.



irreducible error가 0보다 큰 이유는 $\epsilon$에는 Y를 예측하는데 유용하지만 측정되지 않는 변수가 포함될 수 있기 때문입니다.

$\epsilon$은 측정할 수 없는 분산도 포함될 수 있습니다. 예를 들어, 부작용의 위험은 주어진 날에 약물 자체의 제조 변형 혹은 그날 환자의 건강 상태 등, 주어진 환자에 따라 다를 수 있습니다.



예측 $\hat Y = \hat f(X)$를 산출하는 주어진 추정치 $\hat f$와 입력 변수 $X$를 고려해봅시다.

$\hat f$와 $X$가 고정되어 있다고 가정하고, 다음과 같이 생각할 수 있습니다.

$$E(Y-\hat Y) = E[f(X)+\epsilon - \hat f(X)]^2 \\ \quad\quad\quad\quad\:=[f(X)-\hat f(X)]^2 +Var(\epsilon)   \tag{2.3}$$

$E(Y-\hat Y)^2$은 예측 값과 실제 값 사이 차이의 제곱에 대한 평균 혹은 기댓값이며, $Var(\epsilon) $은 오차항 $\epsilon$에 대한 분산을 나타냅니다.

이 책은 reducible error를 최소화 하기위해 $f$를 추정하는 기술에 초점을 맞춥니다.

irreducible error는 항상 $Y$에 대한 예측 정확도의 상한을 제공한다는 점을 명심해야합니다. 이 경계는 실제로 거의 알려지지 않았습니다.



**Inference**

우리는 종종 $Y$가 $X_1,...,X_p$의 변화에 영향을 받는 방식을 이해하는 데 관심이 있습니다.

이 상황에서 우리는 $f$를 추정하고 싶지만 우리의 목표는 반드시 $Y$를 예측하는 것은 아닙니다.

대신 우리는 $X$와 $Y$의 관계를 이해하거나 보다 구체적으로 $Y$가 $X_1,...,X_p$의 함수로 어떻게 변하는지 이해하려고 합니다. 



이제 $\hat f$는 정확한 형태를 알아야 하므로 블랙 박스로 취급할 수 없습니다.

이 설정에서는 다음 질문에 답하는 데 관심이 있을 수 있습니다.

- Which predictors are associated with the response?

    사용 가능한 입력 변수 중 극히 일부만이 $Y$와 실질적으로 연관되는 경우가 많습니다.

    많은 가능한 변수 집합 중에서 몇 가지 중요한 예측 변수를 식별하는 것은 경우에 따라 매우 유용할 수 있습니다.

- What is the relationship between the response and each predictor?

    일부 입력 변수는 입력 변수를 증가시키면 $Y$값이 증가하는 것과 관련이 있다는 점에서 양의 상관관계를 가질 수 있습니다. 다른 변수들은 반대의 관계를 가질 수 있습니다.

    $f$의 복잡도에 따라 반응과 주어진 입력 변수간의 관계는 다른 입력 변수의 값에 따라 달라질 수 있습니다.

- Can the relationship between Y and each predictor be adequately summarized using  a linear equation or is the relationship more complicated?

    역사적으로 $f$를 추정하는 대부분의 방법은 선형을 사용했습니다. 특정 상황에서는 그러한 가정이 합리적이거나 심지어 바람직합니다. 하지만 종종 실제 관계는 보다 복잡해서 선형 모델로는 입력 변수와 출력 변수사이의 관계를 정확하게 제공하는 것이 불가능합니다.



이 책에서는 예측 설정, 추론 설정 혹은 이 둘의 조합에 해당하는 여러 예시를 볼 수 있습니다.

예를 들어, 직접 마케팅 캠페인을 수행하는데 관심이 있는 회사를 생각해봅시다.

목표는 개별로 측정된 인구 통계학적 변수의 관찰을 기반으로 메일에 대하여 긍정적으로 응답할 개인을 식별하는 것입니다.

이 경우 인구 통계학적 변수는 입력 변수 역할을 하고, 마케팅 캠페인에 대한 반응(긍정 or 부정)은 결과에 해당합니다.

회사는 각 개별 입력 변수와 응답 간의 관계를 깊이 이해하는 것에 관심이 없습니다.

대신 회사는 입력 변수를 사용하여 반응을 예측하는 정확한 모델을 원합니다. 이 것이 바로 예측 모델링의 예시입니다.



이와 반대로 가장 처음 고려했던 광고 데이터셋에 대해 생각해봅시다. 

다음과 같은 질문에 대해 관심이 있을 수 있습니다.

- Which media contribute to sales?
- Which media generate the biggest boost in sales?
- How much increase in sales is associated with a given increase in TV advertising?

이런 상황은 추론 영역에 속합니다.



또 다른 예시는 가격, 매장 위치, 할인 수준, 경쟁 가격 등과 같은 변수를 기반으로 고객이 구매할 수 있는 제품의 브랜드를 모델링 하는 것입니다.

이런 상황에서 가장 관심있는 부분은 ''각각의 변수가 구매 확률에 얼마나 영향을 미치는지'' 입니다.

예를 들어, 제품 가격 변경이 판매에 어떤 영향을 미칠까요? 이것은 추론을 위한 모델의 예시입니다.



몇몇 모델은 예측과 추론 두 가지에 관심이 있을 수 있습니다.

예를들어 부동산 환경에서 주택 가치를 범죄율, 구역 설정, 강으로부터의 거리, 대기 질, 학교, 지역 사회 소득 수준, 주택 크기 등과 같은 입력과 연관시키려고 할 수 있습니다. 

이 경우 개별 입력 변수가 가격에 어떤 영향을 미치는지 관심이 있을 수 있습니다. 즉, 강이 보이는 경우 주택 가치가 얼마나 될까요? 또는 주택 특성을 감안할 때 주택 가치를 예측하는 데 관심이 있을 수 있습니다.

궁극적인 목표가 예측인지, 추론인지 또는 두 가지의 조합인지에 따라 $f$를 추정하는 다른 방법이 적절할 수 있습니다.

예를 들어, 선형 모델은 비교적 단순하고 예측 가능한 추론인 반면에, 다른 접근 방식 만큼 정확한 예측을 산출하지 못할 수 있습니다.



### How Do we Estimate f?

이 책 전체에서 $f$를 추정하기 위한 많은 선형 및 비선형 접근법을 탐구합니다.

이러한 방법은 일반적으로 특정 특성을 공유합니다. 이 섹션에서는 이러한 공유 특성에 대한 개요를 제공합니다.

우리는 항상 서로 다른 n개의 데이터 포인트를 관찰했다고 가정합니다.

이런 관측 값을 훈련 데이터 라고 합니다. $f$를 추정하는 방법을 훈련하거나 가르치기 위해 이러한 훈련 데이터 관측 값을 사용하기 때문.

$x_{ij}$가 관측 치 $i = 1,2,...,n$에 대한 $j = 1,2,...,p$번 째 예측 변수 또는 입력 값을 나타내도록 합니다.

따라서 $y_i$는 $i$번 째 관측치에 대한 반응 변수를 나타냅니다.

그러므로 우리의 훈련 데이터는 다음과 같이 구성됩니다.

$$(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$$

$$where\:\: x_i= (x_{i1},x_{i2},...,x_{ip})^T$$

우리 목적은 $f$를 추정하기 위해서 통계적 학습 방법을 훈련 데이터에 적용하는 것입니다.

다시말해서 우리는 모든 관측치 $(X,Y)$에 대해 $ Y\approx \hat f(X)$ 를 만족하는 함수 $\hat f$를 찾고 싶은 것입니다.

일반적으로 이 작업에 대한 대부분의 통계적 학습 방법은 parametric or non-parametric으로 특징지을 수 있습니다.



**Parametric Method**

파라미터릭 방법은 두 가지 단계의 모델 기반 접근방법을 포함합니다.

1. 함수 $f$의 형태나 모양에 대해 가정합니다. 예를들어 아주 간단한 $f$에 대한 가정은 X에 대해 선형으로 나타내는 것입니다.

    $$f(X) = \beta_0 + \beta_1X_1 + \beta_2X_2+\cdot\cdot\cdot + \beta_pX_p \tag{2.4}$$

    이 것이 3장에서 광범위하게 다룰 선형 모델 입니다. $f$가 선형이라고 가정하면 $f$ 추정 문제는 크게 단순화됩니다. 임의의 $p$차원 함수 $f(X)$를 추정하는 대신 $p$+1개의 계수 $\beta_0,...,\beta_p$를 추정합니다.

2. 모델이 선택 되면, 훈련 데이터를 이용하여 모델을 학습합니다. (2.4)와 같이 선형 모델인 경우 파라미터를 추정합니다. 이러한 파라미터의 값을 찾으려면 다음과 같은 식을 따릅니다.

    $$Y\approx \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p$$

    모델 (2.4)를 피팅하는 가장 일반적인 접근 방식은 최소 제곱법이라 불리며 3장에서 다룹니다. 최소 제곱법 또한 선형 모델을 피팅하는 많은 방법 중 하나입니다. 6장에서는 파라미터를 추정하는 다른 접근 방식에 대해 다룹니다.

위에서 설명한 모델 기반 접근 방식을 파라미터릭이라고 합니다. $f$를 추정하는 문제를 파라미터 셋 추정 중 하나로 줄입니다.

일반적으로 파라미터 집합을 추정하는 것이 훨씬 더 쉽습니다.

이 방식의 잠재적인 단점은 우리가 선택한 모델이 일반적으로 $f$의 알 수 없는 실제 형식과 일치하지 않는다는 것입니다. 선택한 모델이 실제 $f$와 너무 멀면 추정치가 좋지 않습니다. $f$에 대해 다양한 기능적 현태에 맞는 유연한 모델을 선택하여 문제를 해결할 수 있습니다.

하지만 일반적으로 유연한 모델을 피팅하려면 더 많은 수의 파라미터를 추정해야 합니다. 

이러한 더 복잡한 모델은 데이터를 오버피팅 시킬 수 잇으며 이는 본질적으로 오버피팅이 오류 또는 노이즈를 너무 가깝게 따라 간다는 것을 의미합니다.

아래의 그림은 앞서 앞선 소득 데이터에 파라미터릭 방식을 적용한 예시입니다.



<img src = "https://py-tonic.github.io/images/islr/2.4.png">



우리는 선형 모델을 다음 형태를 통해 피팅합니다.

$$income = \beta_0+\beta_1\times education+\beta_2\times seniority$$

반응과 두 개의 입력 변수 사이의 관계를 선형으로 가정하고, 전체 피팅 문제는 최소 제곱 선형 회귀를 사용하여 $\beta_0, \beta_1,\beta_2$를 추정합니다.



위 그림과 이전의 그림을 비교해보면 위 그림에서 주어진 선형 피팅이 옳지 않다는 것을 알 수 있습니다. 실제 $f$에는 선형 피팅에서 포착되지 않은 일부 곡률이 존재합니다.

하지만 선형 피팅은 여전히 수입과 나이 사이의 조금 작은 양의 상관관계 뿐만 아니라 교육 연수와 소득 간의 양의 관계를 포착하는 합리적인 작업을 수행합니다.



**Non-parametric Methods**

비 모수적 방법은 $f$의 기능적 형태에 대한 명시적인 가정을 하지 않습니다.

대신 너무 러프하거나 흔들리지 않고 가능한 데이터 포인트에 가까워지는 $f$의 추정치를 찾습니다.

이런 접근 방식은 파라미터릭 접근 방식 보다 큰 이점이 있습니다.

$f$에 대한 특정 기능적 형식의 가정을 피함으로써 $f$에 대해 더 넓은 범위의 가능한 모양에 정확하게 맞출 가능성이 있습니다.

모든 파라미터릭 접근 방식은 $f$를 추정하는데 사용되는 기능적 형식이 실제 $f$와 매우 다를 가능성을 가져옵니다. 이 경우 결과 모델이 데이터에 적합하지 않습니다.

대조적으로, 비 모수적 접근 방식은 본질적으로 $f$의 형태에 대한 가정이 없기 때문에 이러한 위험을 피할 수 있습니다. 하지만 비 모수적 접근 방식에도 단점이 존재합니다.

$f$를 추정하는 문제를 작은 수의 파라미터로 줄이지 않기 때문에 $f$에 대한 정확한 추정을 얻으려면 매우 많은 수의 관측치(파라미터릭 접근 방식에 일반적으로 필요한 것 보다 훨씬 더 많은)가 필요합니다.

수입 데이터를 맞추기 위한 비 모수적 접근 방식의 예가 아래의 그림과 같습니다.

<img src = "https://py-tonic.github.io/images/islr/2.5.png">



얇은 평면은 $f$를 추정하는데 사용됩니다. 이 접근 방식은 $f$에 사전 지정된 모델을 부과하지 않습니다.

대신 피팅에 따라 관찰된 데이터에 가능한 가까운 $f$에 대한 추정치를 구성하려고 노력합니다.(위 그림)

이 경우 비 모수적 피팅은 Fig 2.3에 표시된 참 $f$의 매우 정확한 추정치를 생성했습니다.

얇은 평면을 피팅하려면 데이터 분석가는 부드러운 정도를 선택해야 합니다.

아래의 그림은 낮은 수준의 부드러움을 사용한 동일한 평면 피팅을 보여줍니다.

<img src = "https://py-tonic.github.io/images/islr/2.6.png">



결과 추정치는 관찰된 데이터에 완벽하게 피팅됩니다. 그러나 위 그림의 평면 피팅은 Fig 2.3의 실제 함수 $f$보다 훨씬 더 가변적입니다.

이전에 논의한 데이터 오버피팅의 예시입니다. 얻은 적합도는 새로운 관측치에 대한 반응의 정확한 추정치를 산출하지 못하기 때문에 바람직하지 않은 상황입니다. 



### 2.1.3 The Trade-off Between Prediction Accuracy and Model Interpretability

책에서 사용하는 많은 방법 중 일부는 $f$를 추정하기 위해 상대적으로 작은 범위의 모양만 생성할 수 있기 때문에 제한적이거나 덜 유연합니다.

예를 들어, 선형 회귀의 경우 앞서 보여줬던 직선 혹은 평면과 같은 선형 함수만 생성할 수 있기 때문에  상대적으로 유연하지 않은 접근입니다.

다른 방법으로는 비 모수적 방법에서 다뤘던 thin plate splines가 있는데 이런 방법이 추정 가능한 $f$에 대해 더 넓은 모양의 범위를 생성하기 때문에 훨씬 더 유연합니다.



우리가 지금까지 배운것들을 바탕으로 '유연한 접근 방식 대신 제한적인 방법을 사용하는 이유가 무엇인가요?' 라는 질문을 하는 것은 매우 합리적입니다.

제한적인 모델을 더 선호하는 몇가지 이유가 존재합니다.

만약 우리가 **추론**에 관심이 있다면 제한적인 모델이 훨씬 더 해석가능합니다.

예를 들어, 추론이 목적일 때 선형 모델은 $Y$와 $X_1,...,X_p$의 관계를 이해하기 쉽기 때문에 좋은 선택입니다.

대조적으로 splines, 부스팅 계열과 같은 매우 유연한 접근 방식은 각각의 독립 변수가 응답과 어떤 연관성이 있는지 이해하기 어렵기 때문에 $f$에 대해 복잡한 추정으로 이어집니다.



<img src = "https://py-tonic.github.io/images/islr/2.7.png">

위 그림은 모델의 유연함과 해석 가능함 사이의 trade-off를 나타냅니다.

앞서 몇번 언급했던 최소 제곱법의 경우 상대적으로 유연하진 않지만 해석가능한 모델입니다.

6장에서 다를 라쏘 회귀의 경우 선형 모델에 의존하지만 계수를 추정하기 위해 alternatvie 피팅 절차를 사용합니다.

새로운 절차는 계수를 추정하는데 더 제한적이며 계수를 정확히 0으로 설정합니다. 이런 의미에서 라쏘 회귀는 선형 회귀보다 덜 유연한 접근 방식이지만 최종 모델의 응답 변수는 독립 변수의 작은 부분집합과 관련이 있기 때문에(0이 아닌 계수 추정) 선형 회귀 보다 더 해석 가능합니다.

7장에서 다룰 GAMs은 특정 비 선형 관계를 허용하기 위해 선형 모델을 확장합니다. 결과적으로 GAMs는 선형 회귀보다 더 유연합니다.

각각의 독립 변수와 반응 변수간의 관계가 곡선을 사용하여 모델링 되기 때문에 선형 회귀에 비해서 해석하기 다소 어렵습니다.

마지막으로 배깅, 부스팅, SVM과 같은 8, 9장에서 다룰 비선형 커널을 사용하는 비선형 방법의 경우 매우 유연하지만 해석하기 어렵습니다.

- Prediction : 예측에만 관심이 있고 해석 가능성은 관계 없는 경우 (보다 유연한 모델을 선택)
- Inference : 단순하고 상대적으로 덜 유연한 통계적 학습 방법을 사용



### 2.1.4 Supervised Versus Unsupervised Learning

대부분의 통계적 학습 방법은 두 가지 카테고리로 나눌 수 있습니다.

- Supervised
- Unsueprvised

지금까지 얘기한 예시는 모두 지도학습의 영역에 속합니다.

독립 변수의 측정 값 $x_i = 1,...,n$의 각 관측 값에 대해 연관된 반응 측정 값이 있습니다.

future observations(Prediction)에 대한 반응을 정확하게 예측하거나 반응과 예측 변수 사이의 관계를 더 잘 이해(Inference)하는 목적과 함께 우리는 모델이 피팅하길 원합니다.

선형 회귀 및 로지스틱 회귀와 같은 많은 고전적 통계 학습 방법과 GAM, 부스팅, SVM과 같은 더 현대적 접근 방식은 지도 학습의 영역에서 작동합니다.

책에서 대부분은 지도학습에 초점을 맞춥니다.

비지도 학습은 모든 관찰 $i=1,...,n$에 대해 측정 값 $x_i$의 벡터를 관찰하지만 연관된 응답 $y_i$는 관찰하지 않는 다소 어려운 상황을 설명합니다.

예측할 반응 변수가 없기 때문에 선형 회귀 모델을 통해서 피팅할 수 없습니다. 어떤 의미에서 맹인의 입장에서 일하는 것 같습니다.

하지만 변수 사이 혹은 관측치 사이의 관계를 이해하려고 노력할 수 있습니다.

이런 상황에서 사용 가능한 통계적 학습 도구 중 하나는 클러스터 분석 또는 클러스터링 입니다.

클러스터 분석의 목표는 $x_1,...,x_n$을 기준으로 관측치가 상대적으로 다른 그룹에 속하는지 여부를 확인하는 것입니다.

예를 들어, 시장 세분화 연구에서 우편 번호, 가족 소득 및 쇼핑 습관과 같은 잠재 고객에 대한 여러 특성(변수)을 관찰할 수 있습니다.

각각의 관련 변수에 따라 그룹이 다를 수 있습니다.



<img src = "https://py-tonic.github.io/images/islr/2.8.png">

왼쪽 그룹은 잘 분리됐지만 오른쪽은 겹치는 부분이 존재합니다.

클러스터링 방법은 겹치는 모든 점을 올바른 그룹(파란색, 녹색, 주황색)에 할당할 수 없습니다.

위 그림은 변수가 두 개뿐이므로 클러스터를 식별하기 위해 관측치의 산점도를 시각적으로 간단히 검사할 수 있습니다. 하지만, 실제 데이터는 단순하지 않습니다. 변수가 많ㅇ르 수록 더 많은 개별 산점도를 만들어야 하므로 자동화된 클러스터링 방법이 중요합니다.(10장에서 자세히 다룹니다.)



만약 $n$개의 데이터에서 $(m<n)$ $m$개의 반응 변수만 존재할 때 어떻게 해야 할까요?

나머지 $n-m$개의 반응 변수를 측정하는 비용은 매우 비쌉니다. 이럴 때 사용할 수 있는 방법이 semi-supervised learning입니다.

이 설정에서는 응답 측정이 가능한 $m$개의 관측치와 그렇지 않은 $n-m$개의 관측치를 통합할 수 있는 통계적 학습 방법을 사용하려고 합니다.(이 책의 범위를 벗어나므로 다루진 않습니다.)



### 2.1.5 Regression Versus Classification Problems

변수는 양적, 질적(범주형이라고도 하는)으로 특성화될 수 있습니다.

양적 변수는 수치형 값입니다. (나이, 키, 수입 등)

그와 대조적으로 질적 변수는 서로 다른 클래스나 카테고리를 갖는 값입니다.(브랜드, Yes or no, 등)

우리는 정량적 반응이 있는 문제를 회귀라고 부르는 경향이 있으며 정성적 반응을 포함하는 문제를 종종 분류 문제라고 말합니다.

그러나 항상 이렇게 구별할 수 있는건 아닙니다.

최소 제곱 선형 회귀는 정량적 반응과 함께 사용되는 반면에, 로지스틱 회귀는 정성적 반응과 함께 사용됩니다.(그러나 확률을 추정하기 때문에 회귀 문제로도 생각할 수도 있습니다.)

KNN 및 부스팅과 같은 일부 방법은 정량적, 정성적 경우 둘 다 사용할 수 있습니다.

하지만 대부분의 경우 어떤 데이터 타입인지 중요하지 않습니다. 대부분의 통계적 학습 방법은 분석을 수행하기 전에 정성적 예측 변수를 올바르게 코딩한 경우 예측 변수의 유형예 상관 없이 적용할 수 있습니다.



## 2.2 Assessing Model Accuracy

책에서 다양한 통계적 학습 접근법을 도입하는 이유가 뭘까요? 통계에는 공짜가 없습니다. 즉, 한 가지 방법으로 다른 데이터에 모든 것을 다룰 수 없습니다.

특정 데이터 셋에서 하나의 특정 방법이 가장 잘 작동할 수 있지만 다른 데이터 셋에선 그렇지 않을 수 있습니다. 따라서 주어진 데이터 셋에 대해 어떤 방법이 최상의 결과를 생성하는지 결정하는 것이 중요한 작업입니다. 최상의 접근 방식을 선택하는 것은 실제로 통계 학습을 수행하는 가장 어려운 부분중 하나입니다.

이 섹션에서는 특정 데이터 셋에 대한 통계적 학습 절차를 선택할 때 발생하는 가장 중요한 개념에 대해 설명합니다.



### 2.2.1 Measuring the Quality of Fit

주어진 데이터에 대해 통계적 학습 방법의 성능을 평가하기 위해서 우리는 예측이 실제 관측 데이터와 얼마나 잘 맞는지 측정할 방법이 필요합니다.

즉, 우리는 주어진 관측치에 대해 예측 반응 값이 해당 관측치에 대한 실제 반응 값에 가까운 정도를 정량화 해야 합니다.

회귀문제에서는 가장 흔하게 사용되는 측정은 **MSE** 입니다.

$$MSE = \frac1n \sum\limits_{i=1}^n(y_i-\hat f(x))^2$$

$\hat f(x_i)$는  $\hat f$가 주어진 $i$번째 관측에 대해 제공하는 예측입니다.

훈련 데이터에 대하여 MSE가 낮은 것은 딱히 관심이 없고 궁극적으론 테스트 데이터에 대하여 MSE가 낮은 모델에 관심이 있습니다.

훈련 데이터 MSE가 대부분 테스트 MSE보다 낮습니다. 아래의 그림을 통해 확인할 수 있습니다.(Fig 2.9)



<img src = "https://py-tonic.github.io/images/islr/2.9.png">

주황색 직선은 상대적으로 유연하지 않은 직선이고 초록색 선은 너무 유연한 모델입니다.

훈련 MSE의 경우 유연성이 증가함에 따라 단조롭게 감소합니다. 이 예에서 true $f$는 비선형 이므로 주황색 선형 피팅은 $f$를 추정할 만큼 유연하진 않습니다. 녹색 곡선의 경우 가장 유연하므로 훈련 MSE가 가장 낮습니다.

테스트 MSE를 살펴봅시다 자유도가 떨어짐에 따라 어느정도 같이 떨어지다가 특정 시점에서 다시 증가하기 시작합니다. 결과적으로 주황색과 녹색 모두 높은 테스트 MSE를 갖습니다.

파란색 곡선은 테스트 MSE를 최소화 합니다.

점선은 irreducible error인 $Var(\epsilon)$을 나타내며, 가능한 모든 방법 중 가장 낮은 테스트 MSE에 해당합니다. 따라서 파란색 곡선으로 표현되는 스무딩 스플라인은 최적에 가깝습니다.

녹색 케이스처럼 훈련 MSE는 낮지만 테스트 MSE는 큰 경우 **오버피팅**이라고 합니다. 이것은 통계적 학습 절차가 훈련 데이터에서 패턴을 찾기에는 너무 열심히 일하고 있고, 알 수 없는 함수 $f$의 실제 속성이 아닌 임의의 우연에 의해 발생한 일부 패턴을 선택할 수 있기 때문에 발생합니다.

오버피팅이 발생했는지 여부에 관계없이 대부분의 통계적 학습 방법은 직 간접적으로 훈련 MSE를 최소화 하려고 하기 때문에 거의 항상 훈련 MSE가 테스트 MSE보다 작습니다.



<img src = "https://py-tonic.github.io/images/islr/2.10.png">

위 그림은(Fig 2.10) 다른 true $f$가 선형인 또 다른 예시를 제공합니다.

우리는 또 다시 모델 유연성이 증가함에 따라 훈련 MSE가 단조롭게 감소하고 테스트 MSE에 U자 모양이 있음을 관찰할 수 있습니다.

그러나 이번 케이스는 트루케이스가 선형이기 때문에 주황색 함수가 녹색 곡선에 비해 훨씬 좋습니다.



 <img src = "https://py-tonic.github.io/images/islr/2.11.png">

마지막으로 위 그림(Fig 2.11)의 경우 트루 $f$가 비선형입니다.

훈련 및 테스트 MSE 커브는 여전히 동일한 패턴을 나타내지만 이제 테스트 MSE가 천천히 증가하기 시작하기 전에 두 곡선이 급격히 감소합니다.

앞선 세 가지 그림에서 볼 수 있듯 모델의 유연성은 데이터 셋에 따라 상당히 다를 수 있습니다.

이 책에서는 최소 지점을 추정하기 위해 실제로 사용 가능한 다양한 접근 방법에 대해 얘기합니다.

한 가지 중요한 방법은 교차검증으로 훈련 데이터를 사용하여 테스트 MSE를 추정하는 방식입니다.(5장에서 자세히 다룹니다.)



### 2.2.2 The Bias-Variance Trade-Off

테스트 MSE 곡선에서 관찰된 U자 모양은 통계적 학습 방법의 두 가지 경쟁 속성의 결과인 것으로 밝혀졌습니다. 주어진 값 $x_0$에 대해 예상되는 테스트 MSE가 항상 세 가지에 대한 합으로 분해될 수 있음을 보여줄 수 있습니다. 

$$E(y_0-\hat f(x_0))^2 = Var(\hat f(x_0))+[Bias(\hat f(x_0))]^2+Var(\epsilon) \tag{2.7}$$



위 식은 예상되는 테스트 오류를 최소화 하기 위해 낮은 분산과 낮은 편향을 동시에 달성하는 통계적 학습 방법을 선택해야 함을 알려줍니다.

앞서 살펴봤던 많은 MSE 그래프에서 테스트 에러가 $Var(\epsilon)$ 아래로 떨어질 수 없었던 이유가 분산, 편향이 모두 양수이기 때문입니다.

훈련 데이터는 통계적 학습 방법을 통해 피팅하기 때문에 다른 훈련 데이터 셋은 다른 $\hat f$를 생성합니다.

그러나 이상적으로 $f$에 대한 추정치는 훈련 세트간에 너무 많이 변하지 않아야 합니다.

그러나 사용하는 방법의 분산이 높으면 훈련 데이터의 작은 변화로 인해 $\hat f$에 큰 변화가 발생할 수 있습니다. 일반적으로 더 유연한 통계적 방법의 경우 분산이 높습니다.

Fig 2.9를 다시 살펴보면 유연한 녹색 커브는 관측 데이터에 매우 가깝게 피팅되어 있습니다. 이러한 데이터 포인트 중 하나를 변경하면 추정치 $\hat f$가 상당히 변경될 수 있으므로 분산이 높습니다.

대조적으로 주황색 최소 제곱 직선은 상대적으로 덜 유연하고 분산이 적습니다. 특정 단일 관측치를 이동하면 선의 위치가 약간만 이동하기 때문입니다.

반면에 편향은 매우 복잡한 실제 문제를 훨씬 더 단순한 모델에 근사할 때 발생하는 오류를 의미합니다.

그림 2.11에서 트루 $f$는 실질적으로 비선형이므로 우리가 많은 데이터를 제공하더라도 선형 회귀를 사용하여 정확한 추정치를 생성하는 것은 불가능합니다. 즉, 선형 회귀는 이 예시에서 높은 편향을 유발합니다.

그러나 Fig 2.10 트루$f$가 선형이므로 충분한 데이터가 주어지면 선형 회귀가 정확한 추정치를 생성할 수 있어야 합니다. 일반적으로 더 유연할수록 편향이 적습니다.

일반적으로 더 유연한 방법을 사용하면 분산이 증가하고 편향이 감소합니다. 이 두 가지의 상대적 변화율에 따라 테스트 MSE가 증가할지 감소할지 결정됩니다.

아래의 그림은 Fig 2.9~2.11의 예에 대한 식 2.7을 보여줍니다. 각 경우 파란색 실선 곡선은 다양한 유연성에 대한 제곱 편향을 나타내고 주황색 곡선은 분산에 해당합니다.



<img src = "https://py-tonic.github.io/images/islr/2.12.png">



### 2.2.3 The Classification Setting

이제 분류태스크에 대해 얘기해봅시다. 우리가 만났던 개념에서 반응 변수 약간 수정해서 분류 설정으로 바꿀 수 있습니다.

분류 태스크에서 $\hat f$의 정확도를 정량화 하는 가장 일반적인 접근 방식은 훈련 오류율 즉, 추정치 $\hat f$를 훈련 데이터에 적용할 때 발생하는 실수 비율입니다.

$$\frac1n \sum\limits_{i=1}^nI(y_i\neq\hat y_i) \tag{2.8}$$

테스트 에러 비율의 경우 다음과 같습니다.



$$Ave(I(y_0\neq\hat y_0))\tag{2.9}$$



$y_i$는 추정치 $\hat f$를 사용하여 $i$번 째 관측에 대한 예측된 클래스 레이블입니다.

$I(y_i\neq\hat y_i)$는 $y_i\neq\hat y_i$ 이면 1, $y_i=\hat y_i$ 이면 0인 지시 변수입니다.



**The Bayes Classifier**

식 2.9에 제공된 테스트 오류율은 예측 변수 값이 주어지면 관측 값을 가장 가능성이 높은 클래스에 할당하는 매우 간단한 분류기에 의해 평균적으로 최소화됩니다.

즉, 예측 변수 벡터가 $x_0$인 테스트 관측치를 클래스 $j$에 할당하는 문제로 생각할 수 있습니다.

$$Pr(Y=j\vert X=x_0)\tag{2.10}$$

이 아주 간단한 분류기를 베이즈 분류기라고 부릅니다.

만약 반응 변수의 값이 두 가지라면 $Pr(Y=1\vert X=x_0)>0.5$이고 나머지 확률엔 0으로 분류할 수 있습니다.

<img src = "https://py-tonic.github.io/images/islr/2.13.png">

위 그림은(Fig 2.3) 예측 변수 $X_1$과 $X_2$로 구성된 2차원 공간에서 시뮬레이션된 데이터 세트를 사용하는 예시입니다.

$X_1,X_2$의 각 값에 따라 주황색, 파란색일 확률이 다릅니다. 시뮬레이션 데이터이므로 데이터가 어떻게 생성되었는지 알고 있으며 $X_1,X_2$의 각 값에 대한 조건부 확률을 계산할 수 있습니다.

위 그림에서 자주색 경계를 베이즈 결정경계라고 합니다.

베이즈 분류기는 베이즈 오류율 이라고 하는 가장 낮은 테스트 오류율을 생성합니다. 베이즈 분류기는 항상 2.10이 가장 큰 클래스를 선택하므로 $X=x_0$에서의 오류율은 $1-\max\limits_jPr(Y=j\vert x_0)$ 입니다.

일반적으로 전체 베이즈 오류율은 다음과 같습니다.

$$1-E(\max\limits_jPr(Y=j\vert X))\tag{2.11}$$



**K-Nearest Neighbors**

우리는 베이즈 분류기를 사용하여 정성적 반응을 예측하고 싶습니다.

하지만 실제 데이터에서는, $P(Y\vert X)$의 조건부 분포를 알 수 없으므로 베이즈 분류기를 통한 계산이 불가능합니다.

대부분의 접근 방식은 $X$가 주어질 때 $Y$의 조건부 분포를 추정한 다음 주어진 관측치를 가장 높은 추정 확률에 대한 클래스로 분류하려고 합니다.

이런 방법 중 하나가 바로 이번 섹션에서 다룰 KNN입니다.

양의 정수 $K$와 테스트 관측치 $x_0$가 주어지면 KNN 분류기는 먼저 $N_0$로 표현되는 $x_0$에서 가장 가까운 $K$개의 포인트를 식별합니다.

그런 다음 클래스 $j$에 대한 조건부 확률 응답 변수의 값이 $j$인 $N_0$의 비율로 추정합니다. 

$$Pr(Y=j\vert X=x_0) = \frac1K \sum\limits_{i\in N_0}I(y_i=j)\tag{2.12}$$

마지막으로 KNN은 베이즈 규칙을 적용하고 테스트 관측치 $x_0$를 확률이 가장 큰 클래스로 분류합니다.



<img src = "https://py-tonic.github.io/images/islr/2.14.png">

위 그림은 KNN 접근 방식의 예시입니다.

왼쪽 그림은 6 개의 파란색, 6 개의 주황색 관측치를 제공합니다. 우리의 목표는 x표시된 데이터에 대한 클래스를 예측하는 것입니다. $K=3$으로 가정하면, KNN은 x 주변의 가장 가까운 3개의 관측치를 식별합니다.(원으로 표시됨)

파란 색 2개, 주황색 1개이므로 각각의 클래스에 대한 확률은 2/3, 1/3 입니다. 그러므로 KNN은 x에 대해서 파란색으로 분류합니다. 오른쪽 그림은 가능한 모든 값에 대해서 $K=3$을 기준으로 결정경계를 그렸습니다.

매우 간단한 접근 방식이지만, KNN은 종종 최적의 베이즈 분류기에 가까운 분류기를 생성할 수 있습니다.

  

<img src = "https://py-tonic.github.io/images/islr/2.15.png">

위 그림은 Fig 2.3에 대해 K=10 일 때의 KNN 결정 경계를 보여줍니다. 위 그림이 보여주는 것은  비록 진짜 분포는 모르더라도 KNN을 통해 베이즈 분류기에 매우 가까운 결정 경계를 만들어 낼 수 있습니다.

KNN은 K에 따라 극단적으로 바뀝니다.



<img src = "https://py-tonic.github.io/images/islr/2.16.png">



$K =1$일 경우 매우 유연하게 패턴을 찾고, 베이즈 결정 경계에 해당하지 않는 패턴까지 찾아냅니다.

이는 바이어스는 낮지만 분산이 매우 높은 분류기에 해당합니다. $K$ 를 늘리는 경우 선형적인 결정 경계를 생성하는 것을 볼 수 있습니다. 이는 분산이 낮고 편향이 매우 높은 분류기에 해당합니다.

회귀에서와 마찬가지로 트레이닝 에러와 테스트 에러 사이엔 상관관계가 딱히 없습니다.

<img src = "https://py-tonic.github.io/images/islr/2.17.png">

$K=1$일 때 트레이닝 에러가 0에 수렴하는 것으로 보아 회귀 때 처럼 유연한 모델은 트레이닝 에러가 감소하는 경향이 있는 것을 볼 수 있습니다.

마찬가지로 테스트 에러도 U자 모양을 띄는 것을 볼 수 있습니다. 처음에는 점차 감소하다가 약 $K=10$쯤에서 가장 낮은 테스트 에러를 가지고 다시 올라갑니다.

회귀 및 분류에서 올바른 수준의 유연성을 선택하는 것이 통계적 학습 방법의 성공을 결정짓는 중요한 요소입니다. Bias-variance trade-off, 테스트 에러의 U자 모양 등은 이것을 어렵게 만드는 요소들입니다.

5장에서는 이 주제로 돌아가서 테스트 에러를 추정하고, 주어진 통계적 학습법에 최적의 유연성을 선택하는 다양한 방법에 대해서 얘기합니다.

