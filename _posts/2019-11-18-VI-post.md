---
layout: post
title: Variational Inference
author: Jaeheon Kwon
categories: Mathematics
tags: [statistics]
---

# Variational Inference

Vi는 posterior distribution이 너무 복잡해서 간단한 분포(ex : 정규분포)로 근사하여 문제를 해결하는 방식입니다.

<img src = "https://py-tonic.github.io/images/EM/3.PNG">

어떻게 근사하여 표현할 수 있을까요?

우리는 두 확률분포사이의 차이를 나타낼 때 아주 유용한 도구인 KL-divergence를 알고 있습니다.<br>
이를 이용하여 아주 복잡한 posterior $p(z|x)$ 를 $q(z)$에 근사하여 표현해봅시다. 

<img src = "https://py-tonic.github.io/images/EM/0.PNG">

이외에도 Vi를 응용하여 Monte Carlo Method와 Gradient Descent를 활용하여 사용하는 방법이 있지만 여기서 다루진 않겠습니다.

Vi에 대하여 더 공부해보고 싶으시면 [link]( https://medium.com/@jonathan_hui/machine-learning-variational-inference-273d8e6480bb )를 읽어보세요.
